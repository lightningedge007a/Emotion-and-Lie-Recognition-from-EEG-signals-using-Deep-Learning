{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Nov 09 17:17:37 2019       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 440.97       Driver Version: 440.97       CUDA Version: 10.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce GTX 166... WDDM  | 00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   36C    P3     9W /  N/A |    153MiB /  6144MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-08T15:42:33.354317Z",
     "start_time": "2019-11-08T15:42:33.350328Z"
    }
   },
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-08T15:42:15.808013Z",
     "start_time": "2019-11-08T15:42:15.535620Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_model(model, to_file='full_model.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-08T15:42:41.657883Z",
     "start_time": "2019-11-08T15:42:41.654859Z"
    }
   },
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-08T15:30:05.169434Z",
     "start_time": "2019-11-08T15:30:00.954519Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "# import sklearn\n",
    "from sklearn.metrics import precision_score, recall_score, roc_auc_score, f1_score, confusion_matrix, roc_curve, auc\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import time\n",
    "import math\n",
    "import scipy.io as sio\n",
    "\n",
    "from keras.layers import Conv2D, Dense, Flatten, ELU, BatchNormalization, LSTMCell, StackedRNNCells,\\\n",
    "    RNN, Permute, Dropout, Concatenate, Input, concatenate, Lambda, Reshape, Lambda\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.utils import plot_model\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers.merge import add\n",
    "from keras.callbacks import TensorBoard\n",
    "\n",
    "from keras import callbacks\n",
    "\n",
    "from keras import regularizers\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "import datetime\n",
    "\n",
    "from keras.models import load_model\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-08T15:30:05.186389Z",
     "start_time": "2019-11-08T15:30:05.181403Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32 ['s01', 's02', 's03', 's04', 's05', 's06', 's07', 's08', 's09', 's10', 's11', 's12', 's13', 's14', 's15', 's16', 's17', 's18', 's19', 's20', 's21', 's22', 's23', 's24', 's25', 's26', 's27', 's28', 's29', 's30', 's31', 's32']\n"
     ]
    }
   ],
   "source": [
    "data_files=[]\n",
    "for i in range(1,33):\n",
    "    if(1<=i<=9):\n",
    "        s='s0'+str(i)\n",
    "    else:\n",
    "        s='s'+str(i)\n",
    "    data_files.append(s)\n",
    "print(len(data_files),data_files)\n",
    "\n",
    "# emotions=['arousal','valence']\n",
    "\n",
    "#baseline_preprocessing=['yes','no']\n",
    "emotions=['dominance']\n",
    "\n",
    "baseline_preprocessing=['yes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-08T15:30:05.200352Z",
     "start_time": "2019-11-08T15:30:05.195366Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['s01',\n",
       "  's02',\n",
       "  's03',\n",
       "  's04',\n",
       "  's05',\n",
       "  's06',\n",
       "  's07',\n",
       "  's08',\n",
       "  's09',\n",
       "  's10',\n",
       "  's11',\n",
       "  's12',\n",
       "  's13',\n",
       "  's14',\n",
       "  's15',\n",
       "  's16',\n",
       "  's17',\n",
       "  's18',\n",
       "  's19',\n",
       "  's20',\n",
       "  's21',\n",
       "  's22',\n",
       "  's23',\n",
       "  's24',\n",
       "  's25',\n",
       "  's26',\n",
       "  's27',\n",
       "  's28',\n",
       "  's29',\n",
       "  's30',\n",
       "  's31',\n",
       "  's32'],\n",
       " ['dominance'],\n",
       " ['yes'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data_files=[data_files[0]]\n",
    "data_files,emotions,baseline_preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-08T15:30:05.214315Z",
     "start_time": "2019-11-08T15:30:05.210325Z"
    }
   },
   "outputs": [],
   "source": [
    "def createFolder(directory):\n",
    "    try:\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "    except OSError:\n",
    "        print ('Error: Creating directory. ' +  directory)\n",
    "        \n",
    "\n",
    "# Example\n",
    "createFolder('./data/dd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-07T12:25:32.471751Z",
     "start_time": "2019-11-07T12:25:32.467795Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-07T16:30:44.222471Z",
     "start_time": "2019-11-07T16:30:44.142652Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-08T12:53:08.812148Z",
     "start_time": "2019-11-08T12:53:08.807118Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['s01', 's02', 's03', 's04', 's05']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_files[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-08T12:53:12.139118Z",
     "start_time": "2019-11-08T12:53:12.135139Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['s01', 's02', 's03', 's04', 's05']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_files=data_files[:5]\n",
    "data_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-08T13:23:52.737392Z",
     "start_time": "2019-11-08T12:53:15.220300Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------\n",
      "yes dominance s01\n",
      "---------------------------------------------------\n",
      "\n",
      "loaded shape: (2400,)\n",
      "(2400, 128, 9, 9)\n",
      "(2400, 128, 32)\n",
      "(2400,)\n",
      "(2400, 2)\n",
      "(2400, 128, 9, 9)\n",
      "(2400, 128, 32)\n",
      "(2400, 2)\n",
      "cnn_datasets.shape,rnn_datasets.shape,labels.shape :  (2400, 128, 9, 9) (2400, 128, 32) (2400, 2)\n",
      "(2400, 9, 9, 128)\n",
      "cnn_datasets.shape :  (2400, 9, 9, 128)\n",
      "========================Train / Test Shapes==============================\n",
      "(240, 9, 9, 128) (240, 128, 32) (2160, 9, 9, 128) (2160, 128, 32)\n",
      "================================ DNN ============================================\n",
      "input_cnn:  (None, 9, 9, 128)\n",
      "elu1:  (None, 9, 9, 32)\n",
      "elu2:  (None, 9, 9, 64)\n",
      "elu3:  (None, 9, 9, 128)\n",
      "reshape1:  (None, 9, 9, None)\n",
      "elu4:  (None, 9, 9, 13)\n",
      "reshape2:  (None, 1053)\n",
      "input_rnn (None, 128, 32)\n",
      "rnn_in_flat (None, None, 32)\n",
      "rnn_fc_in (None, 128, 1024)\n",
      "lstm_in (None, None, 1024)\n",
      "lstm_cell (None, 32)\n",
      "output (None, 32)\n",
      "rnn_output (32,)\n",
      "lstm_fc_out (None, 1024)\n",
      "lstm_fc_drop (None, 1024)\n",
      "fuse_cnn_rnn  (None, 2077)\n",
      "(None, 2)\n",
      "y  Tensor(\"dense_3/Softmax:0\", shape=(None, 2), dtype=float32)\n",
      "Model :  yes_dominance_s01_0_fold\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 9, 9, 128)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 9, 9, 32)     65568       input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 9, 9, 32)     128         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "elu_1 (ELU)                     (None, 9, 9, 32)     0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 9, 9, 64)     32832       elu_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 9, 9, 64)     256         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "elu_2 (ELU)                     (None, 9, 9, 64)     0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 9, 9, 128)    131200      elu_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 128, 32)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 9, 9, 128)    512         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_3 (Reshape)             (None, 128, 32)      0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "elu_3 (ELU)                     (None, 9, 9, 128)    0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 128, 1024)    33792       reshape_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 9, 9, 128)    0           elu_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "elu_5 (ELU)                     (None, 128, 1024)    0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 9, 9, 13)     1677        reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_4 (Reshape)             (None, 128, 1024)    0           elu_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 9, 9, 13)     52          conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "rnn_1 (RNN)                     (None, 32)           143616      reshape_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "elu_4 (ELU)                     (None, 9, 9, 13)     0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1024)         33792       rnn_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "reshape_2 (Reshape)             (None, 1053)         0           elu_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 1024)         0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 2077)         0           reshape_2[0][0]                  \n",
      "                                                                 dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 2)            4156        concatenate_1[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 447,581\n",
      "Trainable params: 447,107\n",
      "Non-trainable params: 474\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Train on 1728 samples, validate on 432 samples\n",
      "Epoch 1/50\n",
      " 256/1728 [===>..........................] - ETA: 31s - loss: 0.7276 - accuracy: 0.6406 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ABHISHEK_VERMA\\Anaconda3\\lib\\site-packages\\keras\\callbacks\\callbacks.py:95: RuntimeWarning: Method (on_train_batch_end) is slow compared to the batch update (10.725219). Check your callbacks.\n",
      "  % (hook_name, delta_t_median), RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1728/1728 [==============================] - 30s 17ms/step - loss: 0.2881 - accuracy: 0.8756 - val_loss: 0.1333 - val_accuracy: 0.9630\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.96296, saving model to lightningedge007a_results/yes/dominance/s01/max_acc_yes_dominance_s01.h5\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.13327, saving model to lightningedge007a_results/yes/dominance/s01/min_loss_yes_dominance_s01.h5\n",
      "Epoch 2/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 0.0276 - accuracy: 0.9942 - val_loss: 0.0694 - val_accuracy: 0.9815\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.96296 to 0.98148, saving model to lightningedge007a_results/yes/dominance/s01/max_acc_yes_dominance_s01.h5\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.13327 to 0.06937, saving model to lightningedge007a_results/yes/dominance/s01/min_loss_yes_dominance_s01.h5\n",
      "Epoch 3/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.0460 - val_accuracy: 0.9884\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.98148 to 0.98843, saving model to lightningedge007a_results/yes/dominance/s01/max_acc_yes_dominance_s01.h5\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.06937 to 0.04596, saving model to lightningedge007a_results/yes/dominance/s01/min_loss_yes_dominance_s01.h5\n",
      "Epoch 4/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0311 - val_accuracy: 0.9931\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.98843 to 0.99306, saving model to lightningedge007a_results/yes/dominance/s01/max_acc_yes_dominance_s01.h5\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.04596 to 0.03113, saving model to lightningedge007a_results/yes/dominance/s01/min_loss_yes_dominance_s01.h5\n",
      "Epoch 5/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0248 - val_accuracy: 0.9931\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.99306\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.03113 to 0.02478, saving model to lightningedge007a_results/yes/dominance/s01/min_loss_yes_dominance_s01.h5\n",
      "Epoch 6/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 8.1469e-04 - accuracy: 1.0000 - val_loss: 0.0226 - val_accuracy: 0.9954\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.99306 to 0.99537, saving model to lightningedge007a_results/yes/dominance/s01/max_acc_yes_dominance_s01.h5\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.02478 to 0.02260, saving model to lightningedge007a_results/yes/dominance/s01/min_loss_yes_dominance_s01.h5\n",
      "Epoch 7/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 6.4831e-04 - accuracy: 1.0000 - val_loss: 0.0211 - val_accuracy: 0.9954\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.99537\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.02260 to 0.02108, saving model to lightningedge007a_results/yes/dominance/s01/min_loss_yes_dominance_s01.h5\n",
      "Epoch 8/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 5.3937e-04 - accuracy: 1.0000 - val_loss: 0.0193 - val_accuracy: 0.9954\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.99537\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.02108 to 0.01931, saving model to lightningedge007a_results/yes/dominance/s01/min_loss_yes_dominance_s01.h5\n",
      "Epoch 9/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 4.6648e-04 - accuracy: 1.0000 - val_loss: 0.0174 - val_accuracy: 0.9977\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.99537 to 0.99769, saving model to lightningedge007a_results/yes/dominance/s01/max_acc_yes_dominance_s01.h5\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.01931 to 0.01739, saving model to lightningedge007a_results/yes/dominance/s01/min_loss_yes_dominance_s01.h5\n",
      "Epoch 10/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 4.1777e-04 - accuracy: 1.0000 - val_loss: 0.0157 - val_accuracy: 0.9977\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.99769\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.01739 to 0.01574, saving model to lightningedge007a_results/yes/dominance/s01/min_loss_yes_dominance_s01.h5\n",
      "Epoch 11/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 3.6995e-04 - accuracy: 1.0000 - val_loss: 0.0145 - val_accuracy: 0.9977\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.99769\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.01574 to 0.01455, saving model to lightningedge007a_results/yes/dominance/s01/min_loss_yes_dominance_s01.h5\n",
      "Epoch 12/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 3.2807e-04 - accuracy: 1.0000 - val_loss: 0.0135 - val_accuracy: 0.9977\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.99769\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.01455 to 0.01354, saving model to lightningedge007a_results/yes/dominance/s01/min_loss_yes_dominance_s01.h5\n",
      "Epoch 13/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 2.9109e-04 - accuracy: 1.0000 - val_loss: 0.0127 - val_accuracy: 0.9977\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.99769\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.01354 to 0.01270, saving model to lightningedge007a_results/yes/dominance/s01/min_loss_yes_dominance_s01.h5\n",
      "Epoch 14/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 2.7227e-04 - accuracy: 1.0000 - val_loss: 0.0119 - val_accuracy: 0.9977\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.99769\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.01270 to 0.01192, saving model to lightningedge007a_results/yes/dominance/s01/min_loss_yes_dominance_s01.h5\n",
      "Epoch 15/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 2.4573e-04 - accuracy: 1.0000 - val_loss: 0.0111 - val_accuracy: 0.9977\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.99769\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.01192 to 0.01110, saving model to lightningedge007a_results/yes/dominance/s01/min_loss_yes_dominance_s01.h5\n",
      "Epoch 16/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 2.2325e-04 - accuracy: 1.0000 - val_loss: 0.0104 - val_accuracy: 0.9977\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.99769\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.01110 to 0.01035, saving model to lightningedge007a_results/yes/dominance/s01/min_loss_yes_dominance_s01.h5\n",
      "Epoch 17/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 2.0684e-04 - accuracy: 1.0000 - val_loss: 0.0098 - val_accuracy: 0.9977\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.99769\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.01035 to 0.00982, saving model to lightningedge007a_results/yes/dominance/s01/min_loss_yes_dominance_s01.h5\n",
      "Epoch 18/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.9153e-04 - accuracy: 1.0000 - val_loss: 0.0094 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00018: val_accuracy improved from 0.99769 to 1.00000, saving model to lightningedge007a_results/yes/dominance/s01/max_acc_yes_dominance_s01.h5\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.00982 to 0.00940, saving model to lightningedge007a_results/yes/dominance/s01/min_loss_yes_dominance_s01.h5\n",
      "Epoch 19/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.7470e-04 - accuracy: 1.0000 - val_loss: 0.0090 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 1.00000\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.00940 to 0.00897, saving model to lightningedge007a_results/yes/dominance/s01/min_loss_yes_dominance_s01.h5\n",
      "Epoch 20/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.6660e-04 - accuracy: 1.0000 - val_loss: 0.0085 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 1.00000\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.00897 to 0.00855, saving model to lightningedge007a_results/yes/dominance/s01/min_loss_yes_dominance_s01.h5\n",
      "Epoch 21/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.5246e-04 - accuracy: 1.0000 - val_loss: 0.0082 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 1.00000\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.00855 to 0.00820, saving model to lightningedge007a_results/yes/dominance/s01/min_loss_yes_dominance_s01.h5\n",
      "Epoch 22/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.4750e-04 - accuracy: 1.0000 - val_loss: 0.0079 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 1.00000\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.00820 to 0.00788, saving model to lightningedge007a_results/yes/dominance/s01/min_loss_yes_dominance_s01.h5\n",
      "Epoch 23/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.3362e-04 - accuracy: 1.0000 - val_loss: 0.0076 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 1.00000\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.00788 to 0.00761, saving model to lightningedge007a_results/yes/dominance/s01/min_loss_yes_dominance_s01.h5\n",
      "Epoch 24/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.2587e-04 - accuracy: 1.0000 - val_loss: 0.0074 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 1.00000\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.00761 to 0.00738, saving model to lightningedge007a_results/yes/dominance/s01/min_loss_yes_dominance_s01.h5\n",
      "Epoch 25/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.1727e-04 - accuracy: 1.0000 - val_loss: 0.0072 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 1.00000\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.00738 to 0.00717, saving model to lightningedge007a_results/yes/dominance/s01/min_loss_yes_dominance_s01.h5\n",
      "Epoch 26/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.1399e-04 - accuracy: 1.0000 - val_loss: 0.0071 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 1.00000\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.00717 to 0.00706, saving model to lightningedge007a_results/yes/dominance/s01/min_loss_yes_dominance_s01.h5\n",
      "Epoch 27/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.0501e-04 - accuracy: 1.0000 - val_loss: 0.0068 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 1.00000\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.00706 to 0.00682, saving model to lightningedge007a_results/yes/dominance/s01/min_loss_yes_dominance_s01.h5\n",
      "Epoch 28/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 9.9670e-05 - accuracy: 1.0000 - val_loss: 0.0066 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 1.00000\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.00682 to 0.00658, saving model to lightningedge007a_results/yes/dominance/s01/min_loss_yes_dominance_s01.h5\n",
      "Epoch 29/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 9.2884e-05 - accuracy: 1.0000 - val_loss: 0.0065 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 1.00000\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.00658 to 0.00646, saving model to lightningedge007a_results/yes/dominance/s01/min_loss_yes_dominance_s01.h5\n",
      "Epoch 30/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 8.7530e-05 - accuracy: 1.0000 - val_loss: 0.0063 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 1.00000\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.00646 to 0.00632, saving model to lightningedge007a_results/yes/dominance/s01/min_loss_yes_dominance_s01.h5\n",
      "Epoch 31/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 8.4065e-05 - accuracy: 1.0000 - val_loss: 0.0062 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 1.00000\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.00632 to 0.00621, saving model to lightningedge007a_results/yes/dominance/s01/min_loss_yes_dominance_s01.h5\n",
      "Epoch 32/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 7.9215e-05 - accuracy: 1.0000 - val_loss: 0.0061 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 1.00000\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.00621 to 0.00609, saving model to lightningedge007a_results/yes/dominance/s01/min_loss_yes_dominance_s01.h5\n",
      "Epoch 33/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 7.7539e-05 - accuracy: 1.0000 - val_loss: 0.0060 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 1.00000\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.00609 to 0.00600, saving model to lightningedge007a_results/yes/dominance/s01/min_loss_yes_dominance_s01.h5\n",
      "Epoch 34/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 7.6254e-05 - accuracy: 1.0000 - val_loss: 0.0059 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 1.00000\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.00600 to 0.00589, saving model to lightningedge007a_results/yes/dominance/s01/min_loss_yes_dominance_s01.h5\n",
      "Epoch 35/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 6.8326e-05 - accuracy: 1.0000 - val_loss: 0.0058 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 1.00000\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.00589 to 0.00581, saving model to lightningedge007a_results/yes/dominance/s01/min_loss_yes_dominance_s01.h5\n",
      "Epoch 36/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 6.5941e-05 - accuracy: 1.0000 - val_loss: 0.0057 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 1.00000\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.00581 to 0.00572, saving model to lightningedge007a_results/yes/dominance/s01/min_loss_yes_dominance_s01.h5\n",
      "Epoch 37/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 6.3777e-05 - accuracy: 1.0000 - val_loss: 0.0057 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 1.00000\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.00572 to 0.00566, saving model to lightningedge007a_results/yes/dominance/s01/min_loss_yes_dominance_s01.h5\n",
      "Epoch 38/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 6.0935e-05 - accuracy: 1.0000 - val_loss: 0.0056 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 1.00000\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.00566 to 0.00560, saving model to lightningedge007a_results/yes/dominance/s01/min_loss_yes_dominance_s01.h5\n",
      "Epoch 39/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 5.7222e-05 - accuracy: 1.0000 - val_loss: 0.0055 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 1.00000\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.00560 to 0.00552, saving model to lightningedge007a_results/yes/dominance/s01/min_loss_yes_dominance_s01.h5\n",
      "Epoch 40/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 5.5762e-05 - accuracy: 1.0000 - val_loss: 0.0055 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 1.00000\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.00552 to 0.00546, saving model to lightningedge007a_results/yes/dominance/s01/min_loss_yes_dominance_s01.h5\n",
      "Epoch 41/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 5.2903e-05 - accuracy: 1.0000 - val_loss: 0.0053 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 1.00000\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.00546 to 0.00534, saving model to lightningedge007a_results/yes/dominance/s01/min_loss_yes_dominance_s01.h5\n",
      "Epoch 42/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 5.0234e-05 - accuracy: 1.0000 - val_loss: 0.0052 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 1.00000\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.00534 to 0.00523, saving model to lightningedge007a_results/yes/dominance/s01/min_loss_yes_dominance_s01.h5\n",
      "Epoch 43/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 4.8796e-05 - accuracy: 1.0000 - val_loss: 0.0052 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 1.00000\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.00523 to 0.00519, saving model to lightningedge007a_results/yes/dominance/s01/min_loss_yes_dominance_s01.h5\n",
      "Epoch 44/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 4.8254e-05 - accuracy: 1.0000 - val_loss: 0.0051 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 1.00000\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.00519 to 0.00507, saving model to lightningedge007a_results/yes/dominance/s01/min_loss_yes_dominance_s01.h5\n",
      "Epoch 45/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 4.5684e-05 - accuracy: 1.0000 - val_loss: 0.0050 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 1.00000\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.00507 to 0.00499, saving model to lightningedge007a_results/yes/dominance/s01/min_loss_yes_dominance_s01.h5\n",
      "Epoch 46/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 4.4865e-05 - accuracy: 1.0000 - val_loss: 0.0050 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00046: val_accuracy did not improve from 1.00000\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.00499 to 0.00496, saving model to lightningedge007a_results/yes/dominance/s01/min_loss_yes_dominance_s01.h5\n",
      "Epoch 47/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 4.2927e-05 - accuracy: 1.0000 - val_loss: 0.0049 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 1.00000\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.00496 to 0.00490, saving model to lightningedge007a_results/yes/dominance/s01/min_loss_yes_dominance_s01.h5\n",
      "Epoch 48/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 4.2023e-05 - accuracy: 1.0000 - val_loss: 0.0049 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 1.00000\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.00490 to 0.00488, saving model to lightningedge007a_results/yes/dominance/s01/min_loss_yes_dominance_s01.h5\n",
      "Epoch 49/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 4.0703e-05 - accuracy: 1.0000 - val_loss: 0.0048 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 1.00000\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.00488 to 0.00483, saving model to lightningedge007a_results/yes/dominance/s01/min_loss_yes_dominance_s01.h5\n",
      "Epoch 50/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 3.8356e-05 - accuracy: 1.0000 - val_loss: 0.0048 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 1.00000\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.00483 to 0.00476, saving model to lightningedge007a_results/yes/dominance/s01/min_loss_yes_dominance_s01.h5\n",
      "240/240 [==============================] - 1s 4ms/step\n",
      "max acc:  [0.006265728843087951, 1.0]\n",
      "240/240 [==============================] - 1s 3ms/step\n",
      "min loss:  [0.0032673189726968605, 1.0]\n",
      "---------------------------------------------------\n",
      "yes dominance s02\n",
      "---------------------------------------------------\n",
      "\n",
      "loaded shape: (2400,)\n",
      "(2400, 128, 9, 9)\n",
      "(2400, 128, 32)\n",
      "(2400,)\n",
      "(2400, 2)\n",
      "(2400, 128, 9, 9)\n",
      "(2400, 128, 32)\n",
      "(2400, 2)\n",
      "cnn_datasets.shape,rnn_datasets.shape,labels.shape :  (2400, 128, 9, 9) (2400, 128, 32) (2400, 2)\n",
      "(2400, 9, 9, 128)\n",
      "cnn_datasets.shape :  (2400, 9, 9, 128)\n",
      "========================Train / Test Shapes==============================\n",
      "(240, 9, 9, 128) (240, 128, 32) (2160, 9, 9, 128) (2160, 128, 32)\n",
      "================================ DNN ============================================\n",
      "input_cnn:  (None, 9, 9, 128)\n",
      "elu1:  (None, 9, 9, 32)\n",
      "elu2:  (None, 9, 9, 64)\n",
      "elu3:  (None, 9, 9, 128)\n",
      "reshape1:  (None, 9, 9, None)\n",
      "elu4:  (None, 9, 9, 13)\n",
      "reshape2:  (None, 1053)\n",
      "input_rnn (None, 128, 32)\n",
      "rnn_in_flat (None, None, 32)\n",
      "rnn_fc_in (None, 128, 1024)\n",
      "lstm_in (None, None, 1024)\n",
      "lstm_cell (None, 32)\n",
      "output (None, 32)\n",
      "rnn_output (32,)\n",
      "lstm_fc_out (None, 1024)\n",
      "lstm_fc_drop (None, 1024)\n",
      "fuse_cnn_rnn  (None, 2077)\n",
      "(None, 2)\n",
      "y  Tensor(\"dense_6/Softmax:0\", shape=(None, 2), dtype=float32)\n",
      "Model :  yes_dominance_s02_0_fold\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 9, 9, 128)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 9, 9, 32)     65568       input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 9, 9, 32)     128         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "elu_6 (ELU)                     (None, 9, 9, 32)     0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 9, 9, 64)     32832       elu_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 9, 9, 64)     256         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "elu_7 (ELU)                     (None, 9, 9, 64)     0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 9, 9, 128)    131200      elu_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            (None, 128, 32)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 9, 9, 128)    512         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_7 (Reshape)             (None, 128, 32)      0           input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "elu_8 (ELU)                     (None, 9, 9, 128)    0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 128, 1024)    33792       reshape_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_5 (Reshape)             (None, 9, 9, 128)    0           elu_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "elu_10 (ELU)                    (None, 128, 1024)    0           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 9, 9, 13)     1677        reshape_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_8 (Reshape)             (None, 128, 1024)    0           elu_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 9, 9, 13)     52          conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "rnn_2 (RNN)                     (None, 32)           143616      reshape_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "elu_9 (ELU)                     (None, 9, 9, 13)     0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 1024)         33792       rnn_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "reshape_6 (Reshape)             (None, 1053)         0           elu_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 1024)         0           dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 2077)         0           reshape_6[0][0]                  \n",
      "                                                                 dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 2)            4156        concatenate_2[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 447,581\n",
      "Trainable params: 447,107\n",
      "Non-trainable params: 474\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1728 samples, validate on 432 samples\n",
      "Epoch 1/50\n",
      " 256/1728 [===>..........................] - ETA: 10s - loss: 1.0684 - accuracy: 0.5898"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ABHISHEK_VERMA\\Anaconda3\\lib\\site-packages\\keras\\callbacks\\callbacks.py:95: RuntimeWarning: Method (on_train_batch_end) is slow compared to the batch update (9.924531). Check your callbacks.\n",
      "  % (hook_name, delta_t_median), RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1728/1728 [==============================] - 24s 14ms/step - loss: 0.6670 - accuracy: 0.7633 - val_loss: 0.3603 - val_accuracy: 0.8542\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.85417, saving model to lightningedge007a_results/yes/dominance/s02/max_acc_yes_dominance_s02.h5\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.36030, saving model to lightningedge007a_results/yes/dominance/s02/min_loss_yes_dominance_s02.h5\n",
      "Epoch 2/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 0.2026 - accuracy: 0.9242 - val_loss: 0.2945 - val_accuracy: 0.8727\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.85417 to 0.87269, saving model to lightningedge007a_results/yes/dominance/s02/max_acc_yes_dominance_s02.h5\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.36030 to 0.29451, saving model to lightningedge007a_results/yes/dominance/s02/min_loss_yes_dominance_s02.h5\n",
      "Epoch 3/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 0.1148 - accuracy: 0.9612 - val_loss: 0.2304 - val_accuracy: 0.9097\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.87269 to 0.90972, saving model to lightningedge007a_results/yes/dominance/s02/max_acc_yes_dominance_s02.h5\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.29451 to 0.23040, saving model to lightningedge007a_results/yes/dominance/s02/min_loss_yes_dominance_s02.h5\n",
      "Epoch 4/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 0.0728 - accuracy: 0.9745 - val_loss: 0.2234 - val_accuracy: 0.9074\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.90972\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.23040 to 0.22341, saving model to lightningedge007a_results/yes/dominance/s02/min_loss_yes_dominance_s02.h5\n",
      "Epoch 5/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 0.0438 - accuracy: 0.9907 - val_loss: 0.2057 - val_accuracy: 0.9259\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.90972 to 0.92593, saving model to lightningedge007a_results/yes/dominance/s02/max_acc_yes_dominance_s02.h5\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.22341 to 0.20566, saving model to lightningedge007a_results/yes/dominance/s02/min_loss_yes_dominance_s02.h5\n",
      "Epoch 6/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 0.0315 - accuracy: 0.9913 - val_loss: 0.2298 - val_accuracy: 0.9028\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.92593\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.20566\n",
      "Epoch 7/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 0.0224 - accuracy: 0.9948 - val_loss: 0.2001 - val_accuracy: 0.9167\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.92593\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.20566 to 0.20006, saving model to lightningedge007a_results/yes/dominance/s02/min_loss_yes_dominance_s02.h5\n",
      "Epoch 8/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 0.0151 - accuracy: 0.9977 - val_loss: 0.1802 - val_accuracy: 0.9213\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.92593\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.20006 to 0.18019, saving model to lightningedge007a_results/yes/dominance/s02/min_loss_yes_dominance_s02.h5\n",
      "Epoch 9/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.1690 - val_accuracy: 0.9375\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.92593 to 0.93750, saving model to lightningedge007a_results/yes/dominance/s02/max_acc_yes_dominance_s02.h5\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.18019 to 0.16903, saving model to lightningedge007a_results/yes/dominance/s02/min_loss_yes_dominance_s02.h5\n",
      "Epoch 10/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.1736 - val_accuracy: 0.9306\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.93750\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.16903\n",
      "Epoch 11/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.1660 - val_accuracy: 0.9421\n",
      "\n",
      "Epoch 00011: val_accuracy improved from 0.93750 to 0.94213, saving model to lightningedge007a_results/yes/dominance/s02/max_acc_yes_dominance_s02.h5\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.16903 to 0.16598, saving model to lightningedge007a_results/yes/dominance/s02/min_loss_yes_dominance_s02.h5\n",
      "Epoch 12/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.1745 - val_accuracy: 0.9398\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.94213\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.16598\n",
      "Epoch 13/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.1697 - val_accuracy: 0.9398\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.94213\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.16598\n",
      "Epoch 14/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.1819 - val_accuracy: 0.9352\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.94213\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.16598\n",
      "Epoch 15/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.1771 - val_accuracy: 0.9444\n",
      "\n",
      "Epoch 00015: val_accuracy improved from 0.94213 to 0.94444, saving model to lightningedge007a_results/yes/dominance/s02/max_acc_yes_dominance_s02.h5\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.16598\n",
      "Epoch 16/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.1820 - val_accuracy: 0.9421\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.94444\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.16598\n",
      "Epoch 17/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 9.6293e-04 - accuracy: 1.0000 - val_loss: 0.1810 - val_accuracy: 0.9421\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.94444\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.16598\n",
      "Epoch 18/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 8.8034e-04 - accuracy: 1.0000 - val_loss: 0.1864 - val_accuracy: 0.9444\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.94444\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.16598\n",
      "Epoch 19/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 7.9414e-04 - accuracy: 1.0000 - val_loss: 0.1876 - val_accuracy: 0.9421\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.94444\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.16598\n",
      "Epoch 20/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 7.1843e-04 - accuracy: 1.0000 - val_loss: 0.1886 - val_accuracy: 0.9468\n",
      "\n",
      "Epoch 00020: val_accuracy improved from 0.94444 to 0.94676, saving model to lightningedge007a_results/yes/dominance/s02/max_acc_yes_dominance_s02.h5\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.16598\n",
      "Epoch 21/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 6.6602e-04 - accuracy: 1.0000 - val_loss: 0.1946 - val_accuracy: 0.9444\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.94676\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.16598\n",
      "Epoch 22/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 6.0844e-04 - accuracy: 1.0000 - val_loss: 0.1931 - val_accuracy: 0.9468\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.94676\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.16598\n",
      "Epoch 23/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 5.6526e-04 - accuracy: 1.0000 - val_loss: 0.1939 - val_accuracy: 0.9444\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.94676\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.16598\n",
      "Epoch 24/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 5.2218e-04 - accuracy: 1.0000 - val_loss: 0.1993 - val_accuracy: 0.9398\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.94676\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.16598\n",
      "Epoch 25/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 4.8345e-04 - accuracy: 1.0000 - val_loss: 0.1974 - val_accuracy: 0.9421\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.94676\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.16598\n",
      "Epoch 26/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 4.5458e-04 - accuracy: 1.0000 - val_loss: 0.2013 - val_accuracy: 0.9444\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.94676\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.16598\n",
      "Epoch 27/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1728/1728 [==============================] - 3s 2ms/step - loss: 4.2688e-04 - accuracy: 1.0000 - val_loss: 0.2047 - val_accuracy: 0.9398\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.94676\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.16598\n",
      "Epoch 28/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 3.9824e-04 - accuracy: 1.0000 - val_loss: 0.2035 - val_accuracy: 0.9421\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.94676\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.16598\n",
      "Epoch 29/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 3.7193e-04 - accuracy: 1.0000 - val_loss: 0.2062 - val_accuracy: 0.9421\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.94676\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.16598\n",
      "Epoch 30/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 3.5134e-04 - accuracy: 1.0000 - val_loss: 0.2060 - val_accuracy: 0.9444\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.94676\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.16598\n",
      "Epoch 31/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 3.2899e-04 - accuracy: 1.0000 - val_loss: 0.2099 - val_accuracy: 0.9398\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.94676\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.16598\n",
      "Epoch 32/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 3.1309e-04 - accuracy: 1.0000 - val_loss: 0.2106 - val_accuracy: 0.9398\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.94676\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.16598\n",
      "Epoch 33/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 2.9389e-04 - accuracy: 1.0000 - val_loss: 0.2114 - val_accuracy: 0.9398\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.94676\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.16598\n",
      "Epoch 34/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 2.7984e-04 - accuracy: 1.0000 - val_loss: 0.2121 - val_accuracy: 0.9398\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.94676\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.16598\n",
      "Epoch 35/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 2.6488e-04 - accuracy: 1.0000 - val_loss: 0.2137 - val_accuracy: 0.9398\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.94676\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.16598\n",
      "Epoch 36/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 2.5275e-04 - accuracy: 1.0000 - val_loss: 0.2144 - val_accuracy: 0.9398\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.94676\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.16598\n",
      "Epoch 37/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 2.4126e-04 - accuracy: 1.0000 - val_loss: 0.2144 - val_accuracy: 0.9398\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.94676\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.16598\n",
      "Epoch 38/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 2.2801e-04 - accuracy: 1.0000 - val_loss: 0.2150 - val_accuracy: 0.9421\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.94676\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.16598\n",
      "Epoch 39/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 2.1458e-04 - accuracy: 1.0000 - val_loss: 0.2183 - val_accuracy: 0.9398\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.94676\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.16598\n",
      "Epoch 40/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 2.0633e-04 - accuracy: 1.0000 - val_loss: 0.2171 - val_accuracy: 0.9421\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.94676\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.16598\n",
      "Epoch 41/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.9813e-04 - accuracy: 1.0000 - val_loss: 0.2191 - val_accuracy: 0.9398\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.94676\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.16598\n",
      "Epoch 42/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.8922e-04 - accuracy: 1.0000 - val_loss: 0.2196 - val_accuracy: 0.9398\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.94676\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.16598\n",
      "Epoch 43/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.8282e-04 - accuracy: 1.0000 - val_loss: 0.2208 - val_accuracy: 0.9398\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.94676\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.16598\n",
      "Epoch 44/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.7528e-04 - accuracy: 1.0000 - val_loss: 0.2234 - val_accuracy: 0.9352\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.94676\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.16598\n",
      "Epoch 45/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.6706e-04 - accuracy: 1.0000 - val_loss: 0.2208 - val_accuracy: 0.9398\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.94676\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.16598\n",
      "Epoch 46/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.5973e-04 - accuracy: 1.0000 - val_loss: 0.2247 - val_accuracy: 0.9398\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.94676\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.16598\n",
      "Epoch 47/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.5400e-04 - accuracy: 1.0000 - val_loss: 0.2231 - val_accuracy: 0.9398\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.94676\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.16598\n",
      "Epoch 48/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.4805e-04 - accuracy: 1.0000 - val_loss: 0.2244 - val_accuracy: 0.9398\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.94676\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.16598\n",
      "Epoch 49/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.4225e-04 - accuracy: 1.0000 - val_loss: 0.2237 - val_accuracy: 0.9398\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.94676\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.16598\n",
      "Epoch 50/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.3691e-04 - accuracy: 1.0000 - val_loss: 0.2260 - val_accuracy: 0.9375\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.94676\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.16598\n",
      "240/240 [==============================] - 1s 3ms/step\n",
      "max acc:  [0.14296648219848673, 0.9458333253860474]\n",
      "240/240 [==============================] - 1s 3ms/step\n",
      "min loss:  [0.13654363453388213, 0.9416666626930237]\n",
      "---------------------------------------------------\n",
      "yes dominance s03\n",
      "---------------------------------------------------\n",
      "\n",
      "loaded shape: (2400,)\n",
      "(2400, 128, 9, 9)\n",
      "(2400, 128, 32)\n",
      "(2400,)\n",
      "(2400, 2)\n",
      "(2400, 128, 9, 9)\n",
      "(2400, 128, 32)\n",
      "(2400, 2)\n",
      "cnn_datasets.shape,rnn_datasets.shape,labels.shape :  (2400, 128, 9, 9) (2400, 128, 32) (2400, 2)\n",
      "(2400, 9, 9, 128)\n",
      "cnn_datasets.shape :  (2400, 9, 9, 128)\n",
      "========================Train / Test Shapes==============================\n",
      "(240, 9, 9, 128) (240, 128, 32) (2160, 9, 9, 128) (2160, 128, 32)\n",
      "================================ DNN ============================================\n",
      "input_cnn:  (None, 9, 9, 128)\n",
      "elu1:  (None, 9, 9, 32)\n",
      "elu2:  (None, 9, 9, 64)\n",
      "elu3:  (None, 9, 9, 128)\n",
      "reshape1:  (None, 9, 9, None)\n",
      "elu4:  (None, 9, 9, 13)\n",
      "reshape2:  (None, 1053)\n",
      "input_rnn (None, 128, 32)\n",
      "rnn_in_flat (None, None, 32)\n",
      "rnn_fc_in (None, 128, 1024)\n",
      "lstm_in (None, None, 1024)\n",
      "lstm_cell (None, 32)\n",
      "output (None, 32)\n",
      "rnn_output (32,)\n",
      "lstm_fc_out (None, 1024)\n",
      "lstm_fc_drop (None, 1024)\n",
      "fuse_cnn_rnn  (None, 2077)\n",
      "(None, 2)\n",
      "y  Tensor(\"dense_9/Softmax:0\", shape=(None, 2), dtype=float32)\n",
      "Model :  yes_dominance_s03_0_fold\n",
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            (None, 9, 9, 128)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 9, 9, 32)     65568       input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 9, 9, 32)     128         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "elu_11 (ELU)                    (None, 9, 9, 32)     0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 9, 9, 64)     32832       elu_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 9, 9, 64)     256         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "elu_12 (ELU)                    (None, 9, 9, 64)     0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 9, 9, 128)    131200      elu_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "input_6 (InputLayer)            (None, 128, 32)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 9, 9, 128)    512         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_11 (Reshape)            (None, 128, 32)      0           input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "elu_13 (ELU)                    (None, 9, 9, 128)    0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 128, 1024)    33792       reshape_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_9 (Reshape)             (None, 9, 9, 128)    0           elu_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "elu_15 (ELU)                    (None, 128, 1024)    0           dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 9, 9, 13)     1677        reshape_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_12 (Reshape)            (None, 128, 1024)    0           elu_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 9, 9, 13)     52          conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "rnn_3 (RNN)                     (None, 32)           143616      reshape_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "elu_14 (ELU)                    (None, 9, 9, 13)     0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 1024)         33792       rnn_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "reshape_10 (Reshape)            (None, 1053)         0           elu_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 1024)         0           dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 2077)         0           reshape_10[0][0]                 \n",
      "                                                                 dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 2)            4156        concatenate_3[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 447,581\n",
      "Trainable params: 447,107\n",
      "Non-trainable params: 474\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1728 samples, validate on 432 samples\n",
      "Epoch 1/50\n",
      " 256/1728 [===>..........................] - ETA: 11s - loss: 0.8710 - accuracy: 0.6211"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ABHISHEK_VERMA\\Anaconda3\\lib\\site-packages\\keras\\callbacks\\callbacks.py:95: RuntimeWarning: Method (on_train_batch_end) is slow compared to the batch update (10.480031). Check your callbacks.\n",
      "  % (hook_name, delta_t_median), RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1728/1728 [==============================] - 26s 15ms/step - loss: 0.4168 - accuracy: 0.8310 - val_loss: 0.2007 - val_accuracy: 0.9352\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.93519, saving model to lightningedge007a_results/yes/dominance/s03/max_acc_yes_dominance_s03.h5\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.20073, saving model to lightningedge007a_results/yes/dominance/s03/min_loss_yes_dominance_s03.h5\n",
      "Epoch 2/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 0.0874 - accuracy: 0.9728 - val_loss: 0.1467 - val_accuracy: 0.9537\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.93519 to 0.95370, saving model to lightningedge007a_results/yes/dominance/s03/max_acc_yes_dominance_s03.h5\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.20073 to 0.14669, saving model to lightningedge007a_results/yes/dominance/s03/min_loss_yes_dominance_s03.h5\n",
      "Epoch 3/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 0.0331 - accuracy: 0.9913 - val_loss: 0.0815 - val_accuracy: 0.9745\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.95370 to 0.97454, saving model to lightningedge007a_results/yes/dominance/s03/max_acc_yes_dominance_s03.h5\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.14669 to 0.08148, saving model to lightningedge007a_results/yes/dominance/s03/min_loss_yes_dominance_s03.h5\n",
      "Epoch 4/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 0.0173 - accuracy: 0.9959 - val_loss: 0.0658 - val_accuracy: 0.9861\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.97454 to 0.98611, saving model to lightningedge007a_results/yes/dominance/s03/max_acc_yes_dominance_s03.h5\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.08148 to 0.06576, saving model to lightningedge007a_results/yes/dominance/s03/min_loss_yes_dominance_s03.h5\n",
      "Epoch 5/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 0.0073 - accuracy: 0.9994 - val_loss: 0.0623 - val_accuracy: 0.9884\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.98611 to 0.98843, saving model to lightningedge007a_results/yes/dominance/s03/max_acc_yes_dominance_s03.h5\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.06576 to 0.06231, saving model to lightningedge007a_results/yes/dominance/s03/min_loss_yes_dominance_s03.h5\n",
      "Epoch 6/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.0582 - val_accuracy: 0.9838\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.98843\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.06231 to 0.05820, saving model to lightningedge007a_results/yes/dominance/s03/min_loss_yes_dominance_s03.h5\n",
      "Epoch 7/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.0544 - val_accuracy: 0.9815\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.98843\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.05820 to 0.05437, saving model to lightningedge007a_results/yes/dominance/s03/min_loss_yes_dominance_s03.h5\n",
      "Epoch 8/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0532 - val_accuracy: 0.9838\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.98843\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.05437 to 0.05317, saving model to lightningedge007a_results/yes/dominance/s03/min_loss_yes_dominance_s03.h5\n",
      "Epoch 9/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0501 - val_accuracy: 0.9861\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.98843\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.05317 to 0.05014, saving model to lightningedge007a_results/yes/dominance/s03/min_loss_yes_dominance_s03.h5\n",
      "Epoch 10/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0481 - val_accuracy: 0.9861\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.98843\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.05014 to 0.04811, saving model to lightningedge007a_results/yes/dominance/s03/min_loss_yes_dominance_s03.h5\n",
      "Epoch 11/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0483 - val_accuracy: 0.9861\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.98843\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.04811\n",
      "Epoch 12/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 9.6791e-04 - accuracy: 1.0000 - val_loss: 0.0472 - val_accuracy: 0.9861\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.98843\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.04811 to 0.04724, saving model to lightningedge007a_results/yes/dominance/s03/min_loss_yes_dominance_s03.h5\n",
      "Epoch 13/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 8.4425e-04 - accuracy: 1.0000 - val_loss: 0.0469 - val_accuracy: 0.9861\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.98843\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.04724 to 0.04694, saving model to lightningedge007a_results/yes/dominance/s03/min_loss_yes_dominance_s03.h5\n",
      "Epoch 14/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 7.3602e-04 - accuracy: 1.0000 - val_loss: 0.0461 - val_accuracy: 0.9861\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.98843\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.04694 to 0.04612, saving model to lightningedge007a_results/yes/dominance/s03/min_loss_yes_dominance_s03.h5\n",
      "Epoch 15/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 6.6440e-04 - accuracy: 1.0000 - val_loss: 0.0463 - val_accuracy: 0.9861\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.98843\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.04612\n",
      "Epoch 16/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 5.9693e-04 - accuracy: 1.0000 - val_loss: 0.0467 - val_accuracy: 0.9861\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.98843\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.04612\n",
      "Epoch 17/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 5.4037e-04 - accuracy: 1.0000 - val_loss: 0.0457 - val_accuracy: 0.9838\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.98843\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.04612 to 0.04569, saving model to lightningedge007a_results/yes/dominance/s03/min_loss_yes_dominance_s03.h5\n",
      "Epoch 18/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 4.7825e-04 - accuracy: 1.0000 - val_loss: 0.0455 - val_accuracy: 0.9861\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.98843\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.04569 to 0.04555, saving model to lightningedge007a_results/yes/dominance/s03/min_loss_yes_dominance_s03.h5\n",
      "Epoch 19/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 4.4571e-04 - accuracy: 1.0000 - val_loss: 0.0458 - val_accuracy: 0.9861\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.98843\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.04555\n",
      "Epoch 20/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 3.9774e-04 - accuracy: 1.0000 - val_loss: 0.0454 - val_accuracy: 0.9838\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.98843\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.04555 to 0.04536, saving model to lightningedge007a_results/yes/dominance/s03/min_loss_yes_dominance_s03.h5\n",
      "Epoch 21/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 3.6605e-04 - accuracy: 1.0000 - val_loss: 0.0457 - val_accuracy: 0.9838\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.98843\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.04536\n",
      "Epoch 22/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 3.3366e-04 - accuracy: 1.0000 - val_loss: 0.0454 - val_accuracy: 0.9838\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.98843\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.04536\n",
      "Epoch 23/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 3.2088e-04 - accuracy: 1.0000 - val_loss: 0.0458 - val_accuracy: 0.9838\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.98843\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.04536\n",
      "Epoch 24/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 2.8826e-04 - accuracy: 1.0000 - val_loss: 0.0457 - val_accuracy: 0.9838\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.98843\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.04536\n",
      "Epoch 25/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 2.7630e-04 - accuracy: 1.0000 - val_loss: 0.0456 - val_accuracy: 0.9838\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.98843\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.04536\n",
      "Epoch 26/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 2.5085e-04 - accuracy: 1.0000 - val_loss: 0.0457 - val_accuracy: 0.9838\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.98843\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.04536\n",
      "Epoch 27/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 2.3995e-04 - accuracy: 1.0000 - val_loss: 0.0455 - val_accuracy: 0.9838\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.98843\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.04536\n",
      "Epoch 28/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 2.2514e-04 - accuracy: 1.0000 - val_loss: 0.0454 - val_accuracy: 0.9838\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.98843\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.04536\n",
      "Epoch 29/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 2.1068e-04 - accuracy: 1.0000 - val_loss: 0.0457 - val_accuracy: 0.9838\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.98843\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.04536\n",
      "Epoch 30/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.9937e-04 - accuracy: 1.0000 - val_loss: 0.0456 - val_accuracy: 0.9838\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.98843\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.04536\n",
      "Epoch 31/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.8909e-04 - accuracy: 1.0000 - val_loss: 0.0459 - val_accuracy: 0.9838\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.98843\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.04536\n",
      "Epoch 32/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.7970e-04 - accuracy: 1.0000 - val_loss: 0.0461 - val_accuracy: 0.9838\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.98843\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.04536\n",
      "Epoch 33/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.6791e-04 - accuracy: 1.0000 - val_loss: 0.0460 - val_accuracy: 0.9838\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.98843\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.04536\n",
      "Epoch 34/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.5977e-04 - accuracy: 1.0000 - val_loss: 0.0458 - val_accuracy: 0.9838\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.98843\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.04536\n",
      "Epoch 35/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.5318e-04 - accuracy: 1.0000 - val_loss: 0.0458 - val_accuracy: 0.9838\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.98843\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.04536\n",
      "Epoch 36/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.4240e-04 - accuracy: 1.0000 - val_loss: 0.0460 - val_accuracy: 0.9838\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.98843\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.04536\n",
      "Epoch 37/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.3767e-04 - accuracy: 1.0000 - val_loss: 0.0459 - val_accuracy: 0.9838\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.98843\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.04536\n",
      "Epoch 38/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.3218e-04 - accuracy: 1.0000 - val_loss: 0.0461 - val_accuracy: 0.9838\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.98843\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.04536\n",
      "Epoch 39/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.2535e-04 - accuracy: 1.0000 - val_loss: 0.0459 - val_accuracy: 0.9861\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.98843\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.04536\n",
      "Epoch 40/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.1814e-04 - accuracy: 1.0000 - val_loss: 0.0462 - val_accuracy: 0.9838\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.98843\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.04536\n",
      "Epoch 41/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.1217e-04 - accuracy: 1.0000 - val_loss: 0.0463 - val_accuracy: 0.9838\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.98843\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.04536\n",
      "Epoch 42/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.0823e-04 - accuracy: 1.0000 - val_loss: 0.0463 - val_accuracy: 0.9907\n",
      "\n",
      "Epoch 00042: val_accuracy improved from 0.98843 to 0.99074, saving model to lightningedge007a_results/yes/dominance/s03/max_acc_yes_dominance_s03.h5\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.04536\n",
      "Epoch 43/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.0394e-04 - accuracy: 1.0000 - val_loss: 0.0464 - val_accuracy: 0.9861\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.99074\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.04536\n",
      "Epoch 44/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 9.9287e-05 - accuracy: 1.0000 - val_loss: 0.0466 - val_accuracy: 0.9861\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.99074\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.04536\n",
      "Epoch 45/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 9.6190e-05 - accuracy: 1.0000 - val_loss: 0.0463 - val_accuracy: 0.9884\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.99074\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.04536\n",
      "Epoch 46/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 9.2124e-05 - accuracy: 1.0000 - val_loss: 0.0464 - val_accuracy: 0.9861\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.99074\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.04536\n",
      "Epoch 47/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 8.9481e-05 - accuracy: 1.0000 - val_loss: 0.0466 - val_accuracy: 0.9861\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.99074\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.04536\n",
      "Epoch 48/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 8.4017e-05 - accuracy: 1.0000 - val_loss: 0.0467 - val_accuracy: 0.9861\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.99074\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.04536\n",
      "Epoch 49/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 8.3697e-05 - accuracy: 1.0000 - val_loss: 0.0468 - val_accuracy: 0.9884\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.99074\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.04536\n",
      "Epoch 50/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 7.9294e-05 - accuracy: 1.0000 - val_loss: 0.0467 - val_accuracy: 0.9884\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.99074\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.04536\n",
      "240/240 [==============================] - 1s 3ms/step\n",
      "max acc:  [0.09772606837407996, 0.9833333492279053]\n",
      "240/240 [==============================] - 1s 3ms/step\n",
      "min loss:  [0.08102430674868326, 0.9833333492279053]\n",
      "---------------------------------------------------\n",
      "yes dominance s04\n",
      "---------------------------------------------------\n",
      "\n",
      "loaded shape: (2400,)\n",
      "(2400, 128, 9, 9)\n",
      "(2400, 128, 32)\n",
      "(2400,)\n",
      "(2400, 2)\n",
      "(2400, 128, 9, 9)\n",
      "(2400, 128, 32)\n",
      "(2400, 2)\n",
      "cnn_datasets.shape,rnn_datasets.shape,labels.shape :  (2400, 128, 9, 9) (2400, 128, 32) (2400, 2)\n",
      "(2400, 9, 9, 128)\n",
      "cnn_datasets.shape :  (2400, 9, 9, 128)\n",
      "========================Train / Test Shapes==============================\n",
      "(240, 9, 9, 128) (240, 128, 32) (2160, 9, 9, 128) (2160, 128, 32)\n",
      "================================ DNN ============================================\n",
      "input_cnn:  (None, 9, 9, 128)\n",
      "elu1:  (None, 9, 9, 32)\n",
      "elu2:  (None, 9, 9, 64)\n",
      "elu3:  (None, 9, 9, 128)\n",
      "reshape1:  (None, 9, 9, None)\n",
      "elu4:  (None, 9, 9, 13)\n",
      "reshape2:  (None, 1053)\n",
      "input_rnn (None, 128, 32)\n",
      "rnn_in_flat (None, None, 32)\n",
      "rnn_fc_in (None, 128, 1024)\n",
      "lstm_in (None, None, 1024)\n",
      "lstm_cell (None, 32)\n",
      "output (None, 32)\n",
      "rnn_output (32,)\n",
      "lstm_fc_out (None, 1024)\n",
      "lstm_fc_drop (None, 1024)\n",
      "fuse_cnn_rnn  (None, 2077)\n",
      "(None, 2)\n",
      "y  Tensor(\"dense_12/Softmax:0\", shape=(None, 2), dtype=float32)\n",
      "Model :  yes_dominance_s04_0_fold\n",
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_7 (InputLayer)            (None, 9, 9, 128)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 9, 9, 32)     65568       input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 9, 9, 32)     128         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "elu_16 (ELU)                    (None, 9, 9, 32)     0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 9, 9, 64)     32832       elu_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 9, 9, 64)     256         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "elu_17 (ELU)                    (None, 9, 9, 64)     0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 9, 9, 128)    131200      elu_17[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "input_8 (InputLayer)            (None, 128, 32)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 9, 9, 128)    512         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_15 (Reshape)            (None, 128, 32)      0           input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "elu_18 (ELU)                    (None, 9, 9, 128)    0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 128, 1024)    33792       reshape_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_13 (Reshape)            (None, 9, 9, 128)    0           elu_18[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "elu_20 (ELU)                    (None, 128, 1024)    0           dense_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 9, 9, 13)     1677        reshape_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_16 (Reshape)            (None, 128, 1024)    0           elu_20[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 9, 9, 13)     52          conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "rnn_4 (RNN)                     (None, 32)           143616      reshape_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "elu_19 (ELU)                    (None, 9, 9, 13)     0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 1024)         33792       rnn_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "reshape_14 (Reshape)            (None, 1053)         0           elu_19[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 1024)         0           dense_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 2077)         0           reshape_14[0][0]                 \n",
      "                                                                 dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 2)            4156        concatenate_4[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 447,581\n",
      "Trainable params: 447,107\n",
      "Non-trainable params: 474\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1728 samples, validate on 432 samples\n",
      "Epoch 1/50\n",
      " 256/1728 [===>..........................] - ETA: 10s - loss: 0.8541 - accuracy: 0.6016"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ABHISHEK_VERMA\\Anaconda3\\lib\\site-packages\\keras\\callbacks\\callbacks.py:95: RuntimeWarning: Method (on_train_batch_end) is slow compared to the batch update (11.239255). Check your callbacks.\n",
      "  % (hook_name, delta_t_median), RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1728/1728 [==============================] - 27s 16ms/step - loss: 0.5318 - accuracy: 0.7928 - val_loss: 0.3629 - val_accuracy: 0.8542\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.85417, saving model to lightningedge007a_results/yes/dominance/s04/max_acc_yes_dominance_s04.h5\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.36285, saving model to lightningedge007a_results/yes/dominance/s04/min_loss_yes_dominance_s04.h5\n",
      "Epoch 2/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 0.1626 - accuracy: 0.9375 - val_loss: 0.2658 - val_accuracy: 0.9051\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.85417 to 0.90509, saving model to lightningedge007a_results/yes/dominance/s04/max_acc_yes_dominance_s04.h5\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.36285 to 0.26576, saving model to lightningedge007a_results/yes/dominance/s04/min_loss_yes_dominance_s04.h5\n",
      "Epoch 3/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 0.0793 - accuracy: 0.9792 - val_loss: 0.2122 - val_accuracy: 0.9259\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.90509 to 0.92593, saving model to lightningedge007a_results/yes/dominance/s04/max_acc_yes_dominance_s04.h5\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.26576 to 0.21218, saving model to lightningedge007a_results/yes/dominance/s04/min_loss_yes_dominance_s04.h5\n",
      "Epoch 4/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 0.0417 - accuracy: 0.9919 - val_loss: 0.1557 - val_accuracy: 0.9421\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.92593 to 0.94213, saving model to lightningedge007a_results/yes/dominance/s04/max_acc_yes_dominance_s04.h5\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.21218 to 0.15571, saving model to lightningedge007a_results/yes/dominance/s04/min_loss_yes_dominance_s04.h5\n",
      "Epoch 5/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 0.0208 - accuracy: 0.9965 - val_loss: 0.1450 - val_accuracy: 0.9421\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.94213\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.15571 to 0.14499, saving model to lightningedge007a_results/yes/dominance/s04/min_loss_yes_dominance_s04.h5\n",
      "Epoch 6/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 0.0151 - accuracy: 0.9988 - val_loss: 0.1297 - val_accuracy: 0.9514\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.94213 to 0.95139, saving model to lightningedge007a_results/yes/dominance/s04/max_acc_yes_dominance_s04.h5\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.14499 to 0.12975, saving model to lightningedge007a_results/yes/dominance/s04/min_loss_yes_dominance_s04.h5\n",
      "Epoch 7/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.1225 - val_accuracy: 0.9537\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.95139 to 0.95370, saving model to lightningedge007a_results/yes/dominance/s04/max_acc_yes_dominance_s04.h5\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.12975 to 0.12246, saving model to lightningedge007a_results/yes/dominance/s04/min_loss_yes_dominance_s04.h5\n",
      "Epoch 8/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.1203 - val_accuracy: 0.9514\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.95370\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.12246 to 0.12034, saving model to lightningedge007a_results/yes/dominance/s04/min_loss_yes_dominance_s04.h5\n",
      "Epoch 9/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.1167 - val_accuracy: 0.9537\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.95370\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.12034 to 0.11675, saving model to lightningedge007a_results/yes/dominance/s04/min_loss_yes_dominance_s04.h5\n",
      "Epoch 10/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.1124 - val_accuracy: 0.9560\n",
      "\n",
      "Epoch 00010: val_accuracy improved from 0.95370 to 0.95602, saving model to lightningedge007a_results/yes/dominance/s04/max_acc_yes_dominance_s04.h5\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.11675 to 0.11242, saving model to lightningedge007a_results/yes/dominance/s04/min_loss_yes_dominance_s04.h5\n",
      "Epoch 11/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.1157 - val_accuracy: 0.9537\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.95602\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.11242\n",
      "Epoch 12/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.1177 - val_accuracy: 0.9514\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.95602\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.11242\n",
      "Epoch 13/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.1185 - val_accuracy: 0.9560\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.95602\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.11242\n",
      "Epoch 14/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.1178 - val_accuracy: 0.9583\n",
      "\n",
      "Epoch 00014: val_accuracy improved from 0.95602 to 0.95833, saving model to lightningedge007a_results/yes/dominance/s04/max_acc_yes_dominance_s04.h5\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.11242\n",
      "Epoch 15/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 9.6963e-04 - accuracy: 1.0000 - val_loss: 0.1189 - val_accuracy: 0.9583\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.95833\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.11242\n",
      "Epoch 16/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 8.8691e-04 - accuracy: 1.0000 - val_loss: 0.1218 - val_accuracy: 0.9560\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.95833\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.11242\n",
      "Epoch 17/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 7.8413e-04 - accuracy: 1.0000 - val_loss: 0.1221 - val_accuracy: 0.9560\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.95833\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.11242\n",
      "Epoch 18/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 7.1038e-04 - accuracy: 1.0000 - val_loss: 0.1232 - val_accuracy: 0.9560\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.95833\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.11242\n",
      "Epoch 19/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 6.6586e-04 - accuracy: 1.0000 - val_loss: 0.1223 - val_accuracy: 0.9583\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.95833\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.11242\n",
      "Epoch 20/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 5.8492e-04 - accuracy: 1.0000 - val_loss: 0.1229 - val_accuracy: 0.9583\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.95833\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.11242\n",
      "Epoch 21/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 5.2480e-04 - accuracy: 1.0000 - val_loss: 0.1251 - val_accuracy: 0.9583\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.95833\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.11242\n",
      "Epoch 22/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 4.8282e-04 - accuracy: 1.0000 - val_loss: 0.1259 - val_accuracy: 0.9583\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.95833\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.11242\n",
      "Epoch 23/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 4.4780e-04 - accuracy: 1.0000 - val_loss: 0.1265 - val_accuracy: 0.9583\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.95833\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.11242\n",
      "Epoch 24/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 4.1058e-04 - accuracy: 1.0000 - val_loss: 0.1266 - val_accuracy: 0.9583\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.95833\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.11242\n",
      "Epoch 25/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 3.8206e-04 - accuracy: 1.0000 - val_loss: 0.1277 - val_accuracy: 0.9583\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.95833\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.11242\n",
      "Epoch 26/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 3.4764e-04 - accuracy: 1.0000 - val_loss: 0.1286 - val_accuracy: 0.9583\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.95833\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.11242\n",
      "Epoch 27/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 3.3190e-04 - accuracy: 1.0000 - val_loss: 0.1304 - val_accuracy: 0.9583\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.95833\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.11242\n",
      "Epoch 28/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 3.1164e-04 - accuracy: 1.0000 - val_loss: 0.1305 - val_accuracy: 0.9583\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.95833\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.11242\n",
      "Epoch 29/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 2.9271e-04 - accuracy: 1.0000 - val_loss: 0.1300 - val_accuracy: 0.9583\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.95833\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.11242\n",
      "Epoch 30/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 2.6967e-04 - accuracy: 1.0000 - val_loss: 0.1299 - val_accuracy: 0.9583\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.95833\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.11242\n",
      "Epoch 31/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 2.5523e-04 - accuracy: 1.0000 - val_loss: 0.1331 - val_accuracy: 0.9583\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.95833\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.11242\n",
      "Epoch 32/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 2.4076e-04 - accuracy: 1.0000 - val_loss: 0.1317 - val_accuracy: 0.9583\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.95833\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.11242\n",
      "Epoch 33/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 2.3367e-04 - accuracy: 1.0000 - val_loss: 0.1313 - val_accuracy: 0.9583\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.95833\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.11242\n",
      "Epoch 34/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 2.1954e-04 - accuracy: 1.0000 - val_loss: 0.1320 - val_accuracy: 0.9583\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.95833\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.11242\n",
      "Epoch 35/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 2.0798e-04 - accuracy: 1.0000 - val_loss: 0.1328 - val_accuracy: 0.9583\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.95833\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.11242\n",
      "Epoch 36/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.9620e-04 - accuracy: 1.0000 - val_loss: 0.1330 - val_accuracy: 0.9583\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.95833\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.11242\n",
      "Epoch 37/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.8324e-04 - accuracy: 1.0000 - val_loss: 0.1331 - val_accuracy: 0.9583\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.95833\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.11242\n",
      "Epoch 38/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.7621e-04 - accuracy: 1.0000 - val_loss: 0.1342 - val_accuracy: 0.9583\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.95833\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.11242\n",
      "Epoch 39/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.6968e-04 - accuracy: 1.0000 - val_loss: 0.1339 - val_accuracy: 0.9583\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.95833\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.11242\n",
      "Epoch 40/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.6116e-04 - accuracy: 1.0000 - val_loss: 0.1335 - val_accuracy: 0.9583\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.95833\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.11242\n",
      "Epoch 41/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.4990e-04 - accuracy: 1.0000 - val_loss: 0.1357 - val_accuracy: 0.9583\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.95833\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.11242\n",
      "Epoch 42/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.4495e-04 - accuracy: 1.0000 - val_loss: 0.1365 - val_accuracy: 0.9583\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.95833\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.11242\n",
      "Epoch 43/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.3971e-04 - accuracy: 1.0000 - val_loss: 0.1359 - val_accuracy: 0.9583\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.95833\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.11242\n",
      "Epoch 44/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.3259e-04 - accuracy: 1.0000 - val_loss: 0.1365 - val_accuracy: 0.9583\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.95833\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.11242\n",
      "Epoch 45/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.2868e-04 - accuracy: 1.0000 - val_loss: 0.1363 - val_accuracy: 0.9583\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.95833\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.11242\n",
      "Epoch 46/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.2207e-04 - accuracy: 1.0000 - val_loss: 0.1363 - val_accuracy: 0.9583\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.95833\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.11242\n",
      "Epoch 47/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.2037e-04 - accuracy: 1.0000 - val_loss: 0.1376 - val_accuracy: 0.9583\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.95833\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.11242\n",
      "Epoch 48/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.1293e-04 - accuracy: 1.0000 - val_loss: 0.1364 - val_accuracy: 0.9583\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.95833\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.11242\n",
      "Epoch 49/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.1027e-04 - accuracy: 1.0000 - val_loss: 0.1385 - val_accuracy: 0.9583\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.95833\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.11242\n",
      "Epoch 50/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.0669e-04 - accuracy: 1.0000 - val_loss: 0.1385 - val_accuracy: 0.9583\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.95833\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.11242\n",
      "240/240 [==============================] - 1s 4ms/step\n",
      "max acc:  [0.11753026843070984, 0.9541666507720947]\n",
      "240/240 [==============================] - 1s 3ms/step\n",
      "min loss:  [0.12430112858613332, 0.9541666507720947]\n",
      "---------------------------------------------------\n",
      "yes dominance s05\n",
      "---------------------------------------------------\n",
      "\n",
      "loaded shape: (2400,)\n",
      "(2400, 128, 9, 9)\n",
      "(2400, 128, 32)\n",
      "(2400,)\n",
      "(2400, 2)\n",
      "(2400, 128, 9, 9)\n",
      "(2400, 128, 32)\n",
      "(2400, 2)\n",
      "cnn_datasets.shape,rnn_datasets.shape,labels.shape :  (2400, 128, 9, 9) (2400, 128, 32) (2400, 2)\n",
      "(2400, 9, 9, 128)\n",
      "cnn_datasets.shape :  (2400, 9, 9, 128)\n",
      "========================Train / Test Shapes==============================\n",
      "(240, 9, 9, 128) (240, 128, 32) (2160, 9, 9, 128) (2160, 128, 32)\n",
      "================================ DNN ============================================\n",
      "input_cnn:  (None, 9, 9, 128)\n",
      "elu1:  (None, 9, 9, 32)\n",
      "elu2:  (None, 9, 9, 64)\n",
      "elu3:  (None, 9, 9, 128)\n",
      "reshape1:  (None, 9, 9, None)\n",
      "elu4:  (None, 9, 9, 13)\n",
      "reshape2:  (None, 1053)\n",
      "input_rnn (None, 128, 32)\n",
      "rnn_in_flat (None, None, 32)\n",
      "rnn_fc_in (None, 128, 1024)\n",
      "lstm_in (None, None, 1024)\n",
      "lstm_cell (None, 32)\n",
      "output (None, 32)\n",
      "rnn_output (32,)\n",
      "lstm_fc_out (None, 1024)\n",
      "lstm_fc_drop (None, 1024)\n",
      "fuse_cnn_rnn  (None, 2077)\n",
      "(None, 2)\n",
      "y  Tensor(\"dense_15/Softmax:0\", shape=(None, 2), dtype=float32)\n",
      "Model :  yes_dominance_s05_0_fold\n",
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_9 (InputLayer)            (None, 9, 9, 128)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 9, 9, 32)     65568       input_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 9, 9, 32)     128         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "elu_21 (ELU)                    (None, 9, 9, 32)     0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 9, 9, 64)     32832       elu_21[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 9, 9, 64)     256         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "elu_22 (ELU)                    (None, 9, 9, 64)     0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 9, 9, 128)    131200      elu_22[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "input_10 (InputLayer)           (None, 128, 32)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 9, 9, 128)    512         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_19 (Reshape)            (None, 128, 32)      0           input_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "elu_23 (ELU)                    (None, 9, 9, 128)    0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 128, 1024)    33792       reshape_19[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_17 (Reshape)            (None, 9, 9, 128)    0           elu_23[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "elu_25 (ELU)                    (None, 128, 1024)    0           dense_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 9, 9, 13)     1677        reshape_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_20 (Reshape)            (None, 128, 1024)    0           elu_25[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 9, 9, 13)     52          conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "rnn_5 (RNN)                     (None, 32)           143616      reshape_20[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "elu_24 (ELU)                    (None, 9, 9, 13)     0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 1024)         33792       rnn_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "reshape_18 (Reshape)            (None, 1053)         0           elu_24[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 1024)         0           dense_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 2077)         0           reshape_18[0][0]                 \n",
      "                                                                 dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_15 (Dense)                (None, 2)            4156        concatenate_5[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 447,581\n",
      "Trainable params: 447,107\n",
      "Non-trainable params: 474\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1728 samples, validate on 432 samples\n",
      "Epoch 1/50\n",
      " 256/1728 [===>..........................] - ETA: 10s - loss: 1.4243 - accuracy: 0.4961"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ABHISHEK_VERMA\\Anaconda3\\lib\\site-packages\\keras\\callbacks\\callbacks.py:95: RuntimeWarning: Method (on_train_batch_end) is slow compared to the batch update (10.630046). Check your callbacks.\n",
      "  % (hook_name, delta_t_median), RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1728/1728 [==============================] - 26s 15ms/step - loss: 0.6511 - accuracy: 0.7517 - val_loss: 0.3073 - val_accuracy: 0.8843\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.88426, saving model to lightningedge007a_results/yes/dominance/s05/max_acc_yes_dominance_s05.h5\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.30729, saving model to lightningedge007a_results/yes/dominance/s05/min_loss_yes_dominance_s05.h5\n",
      "Epoch 2/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 0.1532 - accuracy: 0.9381 - val_loss: 0.1845 - val_accuracy: 0.9537\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.88426 to 0.95370, saving model to lightningedge007a_results/yes/dominance/s05/max_acc_yes_dominance_s05.h5\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.30729 to 0.18454, saving model to lightningedge007a_results/yes/dominance/s05/min_loss_yes_dominance_s05.h5\n",
      "Epoch 3/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 0.0733 - accuracy: 0.9815 - val_loss: 0.1566 - val_accuracy: 0.9514\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.95370\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.18454 to 0.15659, saving model to lightningedge007a_results/yes/dominance/s05/min_loss_yes_dominance_s05.h5\n",
      "Epoch 4/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 0.0368 - accuracy: 0.9965 - val_loss: 0.1248 - val_accuracy: 0.9699\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.95370 to 0.96991, saving model to lightningedge007a_results/yes/dominance/s05/max_acc_yes_dominance_s05.h5\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.15659 to 0.12482, saving model to lightningedge007a_results/yes/dominance/s05/min_loss_yes_dominance_s05.h5\n",
      "Epoch 5/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 0.0198 - accuracy: 0.9983 - val_loss: 0.1119 - val_accuracy: 0.9676\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.96991\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.12482 to 0.11192, saving model to lightningedge007a_results/yes/dominance/s05/min_loss_yes_dominance_s05.h5\n",
      "Epoch 6/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 0.0107 - accuracy: 1.0000 - val_loss: 0.0971 - val_accuracy: 0.9769\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.96991 to 0.97685, saving model to lightningedge007a_results/yes/dominance/s05/max_acc_yes_dominance_s05.h5\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.11192 to 0.09710, saving model to lightningedge007a_results/yes/dominance/s05/min_loss_yes_dominance_s05.h5\n",
      "Epoch 7/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.0913 - val_accuracy: 0.9722\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.97685\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.09710 to 0.09132, saving model to lightningedge007a_results/yes/dominance/s05/min_loss_yes_dominance_s05.h5\n",
      "Epoch 8/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.0858 - val_accuracy: 0.9722\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.97685\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.09132 to 0.08585, saving model to lightningedge007a_results/yes/dominance/s05/min_loss_yes_dominance_s05.h5\n",
      "Epoch 9/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0836 - val_accuracy: 0.9699\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.97685\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.08585 to 0.08357, saving model to lightningedge007a_results/yes/dominance/s05/min_loss_yes_dominance_s05.h5\n",
      "Epoch 10/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0786 - val_accuracy: 0.9722\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.97685\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.08357 to 0.07859, saving model to lightningedge007a_results/yes/dominance/s05/min_loss_yes_dominance_s05.h5\n",
      "Epoch 11/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0799 - val_accuracy: 0.9722\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.97685\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.07859\n",
      "Epoch 12/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0790 - val_accuracy: 0.9699\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.97685\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.07859\n",
      "Epoch 13/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0772 - val_accuracy: 0.9722\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.97685\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.07859 to 0.07715, saving model to lightningedge007a_results/yes/dominance/s05/min_loss_yes_dominance_s05.h5\n",
      "Epoch 14/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0784 - val_accuracy: 0.9722\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.97685\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.07715\n",
      "Epoch 15/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0770 - val_accuracy: 0.9745\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.97685\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.07715 to 0.07697, saving model to lightningedge007a_results/yes/dominance/s05/min_loss_yes_dominance_s05.h5\n",
      "Epoch 16/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0784 - val_accuracy: 0.9722\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.97685\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.07697\n",
      "Epoch 17/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 9.3051e-04 - accuracy: 1.0000 - val_loss: 0.0783 - val_accuracy: 0.9722\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.97685\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.07697\n",
      "Epoch 18/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 8.4262e-04 - accuracy: 1.0000 - val_loss: 0.0786 - val_accuracy: 0.9722\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.97685\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.07697\n",
      "Epoch 19/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 7.6356e-04 - accuracy: 1.0000 - val_loss: 0.0799 - val_accuracy: 0.9722\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.97685\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.07697\n",
      "Epoch 20/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 6.9553e-04 - accuracy: 1.0000 - val_loss: 0.0802 - val_accuracy: 0.9722\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.97685\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.07697\n",
      "Epoch 21/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 6.3303e-04 - accuracy: 1.0000 - val_loss: 0.0793 - val_accuracy: 0.9745\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.97685\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.07697\n",
      "Epoch 22/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 5.8802e-04 - accuracy: 1.0000 - val_loss: 0.0812 - val_accuracy: 0.9745\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.97685\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.07697\n",
      "Epoch 23/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 5.3560e-04 - accuracy: 1.0000 - val_loss: 0.0815 - val_accuracy: 0.9745\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.97685\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.07697\n",
      "Epoch 24/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 4.9100e-04 - accuracy: 1.0000 - val_loss: 0.0830 - val_accuracy: 0.9722\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.97685\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.07697\n",
      "Epoch 25/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 4.5794e-04 - accuracy: 1.0000 - val_loss: 0.0827 - val_accuracy: 0.9745\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.97685\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.07697\n",
      "Epoch 26/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 4.2491e-04 - accuracy: 1.0000 - val_loss: 0.0833 - val_accuracy: 0.9722\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.97685\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.07697\n",
      "Epoch 27/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 3.9131e-04 - accuracy: 1.0000 - val_loss: 0.0845 - val_accuracy: 0.9745\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.97685\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.07697\n",
      "Epoch 28/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 3.6832e-04 - accuracy: 1.0000 - val_loss: 0.0831 - val_accuracy: 0.9745\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.97685\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.07697\n",
      "Epoch 29/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 3.4500e-04 - accuracy: 1.0000 - val_loss: 0.0854 - val_accuracy: 0.9722\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.97685\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.07697\n",
      "Epoch 30/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 3.2241e-04 - accuracy: 1.0000 - val_loss: 0.0847 - val_accuracy: 0.9745\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.97685\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.07697\n",
      "Epoch 31/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 2.9997e-04 - accuracy: 1.0000 - val_loss: 0.0865 - val_accuracy: 0.9722\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.97685\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.07697\n",
      "Epoch 32/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 2.8770e-04 - accuracy: 1.0000 - val_loss: 0.0847 - val_accuracy: 0.9745\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.97685\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.07697\n",
      "Epoch 33/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 2.6908e-04 - accuracy: 1.0000 - val_loss: 0.0875 - val_accuracy: 0.9722\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.97685\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.07697\n",
      "Epoch 34/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 2.5602e-04 - accuracy: 1.0000 - val_loss: 0.0869 - val_accuracy: 0.9745\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.97685\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.07697\n",
      "Epoch 35/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 2.4056e-04 - accuracy: 1.0000 - val_loss: 0.0866 - val_accuracy: 0.9745\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.97685\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.07697\n",
      "Epoch 36/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 2.2882e-04 - accuracy: 1.0000 - val_loss: 0.0869 - val_accuracy: 0.9745\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.97685\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.07697\n",
      "Epoch 37/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 2.1941e-04 - accuracy: 1.0000 - val_loss: 0.0879 - val_accuracy: 0.9745\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.97685\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.07697\n",
      "Epoch 38/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 2.0644e-04 - accuracy: 1.0000 - val_loss: 0.0877 - val_accuracy: 0.9745\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.97685\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.07697\n",
      "Epoch 39/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.9566e-04 - accuracy: 1.0000 - val_loss: 0.0888 - val_accuracy: 0.9745\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.97685\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.07697\n",
      "Epoch 40/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.8658e-04 - accuracy: 1.0000 - val_loss: 0.0882 - val_accuracy: 0.9745\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.97685\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.07697\n",
      "Epoch 41/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.8146e-04 - accuracy: 1.0000 - val_loss: 0.0890 - val_accuracy: 0.9745\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.97685\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.07697\n",
      "Epoch 42/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.7013e-04 - accuracy: 1.0000 - val_loss: 0.0887 - val_accuracy: 0.9745\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.97685\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.07697\n",
      "Epoch 43/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.6268e-04 - accuracy: 1.0000 - val_loss: 0.0885 - val_accuracy: 0.9745\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.97685\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.07697\n",
      "Epoch 44/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.5652e-04 - accuracy: 1.0000 - val_loss: 0.0893 - val_accuracy: 0.9745\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.97685\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.07697\n",
      "Epoch 45/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.4994e-04 - accuracy: 1.0000 - val_loss: 0.0906 - val_accuracy: 0.9722\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.97685\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.07697\n",
      "Epoch 46/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.4522e-04 - accuracy: 1.0000 - val_loss: 0.0893 - val_accuracy: 0.9745\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.97685\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.07697\n",
      "Epoch 47/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.3583e-04 - accuracy: 1.0000 - val_loss: 0.0911 - val_accuracy: 0.9722\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.97685\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.07697\n",
      "Epoch 48/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.3222e-04 - accuracy: 1.0000 - val_loss: 0.0907 - val_accuracy: 0.9745\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.97685\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.07697\n",
      "Epoch 49/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.2674e-04 - accuracy: 1.0000 - val_loss: 0.0899 - val_accuracy: 0.9745\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.97685\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.07697\n",
      "Epoch 50/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.2154e-04 - accuracy: 1.0000 - val_loss: 0.0908 - val_accuracy: 0.9745\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.97685\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.07697\n",
      "240/240 [==============================] - 1s 3ms/step\n",
      "max acc:  [0.14387638966242472, 0.9375]\n",
      "240/240 [==============================] - 1s 4ms/step\n",
      "min loss:  [0.12188942345480124, 0.949999988079071]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(32)\n",
    "\n",
    "window_size = 128\n",
    "\n",
    "cnn_suffix ='.mat_win_128_cnn_dataset.pkl'\n",
    "rnn_suffix ='.mat_win_128_rnn_dataset.pkl'\n",
    "label_suffix ='.mat_win_128_labels.pkl'\n",
    "\n",
    "for with_or_without in baseline_preprocessing:\n",
    "    for arousal_or_valence in emotions:\n",
    "        for data_file in data_files:\n",
    "            \n",
    "            gc.collect()\n",
    "            \n",
    "            print('---------------------------------------------------')\n",
    "            print(with_or_without+' '+arousal_or_valence+' '+data_file)\n",
    "            print('---------------------------------------------------\\n')\n",
    "\n",
    "            #data_file    ='s17'\n",
    "            #arousal_or_valence = 'valence'\n",
    "            #with_or_without = 'yes'\n",
    "\n",
    "            dataset_dir = 'deap_shuffled_data/'+with_or_without+'_'+arousal_or_valence+'/'\n",
    "            ###load training set\n",
    "            try:\n",
    "                with open(dataset_dir + data_file + cnn_suffix, \"rb\") as fp:\n",
    "                    cnn_datasets = pickle.load(fp)\n",
    "                with open(dataset_dir + data_file + rnn_suffix, \"rb\") as fp:\n",
    "                    rnn_datasets = pickle.load(fp)\n",
    "                with open(dataset_dir + data_file + label_suffix, \"rb\") as fp:\n",
    "                    labels = pickle.load(fp)\n",
    "                    labels = np.transpose(labels)\n",
    "                    print(\"loaded shape:\",labels.shape)\n",
    "            except:\n",
    "                continue\n",
    "            lables_backup = labels\n",
    "\n",
    "            print(cnn_datasets.shape)\n",
    "            print(rnn_datasets.shape)\n",
    "            print(labels.shape)\n",
    "\n",
    "            #print(\"cnn_dataset shape before reshape:\", np.shape(cnn_datasets))\n",
    "            # cnn_datasets = cnn_datasets.reshape(len(cnn_datasets), window_size, 9,9, 1)\n",
    "            #print(\"cnn_dataset shape after reshape:\", np.shape(cnn_datasets))\n",
    "            one_hot_labels = np.array(list(pd.get_dummies(labels)))\n",
    "\n",
    "            labels = np.asarray(pd.get_dummies(labels), dtype=np.int8)\n",
    "\n",
    "            print(labels.shape)\n",
    "            # shuffle data\n",
    "            index = np.array(range(0, len(labels)))\n",
    "            np.random.shuffle(index)\n",
    "\n",
    "            cnn_datasets   = cnn_datasets[index]\n",
    "            rnn_datasets   = rnn_datasets[index]\n",
    "            labels  = labels[index]\n",
    "\n",
    "            print(cnn_datasets.shape)\n",
    "            print(rnn_datasets.shape)\n",
    "            print(labels.shape)\n",
    "\n",
    "            #print(\"**********(\" + time.asctime(time.localtime(time.time())) + \") Load and Split dataset End **********\\n\")\n",
    "            #print(\"**********(\" + time.asctime(time.localtime(time.time())) + \") Define parameters and functions Begin: **********\\n\")\n",
    "            print('cnn_datasets.shape,rnn_datasets.shape,labels.shape : ',cnn_datasets.shape,rnn_datasets.shape,labels.shape)\n",
    "            #important\n",
    "            cnn_datasets=cnn_datasets.reshape(2400,9,9,-1)# imp\n",
    "            print(cnn_datasets.shape)\n",
    "            print('cnn_datasets.shape : ',cnn_datasets.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            print('========================Train / Test Shapes==============================')\n",
    "\n",
    "\n",
    "\n",
    "            fold=10\n",
    "            curr_fold=0\n",
    "            #for curr_fold in range(fold): # kernel dies\n",
    "                \n",
    "            #   print('curr_fold / fold : ',curr_fold,' / ',fold)\n",
    "\n",
    "\n",
    "            max_acc_acc_list=[]\n",
    "\n",
    "            max_acc_loss_list=[]\n",
    "\n",
    "\n",
    "            min_loss_acc_list=[]\n",
    "\n",
    "            min_loss_loss_list=[]\n",
    "\n",
    "            fold_size = cnn_datasets.shape[0]//fold\n",
    "            indexes_list = [i for i in range(len(cnn_datasets))]\n",
    "            indexes = np.array(indexes_list)\n",
    "            split_list = [i for i in range(curr_fold*fold_size,(curr_fold+1)*fold_size)]\n",
    "            split = np.array(split_list)\n",
    "\n",
    "            cnn_test = cnn_datasets[split] \n",
    "            labels_test = labels[split]\n",
    "            rnn_test = rnn_datasets[split]\n",
    "\n",
    "            split = np.array(list(set(indexes_list)^set(split_list)))\n",
    "\n",
    "            cnn_train = cnn_datasets[split]\n",
    "            rnn_train = rnn_datasets[split]\n",
    "            labels_train = labels[split]\n",
    "\n",
    "            # train_sample = labels_train.shape[0]\n",
    "            # print(\"training examples:\", train_sample)\n",
    "            # test_sample = labels_test.shape[0]\n",
    "            # print(\"test examples    :\",test_sample)\n",
    "            print(cnn_test.shape,rnn_test.shape,cnn_train.shape,rnn_train.shape)\n",
    "\n",
    "            print('================================ DNN ============================================')\n",
    "\n",
    "            input_cnn=Input(shape=(9,9,128))\n",
    "\n",
    "            print('input_cnn: ',input_cnn.shape)\n",
    "\n",
    "            conv1=Conv2D(32,\n",
    "                          kernel_size=(4,4),\n",
    "                          strides=(1,1),\n",
    "                          padding='same',\n",
    "                          input_shape=(9,9,128)\n",
    "                         )(input_cnn)\n",
    "\n",
    "\n",
    "            bn1=BatchNormalization()(conv1)\n",
    "\n",
    "            elu1=ELU()(bn1)\n",
    "\n",
    "            print('elu1: ',elu1.shape)\n",
    "            #?,9,9,32\n",
    "            conv2=Conv2D(64,\n",
    "                          kernel_size=(4,4),\n",
    "                          strides=(1,1),\n",
    "                          padding='same'\n",
    "                         )(elu1)\n",
    "\n",
    "            bn2=BatchNormalization()(conv2)\n",
    "\n",
    "            elu2=ELU()(bn2)\n",
    "\n",
    "            print('elu2: ',elu2.shape)\n",
    "            #?,9,9,64\n",
    "\n",
    "            conv3=Conv2D(128,\n",
    "                          kernel_size=(4,4),\n",
    "                          strides=(1,1),\n",
    "                          padding='same'\n",
    "                         )(elu2)\n",
    "\n",
    "            bn3=BatchNormalization()(conv3)\n",
    "\n",
    "            elu3=ELU()(bn3)\n",
    "\n",
    "\n",
    "            print('elu3: ',elu3.shape)\n",
    "            #?,9,9,128\n",
    "\n",
    "            # mc.add(Flatten())\n",
    "            # mc.add(Lambda(lambda x:x,output_shape=(9,9,32*4*128)))\n",
    "            # mc.add(Lambda(K.reshape((-1,9,9,32*4*128))))\n",
    "            reshape1=Reshape((9,9,-1))(elu3)\n",
    "\n",
    "\n",
    "            print('reshape1: ',reshape1.shape)\n",
    "            #?,9,9,32*4*128\n",
    "\n",
    "            conv4=Conv2D(13,#32*4*128,\n",
    "                          kernel_size=(1,1),\n",
    "                          strides=(1,1),\n",
    "                          padding='same'\n",
    "                         )(reshape1)\n",
    "\n",
    "            bn4=BatchNormalization()(conv4)\n",
    "\n",
    "            elu4=ELU()(bn4)\n",
    "\n",
    "\n",
    "            print('elu4: ',elu4.shape)\n",
    "            #?,9,9,13 #32*4*128\n",
    "\n",
    "            # mc.add(Flatten())\n",
    "\n",
    "            # mc.add(Lambda(lambda x:x,output_shape=([13*9*9])))\n",
    "            # mc.add(Lambda(K.reshape((None,13*9*9))))\n",
    "            reshape2=Reshape(([13*9*9]))(elu4)\n",
    "\n",
    "\n",
    "            print('reshape2: ',reshape2.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            cnn_out_fuse=reshape2\n",
    "\n",
    "\n",
    "            # cube=K.reshape(e3,(-1,9,9,32*4*128))#(e3)\n",
    "\n",
    "\n",
    "            # flat=K.reshape(e4,(-1,13*9*9))#(e4) #1053\n",
    "\n",
    "            # rnn_in=K.placeholder(shape=(None,128,32))\n",
    "            # rnn_in=tf.convert_to_tensor(rnn_datasets,dtype='float32')\n",
    "\n",
    "\n",
    "            # rnn_in.get_shape().as_list()\n",
    "\n",
    "            # rnn_in=K.placeholder(shape=(None,128,32))\n",
    "            # rnn_in_flat=K.reshape(rnn_in,[-1,32])\n",
    "\n",
    "            # print('rnn_in ',rnn_in.shape)\n",
    "\n",
    "            input_rnn=Input(shape=(128,32))\n",
    "            print('input_rnn',input_rnn.shape)\n",
    "\n",
    "            rnn_in_flat=Reshape((-1,32))(input_rnn)\n",
    "            print('rnn_in_flat',rnn_in_flat.shape)\n",
    "            # rnn_in_flat = Lambda(lambda x:x[:,0])(input_rnn)\n",
    "\n",
    "            # rnn_fc_in1 =Dense(32)(rnn_in_flat)\n",
    "            rnn_fc_in1 =Dense(1024)(rnn_in_flat)\n",
    "            rnn_fc_in=ELU()(rnn_fc_in1)\n",
    "            print('rnn_fc_in',rnn_fc_in.shape)\n",
    "\n",
    "            # rnn_fc_in =Dense(1024)(input_rnn)\n",
    "\n",
    "            # lstm_in=Reshape((-1,128,1024))(rnn_fc_in)\n",
    "            lstm_in=Reshape((-1,1024))(rnn_fc_in)\n",
    "            print('lstm_in',lstm_in.shape)\n",
    "\n",
    "            cells=[]\n",
    "\n",
    "            for i in range(2):\n",
    "                cell=LSTMCell(32,unit_forget_bias=True,dropout=0.5)#'forget_bias'=1.0,'state_is_tuple'=True\n",
    "                cells.append(cell)\n",
    "            #     print(cell.shape)\n",
    "\n",
    "            # lstm_cell=StackedRNNCells(cells)\n",
    "            lstm_cell=RNN(cells)(lstm_in)\n",
    "            # print(lstm_cell.shape)\n",
    "            # op,states=RNN(cells)(lstm_in)\n",
    "            print('lstm_cell',lstm_cell.shape)\n",
    "            # output=K.transpose_shape((1,0,2),lstm_cell)\n",
    "            # output=Permute((1,0,2))(lstm_cell)\n",
    "            # output.reshape()\n",
    "            output=lstm_cell\n",
    "            print('output',output.shape)\n",
    "            rnn_output=output[-1]\n",
    "            # rnn_output\n",
    "\n",
    "            print('rnn_output',rnn_output.shape)\n",
    "            # shape_rnn_out=rnn_output.get_shape().as_list()\n",
    "            lstm_fc_out=Dense(1024)(output)#shape_rnn_out[1]\n",
    "\n",
    "            print('lstm_fc_out',lstm_fc_out.shape)\n",
    "\n",
    "\n",
    "            # lstm_fc_out_2=Dense(1053)(lstm_fc_out)#shape_rnn_out[1]\n",
    "\n",
    "\n",
    "\n",
    "            lstm_fc_drop=Dropout(0.5)(lstm_fc_out)\n",
    "            # lstm_fc_drop\n",
    "            print('lstm_fc_drop',lstm_fc_drop.shape)\n",
    "\n",
    "            # fuse_cnn_rnn=add([cnn_out_fuse,lstm_fc_drop])\n",
    "\n",
    "            fuse_cnn_rnn=concatenate([cnn_out_fuse,lstm_fc_drop])\n",
    "            print('fuse_cnn_rnn ',fuse_cnn_rnn.shape)\n",
    "            y=Dense(2,activation='softmax')(fuse_cnn_rnn) ## ,activity_regularizer=regularizers.l2(0.5)\n",
    "            print(y.shape)\n",
    "            y_pred=K.argmax(y,1)\n",
    "            # y_pred=K.argmax(K.softmax(y))\n",
    "            # y_posi=K.softmax(y)\n",
    "            print('y ',y)\n",
    "\n",
    "\n",
    "            directory_le007a='./lightningedge007a_results/'+with_or_without+'/'+arousal_or_valence+'/'+data_file\n",
    "            try:\n",
    "                if not os.path.exists(directory_le007a):\n",
    "                    os.makedirs(directory_le007a)\n",
    "            except OSError:\n",
    "                print ('Error: Creating directory. ' +  directory_le007a)\n",
    "\n",
    "\n",
    "\n",
    "            model=Model(inputs=[input_cnn,input_rnn],outputs=y)\n",
    "            model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "            print('Model : ',with_or_without+'_'+arousal_or_valence+'_'+data_file+'_'+str(curr_fold)+'_fold')\n",
    "            print(model.summary())\n",
    "\n",
    "            m_val_acc=ModelCheckpoint('lightningedge007a_results/'+with_or_without+'/'+arousal_or_valence+'/'+data_file+'/'+'max_acc_'+with_or_without+'_'+arousal_or_valence+'_'+data_file+'.h5',monitor='val_accuracy',mode='max',verbose=1,save_best_only=True)\n",
    "            m_val_loss=ModelCheckpoint('lightningedge007a_results/'+with_or_without+'/'+arousal_or_valence+'/'+data_file+'/'+'min_loss_'+with_or_without+'_'+arousal_or_valence+'_'+data_file+'.h5',monitor='val_loss',mode='min',verbose=1,save_best_only=True)\n",
    "\n",
    "\n",
    "            tb_log_dir='lightningedge007a_results\\\\'+with_or_without+'\\\\'+arousal_or_valence+'\\\\'+data_file+'\\\\'+'logs_'+with_or_without+'_'+arousal_or_valence+'_'+data_file\n",
    "            #tb_log_dir='lightningedge007a_results/'+with_or_without+'/'+arousal_or_valence+'/'+data_file+'/'+'logs_'+with_or_without+'_'+arousal_or_valence+'_'+data_file\n",
    "\n",
    "            createFolder(tb_log_dir)\n",
    "\n",
    "\n",
    "            #log_dir='lightningedge007a_results\\\\'+with_or_without+'\\\\'+arousal_or_valence+'\\\\'+data_file+'\\\\'+'logs_'+with_or_without+'_'+arousal_or_valence+'_'+data_file+'_'+str(curr_fold)+'_fold\\\\' #datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "            tensorboard_callback = callbacks.TensorBoard(log_dir=tb_log_dir)#, histogram_freq=1)\n",
    "\n",
    "            plotpicture=plot_model(model, to_file='lightningedge007a_results/'+with_or_without+'/'+arousal_or_valence+'/'+data_file+'/'+'model_'+with_or_without+'_'+arousal_or_valence+'_'+data_file+'.png', show_shapes=True)\n",
    "\n",
    "            \n",
    "            \n",
    "            gc.collect()\n",
    "            \n",
    "            \n",
    "\n",
    "            history=model.fit([cnn_train,rnn_train],labels_train,batch_size=128,epochs=50,callbacks=[tensorboard_callback,m_val_acc,m_val_loss],validation_split=0.2)\n",
    "\n",
    "\n",
    "            #Plot values\n",
    "            plt.plot(history.history['accuracy'])\n",
    "            plt.plot(history.history['val_accuracy'])\n",
    "            plt.title('max_acc_'+with_or_without+'_'+arousal_or_valence+'_'+data_file)\n",
    "            plt.ylabel('Accuracy')\n",
    "            plt.xlabel('Epoch')\n",
    "            plt.legend(['Train', 'Validation'], loc='upper right',bbox_to_anchor=(1.3,1))\n",
    "            plt.savefig('lightningedge007a_results/'+with_or_without+'/'+arousal_or_valence+'/'+data_file+'/'+'max_acc_'+with_or_without+'_'+arousal_or_valence+'_'+data_file+'.png',bbox_inches='tight')\n",
    "            #plt.show()\n",
    "            plt.close()\n",
    "\n",
    "\n",
    "            # Plot training & validation loss values\n",
    "            plt.plot(history.history['loss'])\n",
    "            plt.plot(history.history['val_loss'])\n",
    "            plt.title('min_loss_'+with_or_without+'_'+arousal_or_valence+'_'+data_file+'_'+str(curr_fold)+'_fold')\n",
    "            plt.ylabel('Loss')\n",
    "            plt.xlabel('Epoch')\n",
    "            plt.legend(['Train', 'Validation'], loc='upper right',bbox_to_anchor=(1.3,1))\n",
    "            plt.savefig('lightningedge007a_results/'+with_or_without+'/'+arousal_or_valence+'/'+data_file+'/'+'min_loss_'+with_or_without+'_'+arousal_or_valence+'_'+data_file+'.png',bbox_inches='tight')\n",
    "            #plt.show()\n",
    "            plt.close()\n",
    "\n",
    "            vam=load_model('lightningedge007a_results/'+with_or_without+'/'+arousal_or_valence+'/'+data_file+'/'+'max_acc_'+with_or_without+'_'+arousal_or_valence+'_'+data_file+'.h5')\n",
    "            vlm=load_model('lightningedge007a_results/'+with_or_without+'/'+arousal_or_valence+'/'+data_file+'/'+'min_loss_'+with_or_without+'_'+arousal_or_valence+'_'+data_file+'.h5')\n",
    "            # pred_labels=vam()\n",
    "            vam_eval=vam.evaluate([cnn_test,rnn_test],labels_test)\n",
    "            print('max acc: ',vam_eval)\n",
    "            vlm_eval=vlm.evaluate([cnn_test,rnn_test],labels_test)\n",
    "            print('min loss: ',vlm_eval)\n",
    "\n",
    "\n",
    "            max_acc_acc_list.append(vam_eval[1])\n",
    "\n",
    "            max_acc_loss_list.append(vam_eval[0])\n",
    "\n",
    "\n",
    "            min_loss_acc_list.append(vlm_eval[1])\n",
    "\n",
    "            min_loss_loss_list.append(vlm_eval[0])\n",
    "\n",
    "            pickle.dump(max_acc_acc_list,open('lightningedge007a_results/'+with_or_without+'/'+arousal_or_valence+'/'+data_file+'/'+'max_acc_acc_list_'+with_or_without+'_'+arousal_or_valence+'_'+data_file+'.pkl','wb'))\n",
    "\n",
    "            pickle.dump(max_acc_loss_list,open('lightningedge007a_results/'+with_or_without+'/'+arousal_or_valence+'/'+data_file+'/'+'max_acc_loss_list_'+with_or_without+'_'+arousal_or_valence+'_'+data_file+'.pkl','wb'))\n",
    "\n",
    "\n",
    "            pickle.dump(min_loss_acc_list,open('lightningedge007a_results/'+with_or_without+'/'+arousal_or_valence+'/'+data_file+'/'+'min_loss_acc_list_'+with_or_without+'_'+arousal_or_valence+'_'+data_file+'.pkl','wb'))\n",
    "\n",
    "            pickle.dump(min_loss_loss_list,open('lightningedge007a_results/'+with_or_without+'/'+arousal_or_valence+'/'+data_file+'/'+'min_loss_loss_list_'+with_or_without+'_'+arousal_or_valence+'_'+data_file+'.pkl','wb'))\n",
    "            \n",
    "            \n",
    "            gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-07T12:58:37.790208Z",
     "start_time": "2019-11-07T12:58:37.785221Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-07T12:58:58.124664Z",
     "start_time": "2019-11-07T12:58:55.269298Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-08T13:35:02.701928Z",
     "start_time": "2019-11-08T13:35:02.697896Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['s06', 's07', 's08', 's09', 's10']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_files[5:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-08T13:35:03.776885Z",
     "start_time": "2019-11-08T13:35:03.772863Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['s06', 's07', 's08', 's09', 's10']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_files=data_files[5:10]\n",
    "data_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-08T14:04:38.951569Z",
     "start_time": "2019-11-08T13:35:06.645264Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------\n",
      "yes dominance s06\n",
      "---------------------------------------------------\n",
      "\n",
      "loaded shape: (2400,)\n",
      "(2400, 128, 9, 9)\n",
      "(2400, 128, 32)\n",
      "(2400,)\n",
      "(2400, 2)\n",
      "(2400, 128, 9, 9)\n",
      "(2400, 128, 32)\n",
      "(2400, 2)\n",
      "cnn_datasets.shape,rnn_datasets.shape,labels.shape :  (2400, 128, 9, 9) (2400, 128, 32) (2400, 2)\n",
      "(2400, 9, 9, 128)\n",
      "cnn_datasets.shape :  (2400, 9, 9, 128)\n",
      "========================Train / Test Shapes==============================\n",
      "(240, 9, 9, 128) (240, 128, 32) (2160, 9, 9, 128) (2160, 128, 32)\n",
      "================================ DNN ============================================\n",
      "input_cnn:  (None, 9, 9, 128)\n",
      "elu1:  (None, 9, 9, 32)\n",
      "elu2:  (None, 9, 9, 64)\n",
      "elu3:  (None, 9, 9, 128)\n",
      "reshape1:  (None, 9, 9, None)\n",
      "elu4:  (None, 9, 9, 13)\n",
      "reshape2:  (None, 1053)\n",
      "input_rnn (None, 128, 32)\n",
      "rnn_in_flat (None, None, 32)\n",
      "rnn_fc_in (None, 128, 1024)\n",
      "lstm_in (None, None, 1024)\n",
      "lstm_cell (None, 32)\n",
      "output (None, 32)\n",
      "rnn_output (32,)\n",
      "lstm_fc_out (None, 1024)\n",
      "lstm_fc_drop (None, 1024)\n",
      "fuse_cnn_rnn  (None, 2077)\n",
      "(None, 2)\n",
      "y  Tensor(\"dense_3/Softmax:0\", shape=(None, 2), dtype=float32)\n",
      "Model :  yes_dominance_s06_0_fold\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 9, 9, 128)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 9, 9, 32)     65568       input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 9, 9, 32)     128         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "elu_1 (ELU)                     (None, 9, 9, 32)     0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 9, 9, 64)     32832       elu_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 9, 9, 64)     256         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "elu_2 (ELU)                     (None, 9, 9, 64)     0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 9, 9, 128)    131200      elu_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 128, 32)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 9, 9, 128)    512         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_3 (Reshape)             (None, 128, 32)      0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "elu_3 (ELU)                     (None, 9, 9, 128)    0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 128, 1024)    33792       reshape_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 9, 9, 128)    0           elu_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "elu_5 (ELU)                     (None, 128, 1024)    0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 9, 9, 13)     1677        reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_4 (Reshape)             (None, 128, 1024)    0           elu_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 9, 9, 13)     52          conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "rnn_1 (RNN)                     (None, 32)           143616      reshape_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "elu_4 (ELU)                     (None, 9, 9, 13)     0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1024)         33792       rnn_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "reshape_2 (Reshape)             (None, 1053)         0           elu_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 1024)         0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 2077)         0           reshape_2[0][0]                  \n",
      "                                                                 dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 2)            4156        concatenate_1[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 447,581\n",
      "Trainable params: 447,107\n",
      "Non-trainable params: 474\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Train on 1728 samples, validate on 432 samples\n",
      "Epoch 1/50\n",
      " 256/1728 [===>..........................] - ETA: 20s - loss: 0.6658 - accuracy: 0.6172"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ABHISHEK_VERMA\\Anaconda3\\lib\\site-packages\\keras\\callbacks\\callbacks.py:95: RuntimeWarning: Method (on_train_batch_end) is slow compared to the batch update (9.986449). Check your callbacks.\n",
      "  % (hook_name, delta_t_median), RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1728/1728 [==============================] - 26s 15ms/step - loss: 0.3738 - accuracy: 0.8252 - val_loss: 0.1845 - val_accuracy: 0.9282\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.92824, saving model to lightningedge007a_results/yes/dominance/s06/max_acc_yes_dominance_s06.h5\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.18451, saving model to lightningedge007a_results/yes/dominance/s06/min_loss_yes_dominance_s06.h5\n",
      "Epoch 2/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 0.0805 - accuracy: 0.9711 - val_loss: 0.1362 - val_accuracy: 0.9444\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.92824 to 0.94444, saving model to lightningedge007a_results/yes/dominance/s06/max_acc_yes_dominance_s06.h5\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.18451 to 0.13615, saving model to lightningedge007a_results/yes/dominance/s06/min_loss_yes_dominance_s06.h5\n",
      "Epoch 3/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 0.0262 - accuracy: 0.9936 - val_loss: 0.0977 - val_accuracy: 0.9606\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.94444 to 0.96065, saving model to lightningedge007a_results/yes/dominance/s06/max_acc_yes_dominance_s06.h5\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.13615 to 0.09773, saving model to lightningedge007a_results/yes/dominance/s06/min_loss_yes_dominance_s06.h5\n",
      "Epoch 4/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 0.0801 - val_accuracy: 0.9722\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.96065 to 0.97222, saving model to lightningedge007a_results/yes/dominance/s06/max_acc_yes_dominance_s06.h5\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.09773 to 0.08009, saving model to lightningedge007a_results/yes/dominance/s06/min_loss_yes_dominance_s06.h5\n",
      "Epoch 5/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0703 - val_accuracy: 0.9769\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.97222 to 0.97685, saving model to lightningedge007a_results/yes/dominance/s06/max_acc_yes_dominance_s06.h5\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.08009 to 0.07029, saving model to lightningedge007a_results/yes/dominance/s06/min_loss_yes_dominance_s06.h5\n",
      "Epoch 6/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0636 - val_accuracy: 0.9745\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.97685\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.07029 to 0.06356, saving model to lightningedge007a_results/yes/dominance/s06/min_loss_yes_dominance_s06.h5\n",
      "Epoch 7/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0598 - val_accuracy: 0.9745\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.97685\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.06356 to 0.05978, saving model to lightningedge007a_results/yes/dominance/s06/min_loss_yes_dominance_s06.h5\n",
      "Epoch 8/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0577 - val_accuracy: 0.9769\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.97685\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.05978 to 0.05773, saving model to lightningedge007a_results/yes/dominance/s06/min_loss_yes_dominance_s06.h5\n",
      "Epoch 9/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0564 - val_accuracy: 0.9769\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.97685\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.05773 to 0.05642, saving model to lightningedge007a_results/yes/dominance/s06/min_loss_yes_dominance_s06.h5\n",
      "Epoch 10/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 9.1177e-04 - accuracy: 1.0000 - val_loss: 0.0551 - val_accuracy: 0.9769\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.97685\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.05642 to 0.05515, saving model to lightningedge007a_results/yes/dominance/s06/min_loss_yes_dominance_s06.h5\n",
      "Epoch 11/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 7.8825e-04 - accuracy: 1.0000 - val_loss: 0.0541 - val_accuracy: 0.9769\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.97685\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.05515 to 0.05405, saving model to lightningedge007a_results/yes/dominance/s06/min_loss_yes_dominance_s06.h5\n",
      "Epoch 12/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 6.9645e-04 - accuracy: 1.0000 - val_loss: 0.0530 - val_accuracy: 0.9769\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.97685\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.05405 to 0.05303, saving model to lightningedge007a_results/yes/dominance/s06/min_loss_yes_dominance_s06.h5\n",
      "Epoch 13/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 6.0414e-04 - accuracy: 1.0000 - val_loss: 0.0529 - val_accuracy: 0.9769\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.97685\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.05303 to 0.05294, saving model to lightningedge007a_results/yes/dominance/s06/min_loss_yes_dominance_s06.h5\n",
      "Epoch 14/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 5.4547e-04 - accuracy: 1.0000 - val_loss: 0.0521 - val_accuracy: 0.9769\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.97685\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.05294 to 0.05208, saving model to lightningedge007a_results/yes/dominance/s06/min_loss_yes_dominance_s06.h5\n",
      "Epoch 15/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 4.8463e-04 - accuracy: 1.0000 - val_loss: 0.0519 - val_accuracy: 0.9769\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.97685\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.05208 to 0.05186, saving model to lightningedge007a_results/yes/dominance/s06/min_loss_yes_dominance_s06.h5\n",
      "Epoch 16/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 4.3691e-04 - accuracy: 1.0000 - val_loss: 0.0515 - val_accuracy: 0.9769\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.97685\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.05186 to 0.05145, saving model to lightningedge007a_results/yes/dominance/s06/min_loss_yes_dominance_s06.h5\n",
      "Epoch 17/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 3.9593e-04 - accuracy: 1.0000 - val_loss: 0.0513 - val_accuracy: 0.9769\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.97685\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.05145 to 0.05127, saving model to lightningedge007a_results/yes/dominance/s06/min_loss_yes_dominance_s06.h5\n",
      "Epoch 18/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 3.5994e-04 - accuracy: 1.0000 - val_loss: 0.0513 - val_accuracy: 0.9769\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.97685\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.05127 to 0.05125, saving model to lightningedge007a_results/yes/dominance/s06/min_loss_yes_dominance_s06.h5\n",
      "Epoch 19/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 3.3138e-04 - accuracy: 1.0000 - val_loss: 0.0513 - val_accuracy: 0.9769\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.97685\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.05125\n",
      "Epoch 20/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 3.0549e-04 - accuracy: 1.0000 - val_loss: 0.0513 - val_accuracy: 0.9769\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.97685\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.05125\n",
      "Epoch 21/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 2.8152e-04 - accuracy: 1.0000 - val_loss: 0.0513 - val_accuracy: 0.9769\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.97685\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.05125\n",
      "Epoch 22/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 2.6163e-04 - accuracy: 1.0000 - val_loss: 0.0508 - val_accuracy: 0.9769\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.97685\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.05125 to 0.05085, saving model to lightningedge007a_results/yes/dominance/s06/min_loss_yes_dominance_s06.h5\n",
      "Epoch 23/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 2.4146e-04 - accuracy: 1.0000 - val_loss: 0.0510 - val_accuracy: 0.9769\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.97685\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.05085\n",
      "Epoch 24/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 2.2863e-04 - accuracy: 1.0000 - val_loss: 0.0510 - val_accuracy: 0.9769\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.97685\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.05085\n",
      "Epoch 25/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 2.1117e-04 - accuracy: 1.0000 - val_loss: 0.0511 - val_accuracy: 0.9769\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.97685\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.05085\n",
      "Epoch 26/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.9597e-04 - accuracy: 1.0000 - val_loss: 0.0511 - val_accuracy: 0.9769\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.97685\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.05085\n",
      "Epoch 27/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.8392e-04 - accuracy: 1.0000 - val_loss: 0.0507 - val_accuracy: 0.9769\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.97685\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.05085 to 0.05074, saving model to lightningedge007a_results/yes/dominance/s06/min_loss_yes_dominance_s06.h5\n",
      "Epoch 28/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.7350e-04 - accuracy: 1.0000 - val_loss: 0.0510 - val_accuracy: 0.9769\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.97685\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.05074\n",
      "Epoch 29/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.6168e-04 - accuracy: 1.0000 - val_loss: 0.0508 - val_accuracy: 0.9769\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.97685\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.05074\n",
      "Epoch 30/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.5372e-04 - accuracy: 1.0000 - val_loss: 0.0509 - val_accuracy: 0.9769\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.97685\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.05074\n",
      "Epoch 31/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.4365e-04 - accuracy: 1.0000 - val_loss: 0.0510 - val_accuracy: 0.9769\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.97685\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.05074\n",
      "Epoch 32/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.3812e-04 - accuracy: 1.0000 - val_loss: 0.0510 - val_accuracy: 0.9769\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.97685\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.05074\n",
      "Epoch 33/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.3058e-04 - accuracy: 1.0000 - val_loss: 0.0511 - val_accuracy: 0.9769\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.97685\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.05074\n",
      "Epoch 34/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.2235e-04 - accuracy: 1.0000 - val_loss: 0.0512 - val_accuracy: 0.9769\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.97685\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.05074\n",
      "Epoch 35/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.1814e-04 - accuracy: 1.0000 - val_loss: 0.0512 - val_accuracy: 0.9769\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.97685\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.05074\n",
      "Epoch 36/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.1216e-04 - accuracy: 1.0000 - val_loss: 0.0512 - val_accuracy: 0.9769\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.97685\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.05074\n",
      "Epoch 37/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.0712e-04 - accuracy: 1.0000 - val_loss: 0.0513 - val_accuracy: 0.9769\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.97685\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.05074\n",
      "Epoch 38/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.0171e-04 - accuracy: 1.0000 - val_loss: 0.0516 - val_accuracy: 0.9769\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.97685\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.05074\n",
      "Epoch 39/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 9.6953e-05 - accuracy: 1.0000 - val_loss: 0.0516 - val_accuracy: 0.9769\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.97685\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.05074\n",
      "Epoch 40/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 9.2736e-05 - accuracy: 1.0000 - val_loss: 0.0517 - val_accuracy: 0.9769\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.97685\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.05074\n",
      "Epoch 41/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 8.8545e-05 - accuracy: 1.0000 - val_loss: 0.0515 - val_accuracy: 0.9769\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.97685\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.05074\n",
      "Epoch 42/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 8.5446e-05 - accuracy: 1.0000 - val_loss: 0.0516 - val_accuracy: 0.9769\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.97685\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.05074\n",
      "Epoch 43/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 8.1068e-05 - accuracy: 1.0000 - val_loss: 0.0516 - val_accuracy: 0.9769\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.97685\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.05074\n",
      "Epoch 44/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 7.8319e-05 - accuracy: 1.0000 - val_loss: 0.0517 - val_accuracy: 0.9769\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.97685\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.05074\n",
      "Epoch 45/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 7.4728e-05 - accuracy: 1.0000 - val_loss: 0.0517 - val_accuracy: 0.9769\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.97685\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.05074\n",
      "Epoch 46/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 7.2029e-05 - accuracy: 1.0000 - val_loss: 0.0518 - val_accuracy: 0.9769\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.97685\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.05074\n",
      "Epoch 47/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 6.9663e-05 - accuracy: 1.0000 - val_loss: 0.0518 - val_accuracy: 0.9769\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.97685\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.05074\n",
      "Epoch 48/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 6.7163e-05 - accuracy: 1.0000 - val_loss: 0.0520 - val_accuracy: 0.9769\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.97685\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.05074\n",
      "Epoch 49/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 6.5089e-05 - accuracy: 1.0000 - val_loss: 0.0521 - val_accuracy: 0.9792\n",
      "\n",
      "Epoch 00049: val_accuracy improved from 0.97685 to 0.97917, saving model to lightningedge007a_results/yes/dominance/s06/max_acc_yes_dominance_s06.h5\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.05074\n",
      "Epoch 50/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 6.2473e-05 - accuracy: 1.0000 - val_loss: 0.0523 - val_accuracy: 0.9792\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.97917\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.05074\n",
      "240/240 [==============================] - 1s 4ms/step\n",
      "max acc:  [0.0820405123134454, 0.9666666388511658]\n",
      "240/240 [==============================] - 1s 3ms/step\n",
      "min loss:  [0.0824745141590635, 0.9666666388511658]\n",
      "---------------------------------------------------\n",
      "yes dominance s07\n",
      "---------------------------------------------------\n",
      "\n",
      "loaded shape: (2400,)\n",
      "(2400, 128, 9, 9)\n",
      "(2400, 128, 32)\n",
      "(2400,)\n",
      "(2400, 2)\n",
      "(2400, 128, 9, 9)\n",
      "(2400, 128, 32)\n",
      "(2400, 2)\n",
      "cnn_datasets.shape,rnn_datasets.shape,labels.shape :  (2400, 128, 9, 9) (2400, 128, 32) (2400, 2)\n",
      "(2400, 9, 9, 128)\n",
      "cnn_datasets.shape :  (2400, 9, 9, 128)\n",
      "========================Train / Test Shapes==============================\n",
      "(240, 9, 9, 128) (240, 128, 32) (2160, 9, 9, 128) (2160, 128, 32)\n",
      "================================ DNN ============================================\n",
      "input_cnn:  (None, 9, 9, 128)\n",
      "elu1:  (None, 9, 9, 32)\n",
      "elu2:  (None, 9, 9, 64)\n",
      "elu3:  (None, 9, 9, 128)\n",
      "reshape1:  (None, 9, 9, None)\n",
      "elu4:  (None, 9, 9, 13)\n",
      "reshape2:  (None, 1053)\n",
      "input_rnn (None, 128, 32)\n",
      "rnn_in_flat (None, None, 32)\n",
      "rnn_fc_in (None, 128, 1024)\n",
      "lstm_in (None, None, 1024)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lstm_cell (None, 32)\n",
      "output (None, 32)\n",
      "rnn_output (32,)\n",
      "lstm_fc_out (None, 1024)\n",
      "lstm_fc_drop (None, 1024)\n",
      "fuse_cnn_rnn  (None, 2077)\n",
      "(None, 2)\n",
      "y  Tensor(\"dense_6/Softmax:0\", shape=(None, 2), dtype=float32)\n",
      "Model :  yes_dominance_s07_0_fold\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 9, 9, 128)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 9, 9, 32)     65568       input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 9, 9, 32)     128         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "elu_6 (ELU)                     (None, 9, 9, 32)     0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 9, 9, 64)     32832       elu_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 9, 9, 64)     256         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "elu_7 (ELU)                     (None, 9, 9, 64)     0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 9, 9, 128)    131200      elu_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            (None, 128, 32)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 9, 9, 128)    512         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_7 (Reshape)             (None, 128, 32)      0           input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "elu_8 (ELU)                     (None, 9, 9, 128)    0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 128, 1024)    33792       reshape_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_5 (Reshape)             (None, 9, 9, 128)    0           elu_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "elu_10 (ELU)                    (None, 128, 1024)    0           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 9, 9, 13)     1677        reshape_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_8 (Reshape)             (None, 128, 1024)    0           elu_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 9, 9, 13)     52          conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "rnn_2 (RNN)                     (None, 32)           143616      reshape_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "elu_9 (ELU)                     (None, 9, 9, 13)     0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 1024)         33792       rnn_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "reshape_6 (Reshape)             (None, 1053)         0           elu_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 1024)         0           dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 2077)         0           reshape_6[0][0]                  \n",
      "                                                                 dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 2)            4156        concatenate_2[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 447,581\n",
      "Trainable params: 447,107\n",
      "Non-trainable params: 474\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Train on 1728 samples, validate on 432 samples\n",
      "Epoch 1/50\n",
      " 256/1728 [===>..........................] - ETA: 10s - loss: 0.6726 - accuracy: 0.6133"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ABHISHEK_VERMA\\Anaconda3\\lib\\site-packages\\keras\\callbacks\\callbacks.py:95: RuntimeWarning: Method (on_train_batch_end) is slow compared to the batch update (9.856547). Check your callbacks.\n",
      "  % (hook_name, delta_t_median), RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1728/1728 [==============================] - 24s 14ms/step - loss: 0.2438 - accuracy: 0.8802 - val_loss: 0.1295 - val_accuracy: 0.9606\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.96065, saving model to lightningedge007a_results/yes/dominance/s07/max_acc_yes_dominance_s07.h5\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.12952, saving model to lightningedge007a_results/yes/dominance/s07/min_loss_yes_dominance_s07.h5\n",
      "Epoch 2/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 0.0233 - accuracy: 0.9948 - val_loss: 0.0761 - val_accuracy: 0.9769\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.96065 to 0.97685, saving model to lightningedge007a_results/yes/dominance/s07/max_acc_yes_dominance_s07.h5\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.12952 to 0.07607, saving model to lightningedge007a_results/yes/dominance/s07/min_loss_yes_dominance_s07.h5\n",
      "Epoch 3/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.0608 - val_accuracy: 0.9815\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.97685 to 0.98148, saving model to lightningedge007a_results/yes/dominance/s07/max_acc_yes_dominance_s07.h5\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.07607 to 0.06079, saving model to lightningedge007a_results/yes/dominance/s07/min_loss_yes_dominance_s07.h5\n",
      "Epoch 4/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0501 - val_accuracy: 0.9815\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.98148\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.06079 to 0.05010, saving model to lightningedge007a_results/yes/dominance/s07/min_loss_yes_dominance_s07.h5\n",
      "Epoch 5/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 8.9125e-04 - accuracy: 1.0000 - val_loss: 0.0455 - val_accuracy: 0.9815\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.98148\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.05010 to 0.04555, saving model to lightningedge007a_results/yes/dominance/s07/min_loss_yes_dominance_s07.h5\n",
      "Epoch 6/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 6.3364e-04 - accuracy: 1.0000 - val_loss: 0.0434 - val_accuracy: 0.9838\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.98148 to 0.98380, saving model to lightningedge007a_results/yes/dominance/s07/max_acc_yes_dominance_s07.h5\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.04555 to 0.04336, saving model to lightningedge007a_results/yes/dominance/s07/min_loss_yes_dominance_s07.h5\n",
      "Epoch 7/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 4.8751e-04 - accuracy: 1.0000 - val_loss: 0.0417 - val_accuracy: 0.9861\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.98380 to 0.98611, saving model to lightningedge007a_results/yes/dominance/s07/max_acc_yes_dominance_s07.h5\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.04336 to 0.04166, saving model to lightningedge007a_results/yes/dominance/s07/min_loss_yes_dominance_s07.h5\n",
      "Epoch 8/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 4.2344e-04 - accuracy: 1.0000 - val_loss: 0.0403 - val_accuracy: 0.9861\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.98611\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.04166 to 0.04034, saving model to lightningedge007a_results/yes/dominance/s07/min_loss_yes_dominance_s07.h5\n",
      "Epoch 9/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 3.4875e-04 - accuracy: 1.0000 - val_loss: 0.0394 - val_accuracy: 0.9861\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.98611\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.04034 to 0.03944, saving model to lightningedge007a_results/yes/dominance/s07/min_loss_yes_dominance_s07.h5\n",
      "Epoch 10/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 3.3010e-04 - accuracy: 1.0000 - val_loss: 0.0390 - val_accuracy: 0.9884\n",
      "\n",
      "Epoch 00010: val_accuracy improved from 0.98611 to 0.98843, saving model to lightningedge007a_results/yes/dominance/s07/max_acc_yes_dominance_s07.h5\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.03944 to 0.03900, saving model to lightningedge007a_results/yes/dominance/s07/min_loss_yes_dominance_s07.h5\n",
      "Epoch 11/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 2.8505e-04 - accuracy: 1.0000 - val_loss: 0.0385 - val_accuracy: 0.9884\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.98843\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.03900 to 0.03846, saving model to lightningedge007a_results/yes/dominance/s07/min_loss_yes_dominance_s07.h5\n",
      "Epoch 12/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 2.5748e-04 - accuracy: 1.0000 - val_loss: 0.0379 - val_accuracy: 0.9884\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.98843\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.03846 to 0.03789, saving model to lightningedge007a_results/yes/dominance/s07/min_loss_yes_dominance_s07.h5\n",
      "Epoch 13/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 2.2969e-04 - accuracy: 1.0000 - val_loss: 0.0376 - val_accuracy: 0.9884\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.98843\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.03789 to 0.03761, saving model to lightningedge007a_results/yes/dominance/s07/min_loss_yes_dominance_s07.h5\n",
      "Epoch 14/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 2.0971e-04 - accuracy: 1.0000 - val_loss: 0.0372 - val_accuracy: 0.9884\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.98843\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.03761 to 0.03718, saving model to lightningedge007a_results/yes/dominance/s07/min_loss_yes_dominance_s07.h5\n",
      "Epoch 15/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.9415e-04 - accuracy: 1.0000 - val_loss: 0.0368 - val_accuracy: 0.9884\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.98843\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.03718 to 0.03680, saving model to lightningedge007a_results/yes/dominance/s07/min_loss_yes_dominance_s07.h5\n",
      "Epoch 16/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.7856e-04 - accuracy: 1.0000 - val_loss: 0.0366 - val_accuracy: 0.9884\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.98843\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.03680 to 0.03655, saving model to lightningedge007a_results/yes/dominance/s07/min_loss_yes_dominance_s07.h5\n",
      "Epoch 17/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.6273e-04 - accuracy: 1.0000 - val_loss: 0.0363 - val_accuracy: 0.9884\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.98843\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.03655 to 0.03633, saving model to lightningedge007a_results/yes/dominance/s07/min_loss_yes_dominance_s07.h5\n",
      "Epoch 18/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.5151e-04 - accuracy: 1.0000 - val_loss: 0.0362 - val_accuracy: 0.9884\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.98843\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.03633 to 0.03619, saving model to lightningedge007a_results/yes/dominance/s07/min_loss_yes_dominance_s07.h5\n",
      "Epoch 19/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.4028e-04 - accuracy: 1.0000 - val_loss: 0.0361 - val_accuracy: 0.9884\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.98843\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.03619 to 0.03608, saving model to lightningedge007a_results/yes/dominance/s07/min_loss_yes_dominance_s07.h5\n",
      "Epoch 20/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.3493e-04 - accuracy: 1.0000 - val_loss: 0.0360 - val_accuracy: 0.9884\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.98843\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.03608 to 0.03602, saving model to lightningedge007a_results/yes/dominance/s07/min_loss_yes_dominance_s07.h5\n",
      "Epoch 21/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.2187e-04 - accuracy: 1.0000 - val_loss: 0.0359 - val_accuracy: 0.9884\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.98843\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.03602 to 0.03587, saving model to lightningedge007a_results/yes/dominance/s07/min_loss_yes_dominance_s07.h5\n",
      "Epoch 22/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.1532e-04 - accuracy: 1.0000 - val_loss: 0.0357 - val_accuracy: 0.9884\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.98843\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.03587 to 0.03574, saving model to lightningedge007a_results/yes/dominance/s07/min_loss_yes_dominance_s07.h5\n",
      "Epoch 23/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.0865e-04 - accuracy: 1.0000 - val_loss: 0.0356 - val_accuracy: 0.9884\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.98843\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.03574 to 0.03559, saving model to lightningedge007a_results/yes/dominance/s07/min_loss_yes_dominance_s07.h5\n",
      "Epoch 24/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.0227e-04 - accuracy: 1.0000 - val_loss: 0.0354 - val_accuracy: 0.9884\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.98843\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.03559 to 0.03539, saving model to lightningedge007a_results/yes/dominance/s07/min_loss_yes_dominance_s07.h5\n",
      "Epoch 25/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 9.7388e-05 - accuracy: 1.0000 - val_loss: 0.0353 - val_accuracy: 0.9884\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.98843\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.03539 to 0.03534, saving model to lightningedge007a_results/yes/dominance/s07/min_loss_yes_dominance_s07.h5\n",
      "Epoch 26/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 9.1360e-05 - accuracy: 1.0000 - val_loss: 0.0353 - val_accuracy: 0.9884\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.98843\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.03534 to 0.03533, saving model to lightningedge007a_results/yes/dominance/s07/min_loss_yes_dominance_s07.h5\n",
      "Epoch 27/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 8.8723e-05 - accuracy: 1.0000 - val_loss: 0.0353 - val_accuracy: 0.9884\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.98843\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.03533 to 0.03530, saving model to lightningedge007a_results/yes/dominance/s07/min_loss_yes_dominance_s07.h5\n",
      "Epoch 28/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 8.2457e-05 - accuracy: 1.0000 - val_loss: 0.0352 - val_accuracy: 0.9884\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.98843\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.03530 to 0.03524, saving model to lightningedge007a_results/yes/dominance/s07/min_loss_yes_dominance_s07.h5\n",
      "Epoch 29/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 7.7269e-05 - accuracy: 1.0000 - val_loss: 0.0353 - val_accuracy: 0.9884\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.98843\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.03524\n",
      "Epoch 30/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 7.4296e-05 - accuracy: 1.0000 - val_loss: 0.0353 - val_accuracy: 0.9884\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.98843\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.03524\n",
      "Epoch 31/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 7.2083e-05 - accuracy: 1.0000 - val_loss: 0.0352 - val_accuracy: 0.9884\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.98843\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.03524 to 0.03524, saving model to lightningedge007a_results/yes/dominance/s07/min_loss_yes_dominance_s07.h5\n",
      "Epoch 32/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 6.7337e-05 - accuracy: 1.0000 - val_loss: 0.0353 - val_accuracy: 0.9884\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.98843\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.03524\n",
      "Epoch 33/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 6.3427e-05 - accuracy: 1.0000 - val_loss: 0.0352 - val_accuracy: 0.9884\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.98843\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.03524 to 0.03522, saving model to lightningedge007a_results/yes/dominance/s07/min_loss_yes_dominance_s07.h5\n",
      "Epoch 34/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 6.1081e-05 - accuracy: 1.0000 - val_loss: 0.0353 - val_accuracy: 0.9884\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.98843\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.03522\n",
      "Epoch 35/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 5.9788e-05 - accuracy: 1.0000 - val_loss: 0.0353 - val_accuracy: 0.9884\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.98843\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.03522\n",
      "Epoch 36/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 5.6315e-05 - accuracy: 1.0000 - val_loss: 0.0353 - val_accuracy: 0.9884\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.98843\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.03522\n",
      "Epoch 37/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 5.4355e-05 - accuracy: 1.0000 - val_loss: 0.0353 - val_accuracy: 0.9884\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.98843\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.03522\n",
      "Epoch 38/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 5.1279e-05 - accuracy: 1.0000 - val_loss: 0.0353 - val_accuracy: 0.9884\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.98843\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.03522\n",
      "Epoch 39/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 4.9379e-05 - accuracy: 1.0000 - val_loss: 0.0353 - val_accuracy: 0.9884\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.98843\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.03522\n",
      "Epoch 40/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 4.6615e-05 - accuracy: 1.0000 - val_loss: 0.0354 - val_accuracy: 0.9884\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.98843\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.03522\n",
      "Epoch 41/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 4.6078e-05 - accuracy: 1.0000 - val_loss: 0.0354 - val_accuracy: 0.9884\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.98843\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.03522\n",
      "Epoch 42/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 4.3791e-05 - accuracy: 1.0000 - val_loss: 0.0354 - val_accuracy: 0.9884\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.98843\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.03522\n",
      "Epoch 43/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 4.1712e-05 - accuracy: 1.0000 - val_loss: 0.0354 - val_accuracy: 0.9884\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.98843\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.03522\n",
      "Epoch 44/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 4.1162e-05 - accuracy: 1.0000 - val_loss: 0.0354 - val_accuracy: 0.9884\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.98843\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.03522\n",
      "Epoch 45/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 3.9247e-05 - accuracy: 1.0000 - val_loss: 0.0354 - val_accuracy: 0.9884\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.98843\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.03522\n",
      "Epoch 46/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 3.7705e-05 - accuracy: 1.0000 - val_loss: 0.0354 - val_accuracy: 0.9884\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.98843\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.03522\n",
      "Epoch 47/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 3.7370e-05 - accuracy: 1.0000 - val_loss: 0.0354 - val_accuracy: 0.9884\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.98843\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.03522\n",
      "Epoch 48/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 3.5328e-05 - accuracy: 1.0000 - val_loss: 0.0353 - val_accuracy: 0.9884\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.98843\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.03522\n",
      "Epoch 49/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 3.4578e-05 - accuracy: 1.0000 - val_loss: 0.0353 - val_accuracy: 0.9884\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.98843\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.03522\n",
      "Epoch 50/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 3.3477e-05 - accuracy: 1.0000 - val_loss: 0.0354 - val_accuracy: 0.9884\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.98843\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.03522\n",
      "240/240 [==============================] - 1s 3ms/step\n",
      "max acc:  [0.05043816187729438, 0.987500011920929]\n",
      "240/240 [==============================] - 1s 4ms/step\n",
      "min loss:  [0.040355025061095756, 0.9916666746139526]\n",
      "---------------------------------------------------\n",
      "yes dominance s08\n",
      "---------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded shape: (2400,)\n",
      "(2400, 128, 9, 9)\n",
      "(2400, 128, 32)\n",
      "(2400,)\n",
      "(2400, 2)\n",
      "(2400, 128, 9, 9)\n",
      "(2400, 128, 32)\n",
      "(2400, 2)\n",
      "cnn_datasets.shape,rnn_datasets.shape,labels.shape :  (2400, 128, 9, 9) (2400, 128, 32) (2400, 2)\n",
      "(2400, 9, 9, 128)\n",
      "cnn_datasets.shape :  (2400, 9, 9, 128)\n",
      "========================Train / Test Shapes==============================\n",
      "(240, 9, 9, 128) (240, 128, 32) (2160, 9, 9, 128) (2160, 128, 32)\n",
      "================================ DNN ============================================\n",
      "input_cnn:  (None, 9, 9, 128)\n",
      "elu1:  (None, 9, 9, 32)\n",
      "elu2:  (None, 9, 9, 64)\n",
      "elu3:  (None, 9, 9, 128)\n",
      "reshape1:  (None, 9, 9, None)\n",
      "elu4:  (None, 9, 9, 13)\n",
      "reshape2:  (None, 1053)\n",
      "input_rnn (None, 128, 32)\n",
      "rnn_in_flat (None, None, 32)\n",
      "rnn_fc_in (None, 128, 1024)\n",
      "lstm_in (None, None, 1024)\n",
      "lstm_cell (None, 32)\n",
      "output (None, 32)\n",
      "rnn_output (32,)\n",
      "lstm_fc_out (None, 1024)\n",
      "lstm_fc_drop (None, 1024)\n",
      "fuse_cnn_rnn  (None, 2077)\n",
      "(None, 2)\n",
      "y  Tensor(\"dense_9/Softmax:0\", shape=(None, 2), dtype=float32)\n",
      "Model :  yes_dominance_s08_0_fold\n",
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            (None, 9, 9, 128)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 9, 9, 32)     65568       input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 9, 9, 32)     128         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "elu_11 (ELU)                    (None, 9, 9, 32)     0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 9, 9, 64)     32832       elu_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 9, 9, 64)     256         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "elu_12 (ELU)                    (None, 9, 9, 64)     0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 9, 9, 128)    131200      elu_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "input_6 (InputLayer)            (None, 128, 32)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 9, 9, 128)    512         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_11 (Reshape)            (None, 128, 32)      0           input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "elu_13 (ELU)                    (None, 9, 9, 128)    0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 128, 1024)    33792       reshape_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_9 (Reshape)             (None, 9, 9, 128)    0           elu_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "elu_15 (ELU)                    (None, 128, 1024)    0           dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 9, 9, 13)     1677        reshape_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_12 (Reshape)            (None, 128, 1024)    0           elu_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 9, 9, 13)     52          conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "rnn_3 (RNN)                     (None, 32)           143616      reshape_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "elu_14 (ELU)                    (None, 9, 9, 13)     0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 1024)         33792       rnn_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "reshape_10 (Reshape)            (None, 1053)         0           elu_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 1024)         0           dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 2077)         0           reshape_10[0][0]                 \n",
      "                                                                 dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 2)            4156        concatenate_3[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 447,581\n",
      "Trainable params: 447,107\n",
      "Non-trainable params: 474\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Train on 1728 samples, validate on 432 samples\n",
      "Epoch 1/50\n",
      " 256/1728 [===>..........................] - ETA: 11s - loss: 0.8393 - accuracy: 0.5234"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ABHISHEK_VERMA\\Anaconda3\\lib\\site-packages\\keras\\callbacks\\callbacks.py:95: RuntimeWarning: Method (on_train_batch_end) is slow compared to the batch update (10.404941). Check your callbacks.\n",
      "  % (hook_name, delta_t_median), RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1728/1728 [==============================] - 25s 15ms/step - loss: 0.3713 - accuracy: 0.8333 - val_loss: 0.1645 - val_accuracy: 0.9444\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.94444, saving model to lightningedge007a_results/yes/dominance/s08/max_acc_yes_dominance_s08.h5\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.16446, saving model to lightningedge007a_results/yes/dominance/s08/min_loss_yes_dominance_s08.h5\n",
      "Epoch 2/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 0.0578 - accuracy: 0.9821 - val_loss: 0.1054 - val_accuracy: 0.9699\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.94444 to 0.96991, saving model to lightningedge007a_results/yes/dominance/s08/max_acc_yes_dominance_s08.h5\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.16446 to 0.10535, saving model to lightningedge007a_results/yes/dominance/s08/min_loss_yes_dominance_s08.h5\n",
      "Epoch 3/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 0.0184 - accuracy: 0.9965 - val_loss: 0.0978 - val_accuracy: 0.9653\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.96991\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.10535 to 0.09780, saving model to lightningedge007a_results/yes/dominance/s08/min_loss_yes_dominance_s08.h5\n",
      "Epoch 4/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 0.0077 - accuracy: 0.9994 - val_loss: 0.0735 - val_accuracy: 0.9722\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.96991 to 0.97222, saving model to lightningedge007a_results/yes/dominance/s08/max_acc_yes_dominance_s08.h5\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.09780 to 0.07348, saving model to lightningedge007a_results/yes/dominance/s08/min_loss_yes_dominance_s08.h5\n",
      "Epoch 5/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0606 - val_accuracy: 0.9838\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.97222 to 0.98380, saving model to lightningedge007a_results/yes/dominance/s08/max_acc_yes_dominance_s08.h5\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.07348 to 0.06061, saving model to lightningedge007a_results/yes/dominance/s08/min_loss_yes_dominance_s08.h5\n",
      "Epoch 6/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0584 - val_accuracy: 0.9861\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.98380 to 0.98611, saving model to lightningedge007a_results/yes/dominance/s08/max_acc_yes_dominance_s08.h5\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.06061 to 0.05841, saving model to lightningedge007a_results/yes/dominance/s08/min_loss_yes_dominance_s08.h5\n",
      "Epoch 7/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0554 - val_accuracy: 0.9838\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.98611\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.05841 to 0.05543, saving model to lightningedge007a_results/yes/dominance/s08/min_loss_yes_dominance_s08.h5\n",
      "Epoch 8/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 9.6022e-04 - accuracy: 1.0000 - val_loss: 0.0537 - val_accuracy: 0.9838\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.98611\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.05543 to 0.05366, saving model to lightningedge007a_results/yes/dominance/s08/min_loss_yes_dominance_s08.h5\n",
      "Epoch 9/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 8.1127e-04 - accuracy: 1.0000 - val_loss: 0.0527 - val_accuracy: 0.9838\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.98611\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.05366 to 0.05268, saving model to lightningedge007a_results/yes/dominance/s08/min_loss_yes_dominance_s08.h5\n",
      "Epoch 10/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 7.0255e-04 - accuracy: 1.0000 - val_loss: 0.0519 - val_accuracy: 0.9838\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.98611\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.05268 to 0.05192, saving model to lightningedge007a_results/yes/dominance/s08/min_loss_yes_dominance_s08.h5\n",
      "Epoch 11/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 6.2292e-04 - accuracy: 1.0000 - val_loss: 0.0517 - val_accuracy: 0.9838\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.98611\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.05192 to 0.05174, saving model to lightningedge007a_results/yes/dominance/s08/min_loss_yes_dominance_s08.h5\n",
      "Epoch 12/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 5.5096e-04 - accuracy: 1.0000 - val_loss: 0.0513 - val_accuracy: 0.9838\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.98611\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.05174 to 0.05134, saving model to lightningedge007a_results/yes/dominance/s08/min_loss_yes_dominance_s08.h5\n",
      "Epoch 13/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 4.9857e-04 - accuracy: 1.0000 - val_loss: 0.0508 - val_accuracy: 0.9838\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.98611\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.05134 to 0.05080, saving model to lightningedge007a_results/yes/dominance/s08/min_loss_yes_dominance_s08.h5\n",
      "Epoch 14/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 4.4298e-04 - accuracy: 1.0000 - val_loss: 0.0503 - val_accuracy: 0.9838\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.98611\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.05080 to 0.05027, saving model to lightningedge007a_results/yes/dominance/s08/min_loss_yes_dominance_s08.h5\n",
      "Epoch 15/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 3.9828e-04 - accuracy: 1.0000 - val_loss: 0.0501 - val_accuracy: 0.9838\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.98611\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.05027 to 0.05014, saving model to lightningedge007a_results/yes/dominance/s08/min_loss_yes_dominance_s08.h5\n",
      "Epoch 16/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 3.6743e-04 - accuracy: 1.0000 - val_loss: 0.0501 - val_accuracy: 0.9838\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.98611\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.05014 to 0.05011, saving model to lightningedge007a_results/yes/dominance/s08/min_loss_yes_dominance_s08.h5\n",
      "Epoch 17/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 3.3380e-04 - accuracy: 1.0000 - val_loss: 0.0500 - val_accuracy: 0.9861\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.98611\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.05011 to 0.05003, saving model to lightningedge007a_results/yes/dominance/s08/min_loss_yes_dominance_s08.h5\n",
      "Epoch 18/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 3.1205e-04 - accuracy: 1.0000 - val_loss: 0.0501 - val_accuracy: 0.9861\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.98611\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.05003\n",
      "Epoch 19/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 2.8394e-04 - accuracy: 1.0000 - val_loss: 0.0500 - val_accuracy: 0.9861\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.98611\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.05003 to 0.04995, saving model to lightningedge007a_results/yes/dominance/s08/min_loss_yes_dominance_s08.h5\n",
      "Epoch 20/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 2.6206e-04 - accuracy: 1.0000 - val_loss: 0.0500 - val_accuracy: 0.9861\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.98611\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.04995\n",
      "Epoch 21/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 2.4419e-04 - accuracy: 1.0000 - val_loss: 0.0501 - val_accuracy: 0.9861\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.98611\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.04995\n",
      "Epoch 22/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 2.2623e-04 - accuracy: 1.0000 - val_loss: 0.0502 - val_accuracy: 0.9861\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.98611\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.04995\n",
      "Epoch 23/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 2.1249e-04 - accuracy: 1.0000 - val_loss: 0.0502 - val_accuracy: 0.9861\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.98611\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.04995\n",
      "Epoch 24/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.9893e-04 - accuracy: 1.0000 - val_loss: 0.0502 - val_accuracy: 0.9861\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.98611\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.04995\n",
      "Epoch 25/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.8609e-04 - accuracy: 1.0000 - val_loss: 0.0502 - val_accuracy: 0.9861\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.98611\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.04995\n",
      "Epoch 26/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.7574e-04 - accuracy: 1.0000 - val_loss: 0.0504 - val_accuracy: 0.9861\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.98611\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.04995\n",
      "Epoch 27/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.6484e-04 - accuracy: 1.0000 - val_loss: 0.0504 - val_accuracy: 0.9861\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.98611\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.04995\n",
      "Epoch 28/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.5562e-04 - accuracy: 1.0000 - val_loss: 0.0505 - val_accuracy: 0.9861\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.98611\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.04995\n",
      "Epoch 29/50\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.4667e-04 - accuracy: 1.0000 - val_loss: 0.0505 - val_accuracy: 0.9861\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.98611\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.04995\n",
      "Epoch 30/50\n",
      "1728/1728 [==============================] - 4s 2ms/step - loss: 1.3834e-04 - accuracy: 1.0000 - val_loss: 0.0505 - val_accuracy: 0.9861\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.98611\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.04995\n",
      "Epoch 31/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.3167e-04 - accuracy: 1.0000 - val_loss: 0.0507 - val_accuracy: 0.9861\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.98611\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.04995\n",
      "Epoch 32/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.2621e-04 - accuracy: 1.0000 - val_loss: 0.0506 - val_accuracy: 0.9861\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.98611\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.04995\n",
      "Epoch 33/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.1940e-04 - accuracy: 1.0000 - val_loss: 0.0509 - val_accuracy: 0.9861\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.98611\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.04995\n",
      "Epoch 34/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.1210e-04 - accuracy: 1.0000 - val_loss: 0.0508 - val_accuracy: 0.9861\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.98611\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.04995\n",
      "Epoch 35/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.0762e-04 - accuracy: 1.0000 - val_loss: 0.0511 - val_accuracy: 0.9861\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.98611\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.04995\n",
      "Epoch 36/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.0201e-04 - accuracy: 1.0000 - val_loss: 0.0510 - val_accuracy: 0.9861\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.98611\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.04995\n",
      "Epoch 37/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 9.7360e-05 - accuracy: 1.0000 - val_loss: 0.0511 - val_accuracy: 0.9861\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.98611\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.04995\n",
      "Epoch 38/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 9.3719e-05 - accuracy: 1.0000 - val_loss: 0.0511 - val_accuracy: 0.9861\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.98611\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.04995\n",
      "Epoch 39/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 8.9580e-05 - accuracy: 1.0000 - val_loss: 0.0511 - val_accuracy: 0.9861\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.98611\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.04995\n",
      "Epoch 40/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 8.5192e-05 - accuracy: 1.0000 - val_loss: 0.0511 - val_accuracy: 0.9861\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.98611\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.04995\n",
      "Epoch 41/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 8.2968e-05 - accuracy: 1.0000 - val_loss: 0.0512 - val_accuracy: 0.9861\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.98611\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.04995\n",
      "Epoch 42/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 7.8567e-05 - accuracy: 1.0000 - val_loss: 0.0511 - val_accuracy: 0.9861\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.98611\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.04995\n",
      "Epoch 43/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 7.5583e-05 - accuracy: 1.0000 - val_loss: 0.0513 - val_accuracy: 0.9861\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.98611\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.04995\n",
      "Epoch 44/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 7.2050e-05 - accuracy: 1.0000 - val_loss: 0.0513 - val_accuracy: 0.9861\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.98611\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.04995\n",
      "Epoch 45/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 7.1047e-05 - accuracy: 1.0000 - val_loss: 0.0513 - val_accuracy: 0.9861\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.98611\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.04995\n",
      "Epoch 46/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 6.7004e-05 - accuracy: 1.0000 - val_loss: 0.0512 - val_accuracy: 0.9861\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.98611\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.04995\n",
      "Epoch 47/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 6.4067e-05 - accuracy: 1.0000 - val_loss: 0.0512 - val_accuracy: 0.9861\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.98611\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.04995\n",
      "Epoch 48/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 6.3123e-05 - accuracy: 1.0000 - val_loss: 0.0513 - val_accuracy: 0.9861\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.98611\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.04995\n",
      "Epoch 49/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 6.0935e-05 - accuracy: 1.0000 - val_loss: 0.0515 - val_accuracy: 0.9861\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.98611\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.04995\n",
      "Epoch 50/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 5.8048e-05 - accuracy: 1.0000 - val_loss: 0.0515 - val_accuracy: 0.9861\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.98611\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.04995\n",
      "240/240 [==============================] - 1s 3ms/step\n",
      "max acc:  [0.11081825072566669, 0.9624999761581421]\n",
      "240/240 [==============================] - 1s 3ms/step\n",
      "min loss:  [0.12520813414206108, 0.9624999761581421]\n",
      "---------------------------------------------------\n",
      "yes dominance s09\n",
      "---------------------------------------------------\n",
      "\n",
      "loaded shape: (2400,)\n",
      "(2400, 128, 9, 9)\n",
      "(2400, 128, 32)\n",
      "(2400,)\n",
      "(2400, 2)\n",
      "(2400, 128, 9, 9)\n",
      "(2400, 128, 32)\n",
      "(2400, 2)\n",
      "cnn_datasets.shape,rnn_datasets.shape,labels.shape :  (2400, 128, 9, 9) (2400, 128, 32) (2400, 2)\n",
      "(2400, 9, 9, 128)\n",
      "cnn_datasets.shape :  (2400, 9, 9, 128)\n",
      "========================Train / Test Shapes==============================\n",
      "(240, 9, 9, 128) (240, 128, 32) (2160, 9, 9, 128) (2160, 128, 32)\n",
      "================================ DNN ============================================\n",
      "input_cnn:  (None, 9, 9, 128)\n",
      "elu1:  (None, 9, 9, 32)\n",
      "elu2:  (None, 9, 9, 64)\n",
      "elu3:  (None, 9, 9, 128)\n",
      "reshape1:  (None, 9, 9, None)\n",
      "elu4:  (None, 9, 9, 13)\n",
      "reshape2:  (None, 1053)\n",
      "input_rnn (None, 128, 32)\n",
      "rnn_in_flat (None, None, 32)\n",
      "rnn_fc_in (None, 128, 1024)\n",
      "lstm_in (None, None, 1024)\n",
      "lstm_cell (None, 32)\n",
      "output (None, 32)\n",
      "rnn_output (32,)\n",
      "lstm_fc_out (None, 1024)\n",
      "lstm_fc_drop (None, 1024)\n",
      "fuse_cnn_rnn  (None, 2077)\n",
      "(None, 2)\n",
      "y  Tensor(\"dense_12/Softmax:0\", shape=(None, 2), dtype=float32)\n",
      "Model :  yes_dominance_s09_0_fold\n",
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_7 (InputLayer)            (None, 9, 9, 128)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 9, 9, 32)     65568       input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 9, 9, 32)     128         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "elu_16 (ELU)                    (None, 9, 9, 32)     0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 9, 9, 64)     32832       elu_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 9, 9, 64)     256         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "elu_17 (ELU)                    (None, 9, 9, 64)     0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 9, 9, 128)    131200      elu_17[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "input_8 (InputLayer)            (None, 128, 32)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 9, 9, 128)    512         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_15 (Reshape)            (None, 128, 32)      0           input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "elu_18 (ELU)                    (None, 9, 9, 128)    0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 128, 1024)    33792       reshape_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_13 (Reshape)            (None, 9, 9, 128)    0           elu_18[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "elu_20 (ELU)                    (None, 128, 1024)    0           dense_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 9, 9, 13)     1677        reshape_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_16 (Reshape)            (None, 128, 1024)    0           elu_20[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 9, 9, 13)     52          conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "rnn_4 (RNN)                     (None, 32)           143616      reshape_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "elu_19 (ELU)                    (None, 9, 9, 13)     0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 1024)         33792       rnn_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "reshape_14 (Reshape)            (None, 1053)         0           elu_19[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 1024)         0           dense_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 2077)         0           reshape_14[0][0]                 \n",
      "                                                                 dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 2)            4156        concatenate_4[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 447,581\n",
      "Trainable params: 447,107\n",
      "Non-trainable params: 474\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1728 samples, validate on 432 samples\n",
      "Epoch 1/50\n",
      " 256/1728 [===>..........................] - ETA: 9s - loss: 1.0782 - accuracy: 0.5703 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ABHISHEK_VERMA\\Anaconda3\\lib\\site-packages\\keras\\callbacks\\callbacks.py:95: RuntimeWarning: Method (on_train_batch_end) is slow compared to the batch update (10.543424). Check your callbacks.\n",
      "  % (hook_name, delta_t_median), RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1728/1728 [==============================] - 25s 15ms/step - loss: 0.6128 - accuracy: 0.7731 - val_loss: 0.3204 - val_accuracy: 0.8657\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.86574, saving model to lightningedge007a_results/yes/dominance/s09/max_acc_yes_dominance_s09.h5\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.32038, saving model to lightningedge007a_results/yes/dominance/s09/min_loss_yes_dominance_s09.h5\n",
      "Epoch 2/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 0.1556 - accuracy: 0.9375 - val_loss: 0.2123 - val_accuracy: 0.9352\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.86574 to 0.93519, saving model to lightningedge007a_results/yes/dominance/s09/max_acc_yes_dominance_s09.h5\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.32038 to 0.21230, saving model to lightningedge007a_results/yes/dominance/s09/min_loss_yes_dominance_s09.h5\n",
      "Epoch 3/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 0.0581 - accuracy: 0.9873 - val_loss: 0.1594 - val_accuracy: 0.9514\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.93519 to 0.95139, saving model to lightningedge007a_results/yes/dominance/s09/max_acc_yes_dominance_s09.h5\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.21230 to 0.15942, saving model to lightningedge007a_results/yes/dominance/s09/min_loss_yes_dominance_s09.h5\n",
      "Epoch 4/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 0.0270 - accuracy: 0.9971 - val_loss: 0.1330 - val_accuracy: 0.9537\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.95139 to 0.95370, saving model to lightningedge007a_results/yes/dominance/s09/max_acc_yes_dominance_s09.h5\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.15942 to 0.13297, saving model to lightningedge007a_results/yes/dominance/s09/min_loss_yes_dominance_s09.h5\n",
      "Epoch 5/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 0.0126 - accuracy: 1.0000 - val_loss: 0.1149 - val_accuracy: 0.9606\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.95370 to 0.96065, saving model to lightningedge007a_results/yes/dominance/s09/max_acc_yes_dominance_s09.h5\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.13297 to 0.11492, saving model to lightningedge007a_results/yes/dominance/s09/min_loss_yes_dominance_s09.h5\n",
      "Epoch 6/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.1035 - val_accuracy: 0.9560\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.96065\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.11492 to 0.10355, saving model to lightningedge007a_results/yes/dominance/s09/min_loss_yes_dominance_s09.h5\n",
      "Epoch 7/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.1028 - val_accuracy: 0.9606\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.96065\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.10355 to 0.10280, saving model to lightningedge007a_results/yes/dominance/s09/min_loss_yes_dominance_s09.h5\n",
      "Epoch 8/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0984 - val_accuracy: 0.9583\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.96065\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.10280 to 0.09838, saving model to lightningedge007a_results/yes/dominance/s09/min_loss_yes_dominance_s09.h5\n",
      "Epoch 9/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0963 - val_accuracy: 0.9606\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.96065\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.09838 to 0.09628, saving model to lightningedge007a_results/yes/dominance/s09/min_loss_yes_dominance_s09.h5\n",
      "Epoch 10/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0951 - val_accuracy: 0.9606\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.96065\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.09628 to 0.09513, saving model to lightningedge007a_results/yes/dominance/s09/min_loss_yes_dominance_s09.h5\n",
      "Epoch 11/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0948 - val_accuracy: 0.9630\n",
      "\n",
      "Epoch 00011: val_accuracy improved from 0.96065 to 0.96296, saving model to lightningedge007a_results/yes/dominance/s09/max_acc_yes_dominance_s09.h5\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.09513 to 0.09482, saving model to lightningedge007a_results/yes/dominance/s09/min_loss_yes_dominance_s09.h5\n",
      "Epoch 12/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0959 - val_accuracy: 0.9653\n",
      "\n",
      "Epoch 00012: val_accuracy improved from 0.96296 to 0.96528, saving model to lightningedge007a_results/yes/dominance/s09/max_acc_yes_dominance_s09.h5\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.09482\n",
      "Epoch 13/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0942 - val_accuracy: 0.9630\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.96528\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.09482 to 0.09418, saving model to lightningedge007a_results/yes/dominance/s09/min_loss_yes_dominance_s09.h5\n",
      "Epoch 14/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0933 - val_accuracy: 0.9676\n",
      "\n",
      "Epoch 00014: val_accuracy improved from 0.96528 to 0.96759, saving model to lightningedge007a_results/yes/dominance/s09/max_acc_yes_dominance_s09.h5\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.09418 to 0.09328, saving model to lightningedge007a_results/yes/dominance/s09/min_loss_yes_dominance_s09.h5\n",
      "Epoch 15/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0941 - val_accuracy: 0.9653\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.96759\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.09328\n",
      "Epoch 16/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 9.3914e-04 - accuracy: 1.0000 - val_loss: 0.0933 - val_accuracy: 0.9653\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.96759\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.09328\n",
      "Epoch 17/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 8.3737e-04 - accuracy: 1.0000 - val_loss: 0.0954 - val_accuracy: 0.9676\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.96759\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.09328\n",
      "Epoch 18/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 7.6393e-04 - accuracy: 1.0000 - val_loss: 0.0961 - val_accuracy: 0.9676\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.96759\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.09328\n",
      "Epoch 19/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 6.8591e-04 - accuracy: 1.0000 - val_loss: 0.0963 - val_accuracy: 0.9676\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.96759\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.09328\n",
      "Epoch 20/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 6.2851e-04 - accuracy: 1.0000 - val_loss: 0.0960 - val_accuracy: 0.9653\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.96759\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.09328\n",
      "Epoch 21/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 5.6762e-04 - accuracy: 1.0000 - val_loss: 0.0968 - val_accuracy: 0.9676\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.96759\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.09328\n",
      "Epoch 22/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 5.2727e-04 - accuracy: 1.0000 - val_loss: 0.0966 - val_accuracy: 0.9653\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.96759\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.09328\n",
      "Epoch 23/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 4.7599e-04 - accuracy: 1.0000 - val_loss: 0.0983 - val_accuracy: 0.9653\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.96759\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.09328\n",
      "Epoch 24/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 4.4225e-04 - accuracy: 1.0000 - val_loss: 0.0988 - val_accuracy: 0.9676\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.96759\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.09328\n",
      "Epoch 25/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 4.1155e-04 - accuracy: 1.0000 - val_loss: 0.0986 - val_accuracy: 0.9653\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.96759\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.09328\n",
      "Epoch 26/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 3.8389e-04 - accuracy: 1.0000 - val_loss: 0.0993 - val_accuracy: 0.9676\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.96759\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.09328\n",
      "Epoch 27/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 3.5503e-04 - accuracy: 1.0000 - val_loss: 0.0995 - val_accuracy: 0.9653\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.96759\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.09328\n",
      "Epoch 28/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 3.3451e-04 - accuracy: 1.0000 - val_loss: 0.1002 - val_accuracy: 0.9653\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.96759\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.09328\n",
      "Epoch 29/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 3.1564e-04 - accuracy: 1.0000 - val_loss: 0.1010 - val_accuracy: 0.9676\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.96759\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.09328\n",
      "Epoch 30/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 2.9635e-04 - accuracy: 1.0000 - val_loss: 0.1005 - val_accuracy: 0.9653\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.96759\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.09328\n",
      "Epoch 31/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 2.8147e-04 - accuracy: 1.0000 - val_loss: 0.1011 - val_accuracy: 0.9653\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.96759\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.09328\n",
      "Epoch 32/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 2.6291e-04 - accuracy: 1.0000 - val_loss: 0.1007 - val_accuracy: 0.9676\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.96759\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.09328\n",
      "Epoch 33/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 2.5019e-04 - accuracy: 1.0000 - val_loss: 0.1017 - val_accuracy: 0.9653\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.96759\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.09328\n",
      "Epoch 34/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 2.3496e-04 - accuracy: 1.0000 - val_loss: 0.1016 - val_accuracy: 0.9653\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.96759\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.09328\n",
      "Epoch 35/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 2.2311e-04 - accuracy: 1.0000 - val_loss: 0.1023 - val_accuracy: 0.9676\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.96759\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.09328\n",
      "Epoch 36/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 2.0992e-04 - accuracy: 1.0000 - val_loss: 0.1024 - val_accuracy: 0.9653\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.96759\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.09328\n",
      "Epoch 37/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 2.0277e-04 - accuracy: 1.0000 - val_loss: 0.1030 - val_accuracy: 0.9653\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.96759\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.09328\n",
      "Epoch 38/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.9069e-04 - accuracy: 1.0000 - val_loss: 0.1030 - val_accuracy: 0.9653\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.96759\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.09328\n",
      "Epoch 39/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.8169e-04 - accuracy: 1.0000 - val_loss: 0.1029 - val_accuracy: 0.9653\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.96759\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.09328\n",
      "Epoch 40/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.7809e-04 - accuracy: 1.0000 - val_loss: 0.1030 - val_accuracy: 0.9653\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.96759\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.09328\n",
      "Epoch 41/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.6560e-04 - accuracy: 1.0000 - val_loss: 0.1035 - val_accuracy: 0.9676\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.96759\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.09328\n",
      "Epoch 42/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.5808e-04 - accuracy: 1.0000 - val_loss: 0.1037 - val_accuracy: 0.9653\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.96759\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.09328\n",
      "Epoch 43/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.5366e-04 - accuracy: 1.0000 - val_loss: 0.1037 - val_accuracy: 0.9676\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.96759\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.09328\n",
      "Epoch 44/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.4875e-04 - accuracy: 1.0000 - val_loss: 0.1042 - val_accuracy: 0.9653\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.96759\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.09328\n",
      "Epoch 45/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.4016e-04 - accuracy: 1.0000 - val_loss: 0.1034 - val_accuracy: 0.9676\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.96759\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.09328\n",
      "Epoch 46/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.3421e-04 - accuracy: 1.0000 - val_loss: 0.1046 - val_accuracy: 0.9676\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.96759\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.09328\n",
      "Epoch 47/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.2996e-04 - accuracy: 1.0000 - val_loss: 0.1043 - val_accuracy: 0.9676\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.96759\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.09328\n",
      "Epoch 48/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.2486e-04 - accuracy: 1.0000 - val_loss: 0.1050 - val_accuracy: 0.9676\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.96759\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.09328\n",
      "Epoch 49/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.1828e-04 - accuracy: 1.0000 - val_loss: 0.1049 - val_accuracy: 0.9676\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.96759\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.09328\n",
      "Epoch 50/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.1521e-04 - accuracy: 1.0000 - val_loss: 0.1044 - val_accuracy: 0.9676\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.96759\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.09328\n",
      "240/240 [==============================] - 1s 4ms/step\n",
      "max acc:  [0.05904675324757894, 0.9833333492279053]\n",
      "240/240 [==============================] - 1s 3ms/step\n",
      "min loss:  [0.05904675324757894, 0.9833333492279053]\n",
      "---------------------------------------------------\n",
      "yes dominance s10\n",
      "---------------------------------------------------\n",
      "\n",
      "loaded shape: (2400,)\n",
      "(2400, 128, 9, 9)\n",
      "(2400, 128, 32)\n",
      "(2400,)\n",
      "(2400, 2)\n",
      "(2400, 128, 9, 9)\n",
      "(2400, 128, 32)\n",
      "(2400, 2)\n",
      "cnn_datasets.shape,rnn_datasets.shape,labels.shape :  (2400, 128, 9, 9) (2400, 128, 32) (2400, 2)\n",
      "(2400, 9, 9, 128)\n",
      "cnn_datasets.shape :  (2400, 9, 9, 128)\n",
      "========================Train / Test Shapes==============================\n",
      "(240, 9, 9, 128) (240, 128, 32) (2160, 9, 9, 128) (2160, 128, 32)\n",
      "================================ DNN ============================================\n",
      "input_cnn:  (None, 9, 9, 128)\n",
      "elu1:  (None, 9, 9, 32)\n",
      "elu2:  (None, 9, 9, 64)\n",
      "elu3:  (None, 9, 9, 128)\n",
      "reshape1:  (None, 9, 9, None)\n",
      "elu4:  (None, 9, 9, 13)\n",
      "reshape2:  (None, 1053)\n",
      "input_rnn (None, 128, 32)\n",
      "rnn_in_flat (None, None, 32)\n",
      "rnn_fc_in (None, 128, 1024)\n",
      "lstm_in (None, None, 1024)\n",
      "lstm_cell (None, 32)\n",
      "output (None, 32)\n",
      "rnn_output (32,)\n",
      "lstm_fc_out (None, 1024)\n",
      "lstm_fc_drop (None, 1024)\n",
      "fuse_cnn_rnn  (None, 2077)\n",
      "(None, 2)\n",
      "y  Tensor(\"dense_15/Softmax:0\", shape=(None, 2), dtype=float32)\n",
      "Model :  yes_dominance_s10_0_fold\n",
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_9 (InputLayer)            (None, 9, 9, 128)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 9, 9, 32)     65568       input_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 9, 9, 32)     128         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "elu_21 (ELU)                    (None, 9, 9, 32)     0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 9, 9, 64)     32832       elu_21[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 9, 9, 64)     256         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "elu_22 (ELU)                    (None, 9, 9, 64)     0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 9, 9, 128)    131200      elu_22[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "input_10 (InputLayer)           (None, 128, 32)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 9, 9, 128)    512         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_19 (Reshape)            (None, 128, 32)      0           input_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "elu_23 (ELU)                    (None, 9, 9, 128)    0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 128, 1024)    33792       reshape_19[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_17 (Reshape)            (None, 9, 9, 128)    0           elu_23[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "elu_25 (ELU)                    (None, 128, 1024)    0           dense_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 9, 9, 13)     1677        reshape_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_20 (Reshape)            (None, 128, 1024)    0           elu_25[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 9, 9, 13)     52          conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "rnn_5 (RNN)                     (None, 32)           143616      reshape_20[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "elu_24 (ELU)                    (None, 9, 9, 13)     0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 1024)         33792       rnn_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "reshape_18 (Reshape)            (None, 1053)         0           elu_24[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 1024)         0           dense_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 2077)         0           reshape_18[0][0]                 \n",
      "                                                                 dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_15 (Dense)                (None, 2)            4156        concatenate_5[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 447,581\n",
      "Trainable params: 447,107\n",
      "Non-trainable params: 474\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1728 samples, validate on 432 samples\n",
      "Epoch 1/50\n",
      " 256/1728 [===>..........................] - ETA: 9s - loss: 1.0129 - accuracy: 0.5898 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ABHISHEK_VERMA\\Anaconda3\\lib\\site-packages\\keras\\callbacks\\callbacks.py:95: RuntimeWarning: Method (on_train_batch_end) is slow compared to the batch update (10.348506). Check your callbacks.\n",
      "  % (hook_name, delta_t_median), RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1728/1728 [==============================] - 25s 15ms/step - loss: 0.4179 - accuracy: 0.8432 - val_loss: 0.1785 - val_accuracy: 0.9421\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.94213, saving model to lightningedge007a_results/yes/dominance/s10/max_acc_yes_dominance_s10.h5\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.17847, saving model to lightningedge007a_results/yes/dominance/s10/min_loss_yes_dominance_s10.h5\n",
      "Epoch 2/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 0.0609 - accuracy: 0.9792 - val_loss: 0.1268 - val_accuracy: 0.9560\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.94213 to 0.95602, saving model to lightningedge007a_results/yes/dominance/s10/max_acc_yes_dominance_s10.h5\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.17847 to 0.12681, saving model to lightningedge007a_results/yes/dominance/s10/min_loss_yes_dominance_s10.h5\n",
      "Epoch 3/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 0.0223 - accuracy: 0.9942 - val_loss: 0.0956 - val_accuracy: 0.9606\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.95602 to 0.96065, saving model to lightningedge007a_results/yes/dominance/s10/max_acc_yes_dominance_s10.h5\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.12681 to 0.09563, saving model to lightningedge007a_results/yes/dominance/s10/min_loss_yes_dominance_s10.h5\n",
      "Epoch 4/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 0.0769 - val_accuracy: 0.9676\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.96065 to 0.96759, saving model to lightningedge007a_results/yes/dominance/s10/max_acc_yes_dominance_s10.h5\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.09563 to 0.07695, saving model to lightningedge007a_results/yes/dominance/s10/min_loss_yes_dominance_s10.h5\n",
      "Epoch 5/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.0876 - val_accuracy: 0.9699\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.96759 to 0.96991, saving model to lightningedge007a_results/yes/dominance/s10/max_acc_yes_dominance_s10.h5\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.07695\n",
      "Epoch 6/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0780 - val_accuracy: 0.9722\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.96991 to 0.97222, saving model to lightningedge007a_results/yes/dominance/s10/max_acc_yes_dominance_s10.h5\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.07695\n",
      "Epoch 7/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0694 - val_accuracy: 0.9745\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.97222 to 0.97454, saving model to lightningedge007a_results/yes/dominance/s10/max_acc_yes_dominance_s10.h5\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.07695 to 0.06943, saving model to lightningedge007a_results/yes/dominance/s10/min_loss_yes_dominance_s10.h5\n",
      "Epoch 8/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0685 - val_accuracy: 0.9722\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.97454\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.06943 to 0.06847, saving model to lightningedge007a_results/yes/dominance/s10/min_loss_yes_dominance_s10.h5\n",
      "Epoch 9/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0677 - val_accuracy: 0.9722\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.97454\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.06847 to 0.06768, saving model to lightningedge007a_results/yes/dominance/s10/min_loss_yes_dominance_s10.h5\n",
      "Epoch 10/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 9.8228e-04 - accuracy: 1.0000 - val_loss: 0.0670 - val_accuracy: 0.9745\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.97454\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.06768 to 0.06699, saving model to lightningedge007a_results/yes/dominance/s10/min_loss_yes_dominance_s10.h5\n",
      "Epoch 11/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 8.3509e-04 - accuracy: 1.0000 - val_loss: 0.0666 - val_accuracy: 0.9745\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.97454\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.06699 to 0.06663, saving model to lightningedge007a_results/yes/dominance/s10/min_loss_yes_dominance_s10.h5\n",
      "Epoch 12/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 7.5918e-04 - accuracy: 1.0000 - val_loss: 0.0656 - val_accuracy: 0.9745\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.97454\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.06663 to 0.06559, saving model to lightningedge007a_results/yes/dominance/s10/min_loss_yes_dominance_s10.h5\n",
      "Epoch 13/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 6.6566e-04 - accuracy: 1.0000 - val_loss: 0.0652 - val_accuracy: 0.9745\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.97454\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.06559 to 0.06518, saving model to lightningedge007a_results/yes/dominance/s10/min_loss_yes_dominance_s10.h5\n",
      "Epoch 14/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 5.7861e-04 - accuracy: 1.0000 - val_loss: 0.0665 - val_accuracy: 0.9745\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.97454\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.06518\n",
      "Epoch 15/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 5.2739e-04 - accuracy: 1.0000 - val_loss: 0.0664 - val_accuracy: 0.9745\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.97454\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.06518\n",
      "Epoch 16/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 4.8080e-04 - accuracy: 1.0000 - val_loss: 0.0662 - val_accuracy: 0.9745\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.97454\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.06518\n",
      "Epoch 17/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 4.3219e-04 - accuracy: 1.0000 - val_loss: 0.0656 - val_accuracy: 0.9745\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.97454\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.06518\n",
      "Epoch 18/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 3.8813e-04 - accuracy: 1.0000 - val_loss: 0.0662 - val_accuracy: 0.9745\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.97454\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.06518\n",
      "Epoch 19/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 3.6627e-04 - accuracy: 1.0000 - val_loss: 0.0644 - val_accuracy: 0.9745\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.97454\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.06518 to 0.06437, saving model to lightningedge007a_results/yes/dominance/s10/min_loss_yes_dominance_s10.h5\n",
      "Epoch 20/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 3.3220e-04 - accuracy: 1.0000 - val_loss: 0.0653 - val_accuracy: 0.9745\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.97454\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.06437\n",
      "Epoch 21/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 3.1099e-04 - accuracy: 1.0000 - val_loss: 0.0659 - val_accuracy: 0.9745\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.97454\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.06437\n",
      "Epoch 22/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 2.9224e-04 - accuracy: 1.0000 - val_loss: 0.0655 - val_accuracy: 0.9745\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.97454\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.06437\n",
      "Epoch 23/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 2.6279e-04 - accuracy: 1.0000 - val_loss: 0.0660 - val_accuracy: 0.9745\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.97454\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.06437\n",
      "Epoch 24/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 2.4156e-04 - accuracy: 1.0000 - val_loss: 0.0664 - val_accuracy: 0.9745\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.97454\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.06437\n",
      "Epoch 25/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 2.2513e-04 - accuracy: 1.0000 - val_loss: 0.0664 - val_accuracy: 0.9745\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.97454\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.06437\n",
      "Epoch 26/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 2.2125e-04 - accuracy: 1.0000 - val_loss: 0.0664 - val_accuracy: 0.9745\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.97454\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.06437\n",
      "Epoch 27/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.9761e-04 - accuracy: 1.0000 - val_loss: 0.0666 - val_accuracy: 0.9745\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.97454\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.06437\n",
      "Epoch 28/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.8990e-04 - accuracy: 1.0000 - val_loss: 0.0667 - val_accuracy: 0.9745\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.97454\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.06437\n",
      "Epoch 29/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.7612e-04 - accuracy: 1.0000 - val_loss: 0.0670 - val_accuracy: 0.9745\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.97454\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.06437\n",
      "Epoch 30/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.7067e-04 - accuracy: 1.0000 - val_loss: 0.0671 - val_accuracy: 0.9745\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.97454\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.06437\n",
      "Epoch 31/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.5833e-04 - accuracy: 1.0000 - val_loss: 0.0674 - val_accuracy: 0.9745\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.97454\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.06437\n",
      "Epoch 32/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.5393e-04 - accuracy: 1.0000 - val_loss: 0.0678 - val_accuracy: 0.9745\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.97454\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.06437\n",
      "Epoch 33/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.4359e-04 - accuracy: 1.0000 - val_loss: 0.0679 - val_accuracy: 0.9745\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.97454\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.06437\n",
      "Epoch 34/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.3502e-04 - accuracy: 1.0000 - val_loss: 0.0676 - val_accuracy: 0.9745\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.97454\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.06437\n",
      "Epoch 35/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.2786e-04 - accuracy: 1.0000 - val_loss: 0.0684 - val_accuracy: 0.9745\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.97454\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.06437\n",
      "Epoch 36/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.2358e-04 - accuracy: 1.0000 - val_loss: 0.0684 - val_accuracy: 0.9745\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.97454\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.06437\n",
      "Epoch 37/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.1612e-04 - accuracy: 1.0000 - val_loss: 0.0682 - val_accuracy: 0.9745\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.97454\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.06437\n",
      "Epoch 38/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.0989e-04 - accuracy: 1.0000 - val_loss: 0.0682 - val_accuracy: 0.9745\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.97454\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.06437\n",
      "Epoch 39/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.0902e-04 - accuracy: 1.0000 - val_loss: 0.0685 - val_accuracy: 0.9745\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.97454\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.06437\n",
      "Epoch 40/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.0147e-04 - accuracy: 1.0000 - val_loss: 0.0685 - val_accuracy: 0.9745\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.97454\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.06437\n",
      "Epoch 41/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 9.8540e-05 - accuracy: 1.0000 - val_loss: 0.0684 - val_accuracy: 0.9745\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.97454\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.06437\n",
      "Epoch 42/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 9.3528e-05 - accuracy: 1.0000 - val_loss: 0.0687 - val_accuracy: 0.9745\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.97454\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.06437\n",
      "Epoch 43/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 9.0903e-05 - accuracy: 1.0000 - val_loss: 0.0685 - val_accuracy: 0.9745\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.97454\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.06437\n",
      "Epoch 44/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 8.6980e-05 - accuracy: 1.0000 - val_loss: 0.0684 - val_accuracy: 0.9745\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.97454\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.06437\n",
      "Epoch 45/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 8.4291e-05 - accuracy: 1.0000 - val_loss: 0.0690 - val_accuracy: 0.9745\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.97454\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.06437\n",
      "Epoch 46/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 8.0081e-05 - accuracy: 1.0000 - val_loss: 0.0688 - val_accuracy: 0.9745\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.97454\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.06437\n",
      "Epoch 47/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 7.8499e-05 - accuracy: 1.0000 - val_loss: 0.0686 - val_accuracy: 0.9745\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.97454\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.06437\n",
      "Epoch 48/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 7.5107e-05 - accuracy: 1.0000 - val_loss: 0.0685 - val_accuracy: 0.9745\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.97454\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.06437\n",
      "Epoch 49/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 7.0740e-05 - accuracy: 1.0000 - val_loss: 0.0689 - val_accuracy: 0.9745\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.97454\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.06437\n",
      "Epoch 50/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 6.8376e-05 - accuracy: 1.0000 - val_loss: 0.0696 - val_accuracy: 0.9745\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.97454\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.06437\n",
      "240/240 [==============================] - 1s 3ms/step\n",
      "max acc:  [0.06233439274753134, 0.9750000238418579]\n",
      "240/240 [==============================] - 1s 3ms/step\n",
      "min loss:  [0.05595085855262975, 0.9750000238418579]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(32)\n",
    "\n",
    "window_size = 128\n",
    "\n",
    "cnn_suffix ='.mat_win_128_cnn_dataset.pkl'\n",
    "rnn_suffix ='.mat_win_128_rnn_dataset.pkl'\n",
    "label_suffix ='.mat_win_128_labels.pkl'\n",
    "\n",
    "for with_or_without in baseline_preprocessing:\n",
    "    for arousal_or_valence in emotions:\n",
    "        for data_file in data_files:\n",
    "            \n",
    "            gc.collect()\n",
    "            \n",
    "            print('---------------------------------------------------')\n",
    "            print(with_or_without+' '+arousal_or_valence+' '+data_file)\n",
    "            print('---------------------------------------------------\\n')\n",
    "\n",
    "            #data_file    ='s17'\n",
    "            #arousal_or_valence = 'valence'\n",
    "            #with_or_without = 'yes'\n",
    "\n",
    "            dataset_dir = 'deap_shuffled_data/'+with_or_without+'_'+arousal_or_valence+'/'\n",
    "            ###load training set\n",
    "            try:\n",
    "                with open(dataset_dir + data_file + cnn_suffix, \"rb\") as fp:\n",
    "                    cnn_datasets = pickle.load(fp)\n",
    "                with open(dataset_dir + data_file + rnn_suffix, \"rb\") as fp:\n",
    "                    rnn_datasets = pickle.load(fp)\n",
    "                with open(dataset_dir + data_file + label_suffix, \"rb\") as fp:\n",
    "                    labels = pickle.load(fp)\n",
    "                    labels = np.transpose(labels)\n",
    "                    print(\"loaded shape:\",labels.shape)\n",
    "            except:\n",
    "                continue\n",
    "            lables_backup = labels\n",
    "\n",
    "            print(cnn_datasets.shape)\n",
    "            print(rnn_datasets.shape)\n",
    "            print(labels.shape)\n",
    "\n",
    "            #print(\"cnn_dataset shape before reshape:\", np.shape(cnn_datasets))\n",
    "            # cnn_datasets = cnn_datasets.reshape(len(cnn_datasets), window_size, 9,9, 1)\n",
    "            #print(\"cnn_dataset shape after reshape:\", np.shape(cnn_datasets))\n",
    "            one_hot_labels = np.array(list(pd.get_dummies(labels)))\n",
    "\n",
    "            labels = np.asarray(pd.get_dummies(labels), dtype=np.int8)\n",
    "\n",
    "            print(labels.shape)\n",
    "            # shuffle data\n",
    "            index = np.array(range(0, len(labels)))\n",
    "            np.random.shuffle(index)\n",
    "\n",
    "            cnn_datasets   = cnn_datasets[index]\n",
    "            rnn_datasets   = rnn_datasets[index]\n",
    "            labels  = labels[index]\n",
    "\n",
    "            print(cnn_datasets.shape)\n",
    "            print(rnn_datasets.shape)\n",
    "            print(labels.shape)\n",
    "\n",
    "            #print(\"**********(\" + time.asctime(time.localtime(time.time())) + \") Load and Split dataset End **********\\n\")\n",
    "            #print(\"**********(\" + time.asctime(time.localtime(time.time())) + \") Define parameters and functions Begin: **********\\n\")\n",
    "            print('cnn_datasets.shape,rnn_datasets.shape,labels.shape : ',cnn_datasets.shape,rnn_datasets.shape,labels.shape)\n",
    "            #important\n",
    "            cnn_datasets=cnn_datasets.reshape(2400,9,9,-1)# imp\n",
    "            print(cnn_datasets.shape)\n",
    "            print('cnn_datasets.shape : ',cnn_datasets.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            print('========================Train / Test Shapes==============================')\n",
    "\n",
    "\n",
    "\n",
    "            fold=10\n",
    "            curr_fold=0\n",
    "            #for curr_fold in range(fold): # kernel dies\n",
    "                \n",
    "            #   print('curr_fold / fold : ',curr_fold,' / ',fold)\n",
    "\n",
    "\n",
    "            max_acc_acc_list=[]\n",
    "\n",
    "            max_acc_loss_list=[]\n",
    "\n",
    "\n",
    "            min_loss_acc_list=[]\n",
    "\n",
    "            min_loss_loss_list=[]\n",
    "\n",
    "            fold_size = cnn_datasets.shape[0]//fold\n",
    "            indexes_list = [i for i in range(len(cnn_datasets))]\n",
    "            indexes = np.array(indexes_list)\n",
    "            split_list = [i for i in range(curr_fold*fold_size,(curr_fold+1)*fold_size)]\n",
    "            split = np.array(split_list)\n",
    "\n",
    "            cnn_test = cnn_datasets[split] \n",
    "            labels_test = labels[split]\n",
    "            rnn_test = rnn_datasets[split]\n",
    "\n",
    "            split = np.array(list(set(indexes_list)^set(split_list)))\n",
    "\n",
    "            cnn_train = cnn_datasets[split]\n",
    "            rnn_train = rnn_datasets[split]\n",
    "            labels_train = labels[split]\n",
    "\n",
    "            # train_sample = labels_train.shape[0]\n",
    "            # print(\"training examples:\", train_sample)\n",
    "            # test_sample = labels_test.shape[0]\n",
    "            # print(\"test examples    :\",test_sample)\n",
    "            print(cnn_test.shape,rnn_test.shape,cnn_train.shape,rnn_train.shape)\n",
    "\n",
    "            print('================================ DNN ============================================')\n",
    "\n",
    "            input_cnn=Input(shape=(9,9,128))\n",
    "\n",
    "            print('input_cnn: ',input_cnn.shape)\n",
    "\n",
    "            conv1=Conv2D(32,\n",
    "                          kernel_size=(4,4),\n",
    "                          strides=(1,1),\n",
    "                          padding='same',\n",
    "                          input_shape=(9,9,128)\n",
    "                         )(input_cnn)\n",
    "\n",
    "\n",
    "            bn1=BatchNormalization()(conv1)\n",
    "\n",
    "            elu1=ELU()(bn1)\n",
    "\n",
    "            print('elu1: ',elu1.shape)\n",
    "            #?,9,9,32\n",
    "            conv2=Conv2D(64,\n",
    "                          kernel_size=(4,4),\n",
    "                          strides=(1,1),\n",
    "                          padding='same'\n",
    "                         )(elu1)\n",
    "\n",
    "            bn2=BatchNormalization()(conv2)\n",
    "\n",
    "            elu2=ELU()(bn2)\n",
    "\n",
    "            print('elu2: ',elu2.shape)\n",
    "            #?,9,9,64\n",
    "\n",
    "            conv3=Conv2D(128,\n",
    "                          kernel_size=(4,4),\n",
    "                          strides=(1,1),\n",
    "                          padding='same'\n",
    "                         )(elu2)\n",
    "\n",
    "            bn3=BatchNormalization()(conv3)\n",
    "\n",
    "            elu3=ELU()(bn3)\n",
    "\n",
    "\n",
    "            print('elu3: ',elu3.shape)\n",
    "            #?,9,9,128\n",
    "\n",
    "            # mc.add(Flatten())\n",
    "            # mc.add(Lambda(lambda x:x,output_shape=(9,9,32*4*128)))\n",
    "            # mc.add(Lambda(K.reshape((-1,9,9,32*4*128))))\n",
    "            reshape1=Reshape((9,9,-1))(elu3)\n",
    "\n",
    "\n",
    "            print('reshape1: ',reshape1.shape)\n",
    "            #?,9,9,32*4*128\n",
    "\n",
    "            conv4=Conv2D(13,#32*4*128,\n",
    "                          kernel_size=(1,1),\n",
    "                          strides=(1,1),\n",
    "                          padding='same'\n",
    "                         )(reshape1)\n",
    "\n",
    "            bn4=BatchNormalization()(conv4)\n",
    "\n",
    "            elu4=ELU()(bn4)\n",
    "\n",
    "\n",
    "            print('elu4: ',elu4.shape)\n",
    "            #?,9,9,13 #32*4*128\n",
    "\n",
    "            # mc.add(Flatten())\n",
    "\n",
    "            # mc.add(Lambda(lambda x:x,output_shape=([13*9*9])))\n",
    "            # mc.add(Lambda(K.reshape((None,13*9*9))))\n",
    "            reshape2=Reshape(([13*9*9]))(elu4)\n",
    "\n",
    "\n",
    "            print('reshape2: ',reshape2.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            cnn_out_fuse=reshape2\n",
    "\n",
    "\n",
    "            # cube=K.reshape(e3,(-1,9,9,32*4*128))#(e3)\n",
    "\n",
    "\n",
    "            # flat=K.reshape(e4,(-1,13*9*9))#(e4) #1053\n",
    "\n",
    "            # rnn_in=K.placeholder(shape=(None,128,32))\n",
    "            # rnn_in=tf.convert_to_tensor(rnn_datasets,dtype='float32')\n",
    "\n",
    "\n",
    "            # rnn_in.get_shape().as_list()\n",
    "\n",
    "            # rnn_in=K.placeholder(shape=(None,128,32))\n",
    "            # rnn_in_flat=K.reshape(rnn_in,[-1,32])\n",
    "\n",
    "            # print('rnn_in ',rnn_in.shape)\n",
    "\n",
    "            input_rnn=Input(shape=(128,32))\n",
    "            print('input_rnn',input_rnn.shape)\n",
    "\n",
    "            rnn_in_flat=Reshape((-1,32))(input_rnn)\n",
    "            print('rnn_in_flat',rnn_in_flat.shape)\n",
    "            # rnn_in_flat = Lambda(lambda x:x[:,0])(input_rnn)\n",
    "\n",
    "            # rnn_fc_in1 =Dense(32)(rnn_in_flat)\n",
    "            rnn_fc_in1 =Dense(1024)(rnn_in_flat)\n",
    "            rnn_fc_in=ELU()(rnn_fc_in1)\n",
    "            print('rnn_fc_in',rnn_fc_in.shape)\n",
    "\n",
    "            # rnn_fc_in =Dense(1024)(input_rnn)\n",
    "\n",
    "            # lstm_in=Reshape((-1,128,1024))(rnn_fc_in)\n",
    "            lstm_in=Reshape((-1,1024))(rnn_fc_in)\n",
    "            print('lstm_in',lstm_in.shape)\n",
    "\n",
    "            cells=[]\n",
    "\n",
    "            for i in range(2):\n",
    "                cell=LSTMCell(32,unit_forget_bias=True,dropout=0.5)#'forget_bias'=1.0,'state_is_tuple'=True\n",
    "                cells.append(cell)\n",
    "            #     print(cell.shape)\n",
    "\n",
    "            # lstm_cell=StackedRNNCells(cells)\n",
    "            lstm_cell=RNN(cells)(lstm_in)\n",
    "            # print(lstm_cell.shape)\n",
    "            # op,states=RNN(cells)(lstm_in)\n",
    "            print('lstm_cell',lstm_cell.shape)\n",
    "            # output=K.transpose_shape((1,0,2),lstm_cell)\n",
    "            # output=Permute((1,0,2))(lstm_cell)\n",
    "            # output.reshape()\n",
    "            output=lstm_cell\n",
    "            print('output',output.shape)\n",
    "            rnn_output=output[-1]\n",
    "            # rnn_output\n",
    "\n",
    "            print('rnn_output',rnn_output.shape)\n",
    "            # shape_rnn_out=rnn_output.get_shape().as_list()\n",
    "            lstm_fc_out=Dense(1024)(output)#shape_rnn_out[1]\n",
    "\n",
    "            print('lstm_fc_out',lstm_fc_out.shape)\n",
    "\n",
    "\n",
    "            # lstm_fc_out_2=Dense(1053)(lstm_fc_out)#shape_rnn_out[1]\n",
    "\n",
    "\n",
    "\n",
    "            lstm_fc_drop=Dropout(0.5)(lstm_fc_out)\n",
    "            # lstm_fc_drop\n",
    "            print('lstm_fc_drop',lstm_fc_drop.shape)\n",
    "\n",
    "            # fuse_cnn_rnn=add([cnn_out_fuse,lstm_fc_drop])\n",
    "\n",
    "            fuse_cnn_rnn=concatenate([cnn_out_fuse,lstm_fc_drop])\n",
    "            print('fuse_cnn_rnn ',fuse_cnn_rnn.shape)\n",
    "            y=Dense(2,activation='softmax')(fuse_cnn_rnn) ## ,activity_regularizer=regularizers.l2(0.5)\n",
    "            print(y.shape)\n",
    "            y_pred=K.argmax(y,1)\n",
    "            # y_pred=K.argmax(K.softmax(y))\n",
    "            # y_posi=K.softmax(y)\n",
    "            print('y ',y)\n",
    "\n",
    "\n",
    "            directory_le007a='./lightningedge007a_results/'+with_or_without+'/'+arousal_or_valence+'/'+data_file\n",
    "            try:\n",
    "                if not os.path.exists(directory_le007a):\n",
    "                    os.makedirs(directory_le007a)\n",
    "            except OSError:\n",
    "                print ('Error: Creating directory. ' +  directory_le007a)\n",
    "\n",
    "\n",
    "\n",
    "            model=Model(inputs=[input_cnn,input_rnn],outputs=y)\n",
    "            model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "            print('Model : ',with_or_without+'_'+arousal_or_valence+'_'+data_file+'_'+str(curr_fold)+'_fold')\n",
    "            print(model.summary())\n",
    "\n",
    "            m_val_acc=ModelCheckpoint('lightningedge007a_results/'+with_or_without+'/'+arousal_or_valence+'/'+data_file+'/'+'max_acc_'+with_or_without+'_'+arousal_or_valence+'_'+data_file+'.h5',monitor='val_accuracy',mode='max',verbose=1,save_best_only=True)\n",
    "            m_val_loss=ModelCheckpoint('lightningedge007a_results/'+with_or_without+'/'+arousal_or_valence+'/'+data_file+'/'+'min_loss_'+with_or_without+'_'+arousal_or_valence+'_'+data_file+'.h5',monitor='val_loss',mode='min',verbose=1,save_best_only=True)\n",
    "\n",
    "\n",
    "            tb_log_dir='lightningedge007a_results\\\\'+with_or_without+'\\\\'+arousal_or_valence+'\\\\'+data_file+'\\\\'+'logs_'+with_or_without+'_'+arousal_or_valence+'_'+data_file\n",
    "            #tb_log_dir='lightningedge007a_results/'+with_or_without+'/'+arousal_or_valence+'/'+data_file+'/'+'logs_'+with_or_without+'_'+arousal_or_valence+'_'+data_file\n",
    "\n",
    "            createFolder(tb_log_dir)\n",
    "\n",
    "\n",
    "            #log_dir='lightningedge007a_results\\\\'+with_or_without+'\\\\'+arousal_or_valence+'\\\\'+data_file+'\\\\'+'logs_'+with_or_without+'_'+arousal_or_valence+'_'+data_file+'_'+str(curr_fold)+'_fold\\\\' #datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "            tensorboard_callback = callbacks.TensorBoard(log_dir=tb_log_dir)#, histogram_freq=1)\n",
    "\n",
    "            plotpicture=plot_model(model, to_file='lightningedge007a_results/'+with_or_without+'/'+arousal_or_valence+'/'+data_file+'/'+'model_'+with_or_without+'_'+arousal_or_valence+'_'+data_file+'.png', show_shapes=True)\n",
    "\n",
    "            \n",
    "            \n",
    "            gc.collect()\n",
    "            \n",
    "            \n",
    "\n",
    "            history=model.fit([cnn_train,rnn_train],labels_train,batch_size=128,epochs=50,callbacks=[tensorboard_callback,m_val_acc,m_val_loss],validation_split=0.2)\n",
    "\n",
    "\n",
    "            #Plot values\n",
    "            plt.plot(history.history['accuracy'])\n",
    "            plt.plot(history.history['val_accuracy'])\n",
    "            plt.title('max_acc_'+with_or_without+'_'+arousal_or_valence+'_'+data_file)\n",
    "            plt.ylabel('Accuracy')\n",
    "            plt.xlabel('Epoch')\n",
    "            plt.legend(['Train', 'Validation'], loc='upper right',bbox_to_anchor=(1.3,1))\n",
    "            plt.savefig('lightningedge007a_results/'+with_or_without+'/'+arousal_or_valence+'/'+data_file+'/'+'max_acc_'+with_or_without+'_'+arousal_or_valence+'_'+data_file+'.png',bbox_inches='tight')\n",
    "            #plt.show()\n",
    "            plt.close()\n",
    "\n",
    "\n",
    "            # Plot training & validation loss values\n",
    "            plt.plot(history.history['loss'])\n",
    "            plt.plot(history.history['val_loss'])\n",
    "            plt.title('min_loss_'+with_or_without+'_'+arousal_or_valence+'_'+data_file+'_'+str(curr_fold)+'_fold')\n",
    "            plt.ylabel('Loss')\n",
    "            plt.xlabel('Epoch')\n",
    "            plt.legend(['Train', 'Validation'], loc='upper right',bbox_to_anchor=(1.3,1))\n",
    "            plt.savefig('lightningedge007a_results/'+with_or_without+'/'+arousal_or_valence+'/'+data_file+'/'+'min_loss_'+with_or_without+'_'+arousal_or_valence+'_'+data_file+'.png',bbox_inches='tight')\n",
    "            #plt.show()\n",
    "            plt.close()\n",
    "\n",
    "            vam=load_model('lightningedge007a_results/'+with_or_without+'/'+arousal_or_valence+'/'+data_file+'/'+'max_acc_'+with_or_without+'_'+arousal_or_valence+'_'+data_file+'.h5')\n",
    "            vlm=load_model('lightningedge007a_results/'+with_or_without+'/'+arousal_or_valence+'/'+data_file+'/'+'min_loss_'+with_or_without+'_'+arousal_or_valence+'_'+data_file+'.h5')\n",
    "            # pred_labels=vam()\n",
    "            vam_eval=vam.evaluate([cnn_test,rnn_test],labels_test)\n",
    "            print('max acc: ',vam_eval)\n",
    "            vlm_eval=vlm.evaluate([cnn_test,rnn_test],labels_test)\n",
    "            print('min loss: ',vlm_eval)\n",
    "\n",
    "\n",
    "            max_acc_acc_list.append(vam_eval[1])\n",
    "\n",
    "            max_acc_loss_list.append(vam_eval[0])\n",
    "\n",
    "\n",
    "            min_loss_acc_list.append(vlm_eval[1])\n",
    "\n",
    "            min_loss_loss_list.append(vlm_eval[0])\n",
    "\n",
    "            pickle.dump(max_acc_acc_list,open('lightningedge007a_results/'+with_or_without+'/'+arousal_or_valence+'/'+data_file+'/'+'max_acc_acc_list_'+with_or_without+'_'+arousal_or_valence+'_'+data_file+'.pkl','wb'))\n",
    "\n",
    "            pickle.dump(max_acc_loss_list,open('lightningedge007a_results/'+with_or_without+'/'+arousal_or_valence+'/'+data_file+'/'+'max_acc_loss_list_'+with_or_without+'_'+arousal_or_valence+'_'+data_file+'.pkl','wb'))\n",
    "\n",
    "\n",
    "            pickle.dump(min_loss_acc_list,open('lightningedge007a_results/'+with_or_without+'/'+arousal_or_valence+'/'+data_file+'/'+'min_loss_acc_list_'+with_or_without+'_'+arousal_or_valence+'_'+data_file+'.pkl','wb'))\n",
    "\n",
    "            pickle.dump(min_loss_loss_list,open('lightningedge007a_results/'+with_or_without+'/'+arousal_or_valence+'/'+data_file+'/'+'min_loss_loss_list_'+with_or_without+'_'+arousal_or_valence+'_'+data_file+'.pkl','wb'))\n",
    "            \n",
    "            \n",
    "            gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-08T14:57:51.984038Z",
     "start_time": "2019-11-08T14:57:51.980052Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['s11', 's12', 's13', 's14', 's15']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_files=data_files[10:15]\n",
    "data_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-11-08T14:57:54.248Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------\n",
      "yes dominance s11\n",
      "---------------------------------------------------\n",
      "\n",
      "loaded shape: (2400,)\n",
      "(2400, 128, 9, 9)\n",
      "(2400, 128, 32)\n",
      "(2400,)\n",
      "(2400, 2)\n",
      "(2400, 128, 9, 9)\n",
      "(2400, 128, 32)\n",
      "(2400, 2)\n",
      "cnn_datasets.shape,rnn_datasets.shape,labels.shape :  (2400, 128, 9, 9) (2400, 128, 32) (2400, 2)\n",
      "(2400, 9, 9, 128)\n",
      "cnn_datasets.shape :  (2400, 9, 9, 128)\n",
      "========================Train / Test Shapes==============================\n",
      "(240, 9, 9, 128) (240, 128, 32) (2160, 9, 9, 128) (2160, 128, 32)\n",
      "================================ DNN ============================================\n",
      "input_cnn:  (None, 9, 9, 128)\n",
      "elu1:  (None, 9, 9, 32)\n",
      "elu2:  (None, 9, 9, 64)\n",
      "elu3:  (None, 9, 9, 128)\n",
      "reshape1:  (None, 9, 9, None)\n",
      "elu4:  (None, 9, 9, 13)\n",
      "reshape2:  (None, 1053)\n",
      "input_rnn (None, 128, 32)\n",
      "rnn_in_flat (None, None, 32)\n",
      "rnn_fc_in (None, 128, 1024)\n",
      "lstm_in (None, None, 1024)\n",
      "lstm_cell (None, 32)\n",
      "output (None, 32)\n",
      "rnn_output (32,)\n",
      "lstm_fc_out (None, 1024)\n",
      "lstm_fc_drop (None, 1024)\n",
      "fuse_cnn_rnn  (None, 2077)\n",
      "(None, 2)\n",
      "y  Tensor(\"dense_3/Softmax:0\", shape=(None, 2), dtype=float32)\n",
      "Model :  yes_dominance_s11_0_fold\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 9, 9, 128)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 9, 9, 32)     65568       input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 9, 9, 32)     128         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "elu_1 (ELU)                     (None, 9, 9, 32)     0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 9, 9, 64)     32832       elu_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 9, 9, 64)     256         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "elu_2 (ELU)                     (None, 9, 9, 64)     0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 9, 9, 128)    131200      elu_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 128, 32)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 9, 9, 128)    512         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_3 (Reshape)             (None, 128, 32)      0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "elu_3 (ELU)                     (None, 9, 9, 128)    0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 128, 1024)    33792       reshape_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 9, 9, 128)    0           elu_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "elu_5 (ELU)                     (None, 128, 1024)    0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 9, 9, 13)     1677        reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_4 (Reshape)             (None, 128, 1024)    0           elu_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 9, 9, 13)     52          conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "rnn_1 (RNN)                     (None, 32)           143616      reshape_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "elu_4 (ELU)                     (None, 9, 9, 13)     0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1024)         33792       rnn_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "reshape_2 (Reshape)             (None, 1053)         0           elu_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 1024)         0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 2077)         0           reshape_2[0][0]                  \n",
      "                                                                 dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 2)            4156        concatenate_1[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 447,581\n",
      "Trainable params: 447,107\n",
      "Non-trainable params: 474\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Train on 1728 samples, validate on 432 samples\n",
      "Epoch 1/50\n",
      " 256/1728 [===>..........................] - ETA: 19s - loss: 1.0110 - accuracy: 0.5625"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ABHISHEK_VERMA\\Anaconda3\\lib\\site-packages\\keras\\callbacks\\callbacks.py:95: RuntimeWarning: Method (on_train_batch_end) is slow compared to the batch update (10.029745). Check your callbacks.\n",
      "  % (hook_name, delta_t_median), RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1728/1728 [==============================] - 26s 15ms/step - loss: 0.5592 - accuracy: 0.7691 - val_loss: 0.3791 - val_accuracy: 0.8403\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.84028, saving model to lightningedge007a_results/yes/dominance/s11/max_acc_yes_dominance_s11.h5\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.37913, saving model to lightningedge007a_results/yes/dominance/s11/min_loss_yes_dominance_s11.h5\n",
      "Epoch 2/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 0.1500 - accuracy: 0.9450 - val_loss: 0.2491 - val_accuracy: 0.9144\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.84028 to 0.91435, saving model to lightningedge007a_results/yes/dominance/s11/max_acc_yes_dominance_s11.h5\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.37913 to 0.24907, saving model to lightningedge007a_results/yes/dominance/s11/min_loss_yes_dominance_s11.h5\n",
      "Epoch 3/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 0.0717 - accuracy: 0.9803 - val_loss: 0.2397 - val_accuracy: 0.9005\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.91435\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.24907 to 0.23973, saving model to lightningedge007a_results/yes/dominance/s11/min_loss_yes_dominance_s11.h5\n",
      "Epoch 4/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 0.0415 - accuracy: 0.9931 - val_loss: 0.2082 - val_accuracy: 0.9259\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.91435 to 0.92593, saving model to lightningedge007a_results/yes/dominance/s11/max_acc_yes_dominance_s11.h5\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.23973 to 0.20819, saving model to lightningedge007a_results/yes/dominance/s11/min_loss_yes_dominance_s11.h5\n",
      "Epoch 5/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 0.0264 - accuracy: 0.9948 - val_loss: 0.2149 - val_accuracy: 0.8958\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.92593\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.20819\n",
      "Epoch 6/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 0.0129 - accuracy: 0.9988 - val_loss: 0.1753 - val_accuracy: 0.9282\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.92593 to 0.92824, saving model to lightningedge007a_results/yes/dominance/s11/max_acc_yes_dominance_s11.h5\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.20819 to 0.17526, saving model to lightningedge007a_results/yes/dominance/s11/min_loss_yes_dominance_s11.h5\n",
      "Epoch 7/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.1685 - val_accuracy: 0.9329\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.92824 to 0.93287, saving model to lightningedge007a_results/yes/dominance/s11/max_acc_yes_dominance_s11.h5\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.17526 to 0.16854, saving model to lightningedge007a_results/yes/dominance/s11/min_loss_yes_dominance_s11.h5\n",
      "Epoch 8/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.1646 - val_accuracy: 0.9282\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.93287\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.16854 to 0.16458, saving model to lightningedge007a_results/yes/dominance/s11/min_loss_yes_dominance_s11.h5\n",
      "Epoch 9/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.1548 - val_accuracy: 0.9398\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.93287 to 0.93981, saving model to lightningedge007a_results/yes/dominance/s11/max_acc_yes_dominance_s11.h5\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.16458 to 0.15480, saving model to lightningedge007a_results/yes/dominance/s11/min_loss_yes_dominance_s11.h5\n",
      "Epoch 10/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.1563 - val_accuracy: 0.9329\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.93981\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.15480\n",
      "Epoch 11/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.1547 - val_accuracy: 0.9398\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.93981\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.15480 to 0.15467, saving model to lightningedge007a_results/yes/dominance/s11/min_loss_yes_dominance_s11.h5\n",
      "Epoch 12/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.1530 - val_accuracy: 0.9398\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.93981\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.15467 to 0.15301, saving model to lightningedge007a_results/yes/dominance/s11/min_loss_yes_dominance_s11.h5\n",
      "Epoch 13/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.1558 - val_accuracy: 0.9375\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.93981\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.15301\n",
      "Epoch 14/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.1541 - val_accuracy: 0.9375\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.93981\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.15301\n",
      "Epoch 15/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 8.9074e-04 - accuracy: 1.0000 - val_loss: 0.1533 - val_accuracy: 0.9375\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.93981\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.15301\n",
      "Epoch 16/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 7.9057e-04 - accuracy: 1.0000 - val_loss: 0.1559 - val_accuracy: 0.9398\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.93981\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.15301\n",
      "Epoch 17/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 7.2205e-04 - accuracy: 1.0000 - val_loss: 0.1559 - val_accuracy: 0.9398\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.93981\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.15301\n",
      "Epoch 18/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 6.5445e-04 - accuracy: 1.0000 - val_loss: 0.1567 - val_accuracy: 0.9398\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.93981\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.15301\n",
      "Epoch 19/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 5.9476e-04 - accuracy: 1.0000 - val_loss: 0.1567 - val_accuracy: 0.9398\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.93981\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.15301\n",
      "Epoch 20/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 5.5158e-04 - accuracy: 1.0000 - val_loss: 0.1580 - val_accuracy: 0.9398\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.93981\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.15301\n",
      "Epoch 21/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 4.9545e-04 - accuracy: 1.0000 - val_loss: 0.1584 - val_accuracy: 0.9398\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.93981\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.15301\n",
      "Epoch 22/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 4.6142e-04 - accuracy: 1.0000 - val_loss: 0.1570 - val_accuracy: 0.9421\n",
      "\n",
      "Epoch 00022: val_accuracy improved from 0.93981 to 0.94213, saving model to lightningedge007a_results/yes/dominance/s11/max_acc_yes_dominance_s11.h5\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.15301\n",
      "Epoch 23/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 4.3377e-04 - accuracy: 1.0000 - val_loss: 0.1578 - val_accuracy: 0.9421\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.94213\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.15301\n",
      "Epoch 24/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 3.9848e-04 - accuracy: 1.0000 - val_loss: 0.1576 - val_accuracy: 0.9398\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.94213\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.15301\n",
      "Epoch 25/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 3.6574e-04 - accuracy: 1.0000 - val_loss: 0.1589 - val_accuracy: 0.9398\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.94213\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.15301\n",
      "Epoch 26/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 3.4613e-04 - accuracy: 1.0000 - val_loss: 0.1603 - val_accuracy: 0.9398\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.94213\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.15301\n",
      "Epoch 27/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1728/1728 [==============================] - 3s 2ms/step - loss: 3.1973e-04 - accuracy: 1.0000 - val_loss: 0.1605 - val_accuracy: 0.9421\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.94213\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.15301\n",
      "Epoch 28/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 3.0278e-04 - accuracy: 1.0000 - val_loss: 0.1594 - val_accuracy: 0.9421\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.94213\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.15301\n",
      "Epoch 29/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 2.8369e-04 - accuracy: 1.0000 - val_loss: 0.1607 - val_accuracy: 0.9421\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.94213\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.15301\n",
      "Epoch 30/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 2.7089e-04 - accuracy: 1.0000 - val_loss: 0.1617 - val_accuracy: 0.9421\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.94213\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.15301\n",
      "Epoch 31/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 2.5404e-04 - accuracy: 1.0000 - val_loss: 0.1607 - val_accuracy: 0.9398\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.94213\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.15301\n",
      "Epoch 32/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 2.3900e-04 - accuracy: 1.0000 - val_loss: 0.1612 - val_accuracy: 0.9398\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.94213\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.15301\n",
      "Epoch 33/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 2.2498e-04 - accuracy: 1.0000 - val_loss: 0.1620 - val_accuracy: 0.9421\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.94213\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.15301\n",
      "Epoch 34/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 2.1382e-04 - accuracy: 1.0000 - val_loss: 0.1625 - val_accuracy: 0.9421\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.94213\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.15301\n",
      "Epoch 35/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 2.0240e-04 - accuracy: 1.0000 - val_loss: 0.1640 - val_accuracy: 0.9421\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.94213\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.15301\n",
      "Epoch 36/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.9382e-04 - accuracy: 1.0000 - val_loss: 0.1634 - val_accuracy: 0.9421\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.94213\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.15301\n",
      "Epoch 37/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.8367e-04 - accuracy: 1.0000 - val_loss: 0.1632 - val_accuracy: 0.9421\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.94213\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.15301\n",
      "Epoch 38/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.7434e-04 - accuracy: 1.0000 - val_loss: 0.1633 - val_accuracy: 0.9421\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.94213\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.15301\n",
      "Epoch 39/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.6682e-04 - accuracy: 1.0000 - val_loss: 0.1637 - val_accuracy: 0.9421\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.94213\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.15301\n",
      "Epoch 40/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.5976e-04 - accuracy: 1.0000 - val_loss: 0.1650 - val_accuracy: 0.9421\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.94213\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.15301\n",
      "Epoch 41/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.5425e-04 - accuracy: 1.0000 - val_loss: 0.1650 - val_accuracy: 0.9421\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.94213\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.15301\n",
      "Epoch 42/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.4584e-04 - accuracy: 1.0000 - val_loss: 0.1649 - val_accuracy: 0.9421\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.94213\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.15301\n",
      "Epoch 43/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.4036e-04 - accuracy: 1.0000 - val_loss: 0.1653 - val_accuracy: 0.9421\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.94213\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.15301\n",
      "Epoch 44/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.3459e-04 - accuracy: 1.0000 - val_loss: 0.1651 - val_accuracy: 0.9421\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.94213\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.15301\n",
      "Epoch 45/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.2885e-04 - accuracy: 1.0000 - val_loss: 0.1646 - val_accuracy: 0.9421\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.94213\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.15301\n",
      "Epoch 46/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.2295e-04 - accuracy: 1.0000 - val_loss: 0.1657 - val_accuracy: 0.9421\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.94213\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.15301\n",
      "Epoch 47/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.1876e-04 - accuracy: 1.0000 - val_loss: 0.1652 - val_accuracy: 0.9421\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.94213\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.15301\n",
      "Epoch 48/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.1375e-04 - accuracy: 1.0000 - val_loss: 0.1657 - val_accuracy: 0.9421\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.94213\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.15301\n",
      "Epoch 49/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.0944e-04 - accuracy: 1.0000 - val_loss: 0.1668 - val_accuracy: 0.9421\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.94213\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.15301\n",
      "Epoch 50/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.0657e-04 - accuracy: 1.0000 - val_loss: 0.1669 - val_accuracy: 0.9421\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.94213\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.15301\n",
      "240/240 [==============================] - 1s 4ms/step\n",
      "max acc:  [0.09085775564114253, 0.9666666388511658]\n",
      "240/240 [==============================] - 1s 3ms/step\n",
      "min loss:  [0.09371800969044368, 0.9666666388511658]\n",
      "---------------------------------------------------\n",
      "yes dominance s12\n",
      "---------------------------------------------------\n",
      "\n",
      "loaded shape: (2400,)\n",
      "(2400, 128, 9, 9)\n",
      "(2400, 128, 32)\n",
      "(2400,)\n",
      "(2400, 2)\n",
      "(2400, 128, 9, 9)\n",
      "(2400, 128, 32)\n",
      "(2400, 2)\n",
      "cnn_datasets.shape,rnn_datasets.shape,labels.shape :  (2400, 128, 9, 9) (2400, 128, 32) (2400, 2)\n",
      "(2400, 9, 9, 128)\n",
      "cnn_datasets.shape :  (2400, 9, 9, 128)\n",
      "========================Train / Test Shapes==============================\n",
      "(240, 9, 9, 128) (240, 128, 32) (2160, 9, 9, 128) (2160, 128, 32)\n",
      "================================ DNN ============================================\n",
      "input_cnn:  (None, 9, 9, 128)\n",
      "elu1:  (None, 9, 9, 32)\n",
      "elu2:  (None, 9, 9, 64)\n",
      "elu3:  (None, 9, 9, 128)\n",
      "reshape1:  (None, 9, 9, None)\n",
      "elu4:  (None, 9, 9, 13)\n",
      "reshape2:  (None, 1053)\n",
      "input_rnn (None, 128, 32)\n",
      "rnn_in_flat (None, None, 32)\n",
      "rnn_fc_in (None, 128, 1024)\n",
      "lstm_in (None, None, 1024)\n",
      "lstm_cell (None, 32)\n",
      "output (None, 32)\n",
      "rnn_output (32,)\n",
      "lstm_fc_out (None, 1024)\n",
      "lstm_fc_drop (None, 1024)\n",
      "fuse_cnn_rnn  (None, 2077)\n",
      "(None, 2)\n",
      "y  Tensor(\"dense_6/Softmax:0\", shape=(None, 2), dtype=float32)\n",
      "Model :  yes_dominance_s12_0_fold\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 9, 9, 128)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 9, 9, 32)     65568       input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 9, 9, 32)     128         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "elu_6 (ELU)                     (None, 9, 9, 32)     0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 9, 9, 64)     32832       elu_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 9, 9, 64)     256         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "elu_7 (ELU)                     (None, 9, 9, 64)     0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 9, 9, 128)    131200      elu_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            (None, 128, 32)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 9, 9, 128)    512         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_7 (Reshape)             (None, 128, 32)      0           input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "elu_8 (ELU)                     (None, 9, 9, 128)    0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 128, 1024)    33792       reshape_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_5 (Reshape)             (None, 9, 9, 128)    0           elu_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "elu_10 (ELU)                    (None, 128, 1024)    0           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 9, 9, 13)     1677        reshape_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_8 (Reshape)             (None, 128, 1024)    0           elu_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 9, 9, 13)     52          conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "rnn_2 (RNN)                     (None, 32)           143616      reshape_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "elu_9 (ELU)                     (None, 9, 9, 13)     0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 1024)         33792       rnn_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "reshape_6 (Reshape)             (None, 1053)         0           elu_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 1024)         0           dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 2077)         0           reshape_6[0][0]                  \n",
      "                                                                 dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 2)            4156        concatenate_2[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 447,581\n",
      "Trainable params: 447,107\n",
      "Non-trainable params: 474\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1728 samples, validate on 432 samples\n",
      "Epoch 1/50\n",
      " 256/1728 [===>..........................] - ETA: 10s - loss: 0.7845 - accuracy: 0.5664"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ABHISHEK_VERMA\\Anaconda3\\lib\\site-packages\\keras\\callbacks\\callbacks.py:95: RuntimeWarning: Method (on_train_batch_end) is slow compared to the batch update (10.319370). Check your callbacks.\n",
      "  % (hook_name, delta_t_median), RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1728/1728 [==============================] - 25s 15ms/step - loss: 0.3879 - accuracy: 0.8154 - val_loss: 0.2144 - val_accuracy: 0.9236\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.92361, saving model to lightningedge007a_results/yes/dominance/s12/max_acc_yes_dominance_s12.h5\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.21442, saving model to lightningedge007a_results/yes/dominance/s12/min_loss_yes_dominance_s12.h5\n",
      "Epoch 2/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 0.0772 - accuracy: 0.9722 - val_loss: 0.1507 - val_accuracy: 0.9398\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.92361 to 0.93981, saving model to lightningedge007a_results/yes/dominance/s12/max_acc_yes_dominance_s12.h5\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.21442 to 0.15074, saving model to lightningedge007a_results/yes/dominance/s12/min_loss_yes_dominance_s12.h5\n",
      "Epoch 3/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 0.0227 - accuracy: 0.9965 - val_loss: 0.1176 - val_accuracy: 0.9514\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.93981 to 0.95139, saving model to lightningedge007a_results/yes/dominance/s12/max_acc_yes_dominance_s12.h5\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.15074 to 0.11759, saving model to lightningedge007a_results/yes/dominance/s12/min_loss_yes_dominance_s12.h5\n",
      "Epoch 4/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 0.1124 - val_accuracy: 0.9537\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.95139 to 0.95370, saving model to lightningedge007a_results/yes/dominance/s12/max_acc_yes_dominance_s12.h5\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.11759 to 0.11241, saving model to lightningedge007a_results/yes/dominance/s12/min_loss_yes_dominance_s12.h5\n",
      "Epoch 5/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0983 - val_accuracy: 0.9630\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.95370 to 0.96296, saving model to lightningedge007a_results/yes/dominance/s12/max_acc_yes_dominance_s12.h5\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.11241 to 0.09829, saving model to lightningedge007a_results/yes/dominance/s12/min_loss_yes_dominance_s12.h5\n",
      "Epoch 6/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0950 - val_accuracy: 0.9653\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.96296 to 0.96528, saving model to lightningedge007a_results/yes/dominance/s12/max_acc_yes_dominance_s12.h5\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.09829 to 0.09498, saving model to lightningedge007a_results/yes/dominance/s12/min_loss_yes_dominance_s12.h5\n",
      "Epoch 7/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0887 - val_accuracy: 0.9676\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.96528 to 0.96759, saving model to lightningedge007a_results/yes/dominance/s12/max_acc_yes_dominance_s12.h5\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.09498 to 0.08871, saving model to lightningedge007a_results/yes/dominance/s12/min_loss_yes_dominance_s12.h5\n",
      "Epoch 8/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0862 - val_accuracy: 0.9676\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.96759\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.08871 to 0.08619, saving model to lightningedge007a_results/yes/dominance/s12/min_loss_yes_dominance_s12.h5\n",
      "Epoch 9/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0863 - val_accuracy: 0.9676\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.96759\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.08619\n",
      "Epoch 10/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0849 - val_accuracy: 0.9676\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.96759\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.08619 to 0.08490, saving model to lightningedge007a_results/yes/dominance/s12/min_loss_yes_dominance_s12.h5\n",
      "Epoch 11/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 8.9810e-04 - accuracy: 1.0000 - val_loss: 0.0847 - val_accuracy: 0.9676\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.96759\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.08490 to 0.08473, saving model to lightningedge007a_results/yes/dominance/s12/min_loss_yes_dominance_s12.h5\n",
      "Epoch 12/50\n",
      "1728/1728 [==============================] - 4s 2ms/step - loss: 7.7045e-04 - accuracy: 1.0000 - val_loss: 0.0843 - val_accuracy: 0.9676\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.96759\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.08473 to 0.08428, saving model to lightningedge007a_results/yes/dominance/s12/min_loss_yes_dominance_s12.h5\n",
      "Epoch 13/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 6.8233e-04 - accuracy: 1.0000 - val_loss: 0.0847 - val_accuracy: 0.9653\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.96759\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.08428\n",
      "Epoch 14/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 6.0430e-04 - accuracy: 1.0000 - val_loss: 0.0842 - val_accuracy: 0.9653\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.96759\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.08428 to 0.08415, saving model to lightningedge007a_results/yes/dominance/s12/min_loss_yes_dominance_s12.h5\n",
      "Epoch 15/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 5.4804e-04 - accuracy: 1.0000 - val_loss: 0.0841 - val_accuracy: 0.9653\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.96759\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.08415 to 0.08406, saving model to lightningedge007a_results/yes/dominance/s12/min_loss_yes_dominance_s12.h5\n",
      "Epoch 16/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 4.9115e-04 - accuracy: 1.0000 - val_loss: 0.0837 - val_accuracy: 0.9676\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.96759\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.08406 to 0.08372, saving model to lightningedge007a_results/yes/dominance/s12/min_loss_yes_dominance_s12.h5\n",
      "Epoch 17/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 4.4759e-04 - accuracy: 1.0000 - val_loss: 0.0846 - val_accuracy: 0.9653\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.96759\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.08372\n",
      "Epoch 18/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 4.0807e-04 - accuracy: 1.0000 - val_loss: 0.0848 - val_accuracy: 0.9653\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.96759\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.08372\n",
      "Epoch 19/50\n",
      "1728/1728 [==============================] - 4s 2ms/step - loss: 3.7131e-04 - accuracy: 1.0000 - val_loss: 0.0851 - val_accuracy: 0.9653\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.96759\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.08372\n",
      "Epoch 20/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 3.4230e-04 - accuracy: 1.0000 - val_loss: 0.0852 - val_accuracy: 0.9653\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.96759\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.08372\n",
      "Epoch 21/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 3.0893e-04 - accuracy: 1.0000 - val_loss: 0.0854 - val_accuracy: 0.9653\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.96759\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.08372\n",
      "Epoch 22/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 2.9305e-04 - accuracy: 1.0000 - val_loss: 0.0849 - val_accuracy: 0.9653\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.96759\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.08372\n",
      "Epoch 23/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 2.6859e-04 - accuracy: 1.0000 - val_loss: 0.0855 - val_accuracy: 0.9653\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.96759\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.08372\n",
      "Epoch 24/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 2.5313e-04 - accuracy: 1.0000 - val_loss: 0.0856 - val_accuracy: 0.9653\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.96759\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.08372\n",
      "Epoch 25/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 2.3580e-04 - accuracy: 1.0000 - val_loss: 0.0856 - val_accuracy: 0.9653\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.96759\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.08372\n",
      "Epoch 26/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 2.2049e-04 - accuracy: 1.0000 - val_loss: 0.0862 - val_accuracy: 0.9653\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.96759\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.08372\n",
      "Epoch 27/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 2.0319e-04 - accuracy: 1.0000 - val_loss: 0.0867 - val_accuracy: 0.9653\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.96759\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.08372\n",
      "Epoch 28/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.9216e-04 - accuracy: 1.0000 - val_loss: 0.0870 - val_accuracy: 0.9653\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.96759\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.08372\n",
      "Epoch 29/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.7987e-04 - accuracy: 1.0000 - val_loss: 0.0872 - val_accuracy: 0.9653\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.96759\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.08372\n",
      "Epoch 30/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.6940e-04 - accuracy: 1.0000 - val_loss: 0.0874 - val_accuracy: 0.9653\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.96759\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.08372\n",
      "Epoch 31/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.6416e-04 - accuracy: 1.0000 - val_loss: 0.0878 - val_accuracy: 0.9653\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.96759\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.08372\n",
      "Epoch 32/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.5158e-04 - accuracy: 1.0000 - val_loss: 0.0878 - val_accuracy: 0.9653\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.96759\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.08372\n",
      "Epoch 33/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.4514e-04 - accuracy: 1.0000 - val_loss: 0.0880 - val_accuracy: 0.9653\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.96759\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.08372\n",
      "Epoch 34/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.3926e-04 - accuracy: 1.0000 - val_loss: 0.0878 - val_accuracy: 0.9653\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.96759\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.08372\n",
      "Epoch 35/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.3016e-04 - accuracy: 1.0000 - val_loss: 0.0878 - val_accuracy: 0.9676\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.96759\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.08372\n",
      "Epoch 36/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.2552e-04 - accuracy: 1.0000 - val_loss: 0.0880 - val_accuracy: 0.9653\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.96759\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.08372\n",
      "Epoch 37/50\n",
      "1728/1728 [==============================] - 4s 2ms/step - loss: 1.2010e-04 - accuracy: 1.0000 - val_loss: 0.0882 - val_accuracy: 0.9653\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.96759\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.08372\n",
      "Epoch 38/50\n",
      "1728/1728 [==============================] - 4s 2ms/step - loss: 1.1333e-04 - accuracy: 1.0000 - val_loss: 0.0885 - val_accuracy: 0.9653\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.96759\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.08372\n",
      "Epoch 39/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.0780e-04 - accuracy: 1.0000 - val_loss: 0.0884 - val_accuracy: 0.9653\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.96759\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.08372\n",
      "Epoch 40/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.0391e-04 - accuracy: 1.0000 - val_loss: 0.0887 - val_accuracy: 0.9676\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.96759\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.08372\n",
      "Epoch 41/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 9.9235e-05 - accuracy: 1.0000 - val_loss: 0.0889 - val_accuracy: 0.9653\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.96759\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.08372\n",
      "Epoch 42/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 9.4389e-05 - accuracy: 1.0000 - val_loss: 0.0889 - val_accuracy: 0.9653\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.96759\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.08372\n",
      "Epoch 43/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 9.0995e-05 - accuracy: 1.0000 - val_loss: 0.0892 - val_accuracy: 0.9653\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.96759\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.08372\n",
      "Epoch 44/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 8.6750e-05 - accuracy: 1.0000 - val_loss: 0.0896 - val_accuracy: 0.9653\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.96759\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.08372\n",
      "Epoch 45/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 8.4897e-05 - accuracy: 1.0000 - val_loss: 0.0897 - val_accuracy: 0.9653\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.96759\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.08372\n",
      "Epoch 46/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 8.0608e-05 - accuracy: 1.0000 - val_loss: 0.0901 - val_accuracy: 0.9653\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.96759\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.08372\n",
      "Epoch 47/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 7.7084e-05 - accuracy: 1.0000 - val_loss: 0.0901 - val_accuracy: 0.9653\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.96759\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.08372\n",
      "Epoch 48/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 7.5581e-05 - accuracy: 1.0000 - val_loss: 0.0903 - val_accuracy: 0.9653\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.96759\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.08372\n",
      "Epoch 49/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 7.1878e-05 - accuracy: 1.0000 - val_loss: 0.0906 - val_accuracy: 0.9653\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.96759\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.08372\n",
      "Epoch 50/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 6.9484e-05 - accuracy: 1.0000 - val_loss: 0.0905 - val_accuracy: 0.9653\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.96759\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.08372\n",
      "240/240 [==============================] - 1s 3ms/step\n",
      "max acc:  [0.07817463129758835, 0.9708333611488342]\n",
      "240/240 [==============================] - 1s 3ms/step\n",
      "min loss:  [0.06424604970961809, 0.9666666388511658]\n",
      "---------------------------------------------------\n",
      "yes dominance s13\n",
      "---------------------------------------------------\n",
      "\n",
      "loaded shape: (2400,)\n",
      "(2400, 128, 9, 9)\n",
      "(2400, 128, 32)\n",
      "(2400,)\n",
      "(2400, 2)\n",
      "(2400, 128, 9, 9)\n",
      "(2400, 128, 32)\n",
      "(2400, 2)\n",
      "cnn_datasets.shape,rnn_datasets.shape,labels.shape :  (2400, 128, 9, 9) (2400, 128, 32) (2400, 2)\n",
      "(2400, 9, 9, 128)\n",
      "cnn_datasets.shape :  (2400, 9, 9, 128)\n",
      "========================Train / Test Shapes==============================\n",
      "(240, 9, 9, 128) (240, 128, 32) (2160, 9, 9, 128) (2160, 128, 32)\n",
      "================================ DNN ============================================\n",
      "input_cnn:  (None, 9, 9, 128)\n",
      "elu1:  (None, 9, 9, 32)\n",
      "elu2:  (None, 9, 9, 64)\n",
      "elu3:  (None, 9, 9, 128)\n",
      "reshape1:  (None, 9, 9, None)\n",
      "elu4:  (None, 9, 9, 13)\n",
      "reshape2:  (None, 1053)\n",
      "input_rnn (None, 128, 32)\n",
      "rnn_in_flat (None, None, 32)\n",
      "rnn_fc_in (None, 128, 1024)\n",
      "lstm_in (None, None, 1024)\n",
      "lstm_cell (None, 32)\n",
      "output (None, 32)\n",
      "rnn_output (32,)\n",
      "lstm_fc_out (None, 1024)\n",
      "lstm_fc_drop (None, 1024)\n",
      "fuse_cnn_rnn  (None, 2077)\n",
      "(None, 2)\n",
      "y  Tensor(\"dense_9/Softmax:0\", shape=(None, 2), dtype=float32)\n",
      "Model :  yes_dominance_s13_0_fold\n",
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            (None, 9, 9, 128)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 9, 9, 32)     65568       input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 9, 9, 32)     128         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "elu_11 (ELU)                    (None, 9, 9, 32)     0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 9, 9, 64)     32832       elu_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 9, 9, 64)     256         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "elu_12 (ELU)                    (None, 9, 9, 64)     0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 9, 9, 128)    131200      elu_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "input_6 (InputLayer)            (None, 128, 32)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 9, 9, 128)    512         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_11 (Reshape)            (None, 128, 32)      0           input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "elu_13 (ELU)                    (None, 9, 9, 128)    0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 128, 1024)    33792       reshape_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_9 (Reshape)             (None, 9, 9, 128)    0           elu_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "elu_15 (ELU)                    (None, 128, 1024)    0           dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 9, 9, 13)     1677        reshape_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_12 (Reshape)            (None, 128, 1024)    0           elu_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 9, 9, 13)     52          conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "rnn_3 (RNN)                     (None, 32)           143616      reshape_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "elu_14 (ELU)                    (None, 9, 9, 13)     0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 1024)         33792       rnn_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "reshape_10 (Reshape)            (None, 1053)         0           elu_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 1024)         0           dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 2077)         0           reshape_10[0][0]                 \n",
      "                                                                 dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 2)            4156        concatenate_3[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 447,581\n",
      "Trainable params: 447,107\n",
      "Non-trainable params: 474\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1728 samples, validate on 432 samples\n",
      "Epoch 1/50\n",
      " 256/1728 [===>..........................] - ETA: 10s - loss: 0.6414 - accuracy: 0.6641"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ABHISHEK_VERMA\\Anaconda3\\lib\\site-packages\\keras\\callbacks\\callbacks.py:95: RuntimeWarning: Method (on_train_batch_end) is slow compared to the batch update (10.941253). Check your callbacks.\n",
      "  % (hook_name, delta_t_median), RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1728/1728 [==============================] - 27s 16ms/step - loss: 0.4210 - accuracy: 0.8079 - val_loss: 0.2771 - val_accuracy: 0.8773\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.87731, saving model to lightningedge007a_results/yes/dominance/s13/max_acc_yes_dominance_s13.h5\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.27713, saving model to lightningedge007a_results/yes/dominance/s13/min_loss_yes_dominance_s13.h5\n",
      "Epoch 2/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 0.0922 - accuracy: 0.9670 - val_loss: 0.2093 - val_accuracy: 0.9097\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.87731 to 0.90972, saving model to lightningedge007a_results/yes/dominance/s13/max_acc_yes_dominance_s13.h5\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.27713 to 0.20928, saving model to lightningedge007a_results/yes/dominance/s13/min_loss_yes_dominance_s13.h5\n",
      "Epoch 3/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 0.0360 - accuracy: 0.9925 - val_loss: 0.1524 - val_accuracy: 0.9306\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.90972 to 0.93056, saving model to lightningedge007a_results/yes/dominance/s13/max_acc_yes_dominance_s13.h5\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.20928 to 0.15245, saving model to lightningedge007a_results/yes/dominance/s13/min_loss_yes_dominance_s13.h5\n",
      "Epoch 4/50\n",
      "1728/1728 [==============================] - 4s 2ms/step - loss: 0.0125 - accuracy: 0.9994 - val_loss: 0.1090 - val_accuracy: 0.9514\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.93056 to 0.95139, saving model to lightningedge007a_results/yes/dominance/s13/max_acc_yes_dominance_s13.h5\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.15245 to 0.10904, saving model to lightningedge007a_results/yes/dominance/s13/min_loss_yes_dominance_s13.h5\n",
      "Epoch 5/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 0.0069 - accuracy: 0.9994 - val_loss: 0.1235 - val_accuracy: 0.9560\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.95139 to 0.95602, saving model to lightningedge007a_results/yes/dominance/s13/max_acc_yes_dominance_s13.h5\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.10904\n",
      "Epoch 6/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0918 - val_accuracy: 0.9630\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.95602 to 0.96296, saving model to lightningedge007a_results/yes/dominance/s13/max_acc_yes_dominance_s13.h5\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.10904 to 0.09184, saving model to lightningedge007a_results/yes/dominance/s13/min_loss_yes_dominance_s13.h5\n",
      "Epoch 7/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0997 - val_accuracy: 0.9676\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.96296 to 0.96759, saving model to lightningedge007a_results/yes/dominance/s13/max_acc_yes_dominance_s13.h5\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.09184\n",
      "Epoch 8/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0854 - val_accuracy: 0.9630\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.96759\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.09184 to 0.08542, saving model to lightningedge007a_results/yes/dominance/s13/min_loss_yes_dominance_s13.h5\n",
      "Epoch 9/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0842 - val_accuracy: 0.9699\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.96759 to 0.96991, saving model to lightningedge007a_results/yes/dominance/s13/max_acc_yes_dominance_s13.h5\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.08542 to 0.08416, saving model to lightningedge007a_results/yes/dominance/s13/min_loss_yes_dominance_s13.h5\n",
      "Epoch 10/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 9.8802e-04 - accuracy: 1.0000 - val_loss: 0.0824 - val_accuracy: 0.9699\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.96991\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.08416 to 0.08244, saving model to lightningedge007a_results/yes/dominance/s13/min_loss_yes_dominance_s13.h5\n",
      "Epoch 11/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 8.6645e-04 - accuracy: 1.0000 - val_loss: 0.0809 - val_accuracy: 0.9722\n",
      "\n",
      "Epoch 00011: val_accuracy improved from 0.96991 to 0.97222, saving model to lightningedge007a_results/yes/dominance/s13/max_acc_yes_dominance_s13.h5\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.08244 to 0.08092, saving model to lightningedge007a_results/yes/dominance/s13/min_loss_yes_dominance_s13.h5\n",
      "Epoch 12/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 7.5428e-04 - accuracy: 1.0000 - val_loss: 0.0802 - val_accuracy: 0.9699\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.97222\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.08092 to 0.08015, saving model to lightningedge007a_results/yes/dominance/s13/min_loss_yes_dominance_s13.h5\n",
      "Epoch 13/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 6.8963e-04 - accuracy: 1.0000 - val_loss: 0.0784 - val_accuracy: 0.9699\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.97222\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.08015 to 0.07841, saving model to lightningedge007a_results/yes/dominance/s13/min_loss_yes_dominance_s13.h5\n",
      "Epoch 14/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 6.1106e-04 - accuracy: 1.0000 - val_loss: 0.0780 - val_accuracy: 0.9699\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.97222\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.07841 to 0.07805, saving model to lightningedge007a_results/yes/dominance/s13/min_loss_yes_dominance_s13.h5\n",
      "Epoch 15/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 5.4689e-04 - accuracy: 1.0000 - val_loss: 0.0783 - val_accuracy: 0.9722\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.97222\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.07805\n",
      "Epoch 16/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 5.0410e-04 - accuracy: 1.0000 - val_loss: 0.0769 - val_accuracy: 0.9722\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.97222\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.07805 to 0.07685, saving model to lightningedge007a_results/yes/dominance/s13/min_loss_yes_dominance_s13.h5\n",
      "Epoch 17/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 4.5466e-04 - accuracy: 1.0000 - val_loss: 0.0763 - val_accuracy: 0.9722\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.97222\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.07685 to 0.07631, saving model to lightningedge007a_results/yes/dominance/s13/min_loss_yes_dominance_s13.h5\n",
      "Epoch 18/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 4.1322e-04 - accuracy: 1.0000 - val_loss: 0.0757 - val_accuracy: 0.9722\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.97222\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.07631 to 0.07568, saving model to lightningedge007a_results/yes/dominance/s13/min_loss_yes_dominance_s13.h5\n",
      "Epoch 19/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 3.7739e-04 - accuracy: 1.0000 - val_loss: 0.0751 - val_accuracy: 0.9722\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.97222\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.07568 to 0.07509, saving model to lightningedge007a_results/yes/dominance/s13/min_loss_yes_dominance_s13.h5\n",
      "Epoch 20/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 3.5918e-04 - accuracy: 1.0000 - val_loss: 0.0756 - val_accuracy: 0.9722\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.97222\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.07509\n",
      "Epoch 21/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 3.2508e-04 - accuracy: 1.0000 - val_loss: 0.0753 - val_accuracy: 0.9745\n",
      "\n",
      "Epoch 00021: val_accuracy improved from 0.97222 to 0.97454, saving model to lightningedge007a_results/yes/dominance/s13/max_acc_yes_dominance_s13.h5\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.07509\n",
      "Epoch 22/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 3.0294e-04 - accuracy: 1.0000 - val_loss: 0.0746 - val_accuracy: 0.9745\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.97454\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.07509 to 0.07458, saving model to lightningedge007a_results/yes/dominance/s13/min_loss_yes_dominance_s13.h5\n",
      "Epoch 23/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 2.8285e-04 - accuracy: 1.0000 - val_loss: 0.0745 - val_accuracy: 0.9722\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.97454\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.07458 to 0.07447, saving model to lightningedge007a_results/yes/dominance/s13/min_loss_yes_dominance_s13.h5\n",
      "Epoch 24/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 2.6853e-04 - accuracy: 1.0000 - val_loss: 0.0744 - val_accuracy: 0.9722\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.97454\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.07447 to 0.07444, saving model to lightningedge007a_results/yes/dominance/s13/min_loss_yes_dominance_s13.h5\n",
      "Epoch 25/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 2.4787e-04 - accuracy: 1.0000 - val_loss: 0.0736 - val_accuracy: 0.9745\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.97454\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.07444 to 0.07356, saving model to lightningedge007a_results/yes/dominance/s13/min_loss_yes_dominance_s13.h5\n",
      "Epoch 26/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 2.3280e-04 - accuracy: 1.0000 - val_loss: 0.0742 - val_accuracy: 0.9745\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.97454\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.07356\n",
      "Epoch 27/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 2.2020e-04 - accuracy: 1.0000 - val_loss: 0.0733 - val_accuracy: 0.9722\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.97454\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.07356 to 0.07333, saving model to lightningedge007a_results/yes/dominance/s13/min_loss_yes_dominance_s13.h5\n",
      "Epoch 28/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 2.0641e-04 - accuracy: 1.0000 - val_loss: 0.0732 - val_accuracy: 0.9722\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.97454\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.07333 to 0.07316, saving model to lightningedge007a_results/yes/dominance/s13/min_loss_yes_dominance_s13.h5\n",
      "Epoch 29/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.9237e-04 - accuracy: 1.0000 - val_loss: 0.0733 - val_accuracy: 0.9722\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.97454\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.07316\n",
      "Epoch 30/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.8493e-04 - accuracy: 1.0000 - val_loss: 0.0735 - val_accuracy: 0.9722\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.97454\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.07316\n",
      "Epoch 31/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.7486e-04 - accuracy: 1.0000 - val_loss: 0.0735 - val_accuracy: 0.9722\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.97454\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.07316\n",
      "Epoch 32/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.6387e-04 - accuracy: 1.0000 - val_loss: 0.0729 - val_accuracy: 0.9722\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.97454\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.07316 to 0.07292, saving model to lightningedge007a_results/yes/dominance/s13/min_loss_yes_dominance_s13.h5\n",
      "Epoch 33/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.5524e-04 - accuracy: 1.0000 - val_loss: 0.0729 - val_accuracy: 0.9722\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.97454\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.07292 to 0.07288, saving model to lightningedge007a_results/yes/dominance/s13/min_loss_yes_dominance_s13.h5\n",
      "Epoch 34/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.4746e-04 - accuracy: 1.0000 - val_loss: 0.0735 - val_accuracy: 0.9722\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.97454\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.07288\n",
      "Epoch 35/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.3991e-04 - accuracy: 1.0000 - val_loss: 0.0727 - val_accuracy: 0.9722\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.97454\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.07288 to 0.07273, saving model to lightningedge007a_results/yes/dominance/s13/min_loss_yes_dominance_s13.h5\n",
      "Epoch 36/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.3368e-04 - accuracy: 1.0000 - val_loss: 0.0725 - val_accuracy: 0.9722\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.97454\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.07273 to 0.07251, saving model to lightningedge007a_results/yes/dominance/s13/min_loss_yes_dominance_s13.h5\n",
      "Epoch 37/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.3009e-04 - accuracy: 1.0000 - val_loss: 0.0728 - val_accuracy: 0.9722\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.97454\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.07251\n",
      "Epoch 38/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.2322e-04 - accuracy: 1.0000 - val_loss: 0.0731 - val_accuracy: 0.9722\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.97454\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.07251\n",
      "Epoch 39/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.1671e-04 - accuracy: 1.0000 - val_loss: 0.0726 - val_accuracy: 0.9722\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.97454\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.07251\n",
      "Epoch 40/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.1374e-04 - accuracy: 1.0000 - val_loss: 0.0723 - val_accuracy: 0.9722\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.97454\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.07251 to 0.07229, saving model to lightningedge007a_results/yes/dominance/s13/min_loss_yes_dominance_s13.h5\n",
      "Epoch 41/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.0766e-04 - accuracy: 1.0000 - val_loss: 0.0714 - val_accuracy: 0.9722\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.97454\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.07229 to 0.07143, saving model to lightningedge007a_results/yes/dominance/s13/min_loss_yes_dominance_s13.h5\n",
      "Epoch 42/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.0346e-04 - accuracy: 1.0000 - val_loss: 0.0721 - val_accuracy: 0.9722\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.97454\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.07143\n",
      "Epoch 43/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 9.9095e-05 - accuracy: 1.0000 - val_loss: 0.0723 - val_accuracy: 0.9722\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.97454\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.07143\n",
      "Epoch 44/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 9.6473e-05 - accuracy: 1.0000 - val_loss: 0.0726 - val_accuracy: 0.9722\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.97454\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.07143\n",
      "Epoch 45/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 9.2588e-05 - accuracy: 1.0000 - val_loss: 0.0724 - val_accuracy: 0.9722\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.97454\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.07143\n",
      "Epoch 46/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 8.8685e-05 - accuracy: 1.0000 - val_loss: 0.0724 - val_accuracy: 0.9745\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.97454\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.07143\n",
      "Epoch 47/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 8.5038e-05 - accuracy: 1.0000 - val_loss: 0.0718 - val_accuracy: 0.9745\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.97454\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.07143\n",
      "Epoch 48/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 8.1267e-05 - accuracy: 1.0000 - val_loss: 0.0717 - val_accuracy: 0.9745\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.97454\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.07143\n",
      "Epoch 49/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 7.9264e-05 - accuracy: 1.0000 - val_loss: 0.0715 - val_accuracy: 0.9745\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.97454\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.07143\n",
      "Epoch 50/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 7.6116e-05 - accuracy: 1.0000 - val_loss: 0.0717 - val_accuracy: 0.9745\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.97454\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.07143\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240/240 [==============================] - 1s 4ms/step\n",
      "max acc:  [0.0761141691977779, 0.9666666388511658]\n",
      "240/240 [==============================] - 1s 3ms/step\n",
      "min loss:  [0.0737880252301693, 0.9791666865348816]\n",
      "---------------------------------------------------\n",
      "yes dominance s14\n",
      "---------------------------------------------------\n",
      "\n",
      "loaded shape: (2400,)\n",
      "(2400, 128, 9, 9)\n",
      "(2400, 128, 32)\n",
      "(2400,)\n",
      "(2400, 2)\n",
      "(2400, 128, 9, 9)\n",
      "(2400, 128, 32)\n",
      "(2400, 2)\n",
      "cnn_datasets.shape,rnn_datasets.shape,labels.shape :  (2400, 128, 9, 9) (2400, 128, 32) (2400, 2)\n",
      "(2400, 9, 9, 128)\n",
      "cnn_datasets.shape :  (2400, 9, 9, 128)\n",
      "========================Train / Test Shapes==============================\n",
      "(240, 9, 9, 128) (240, 128, 32) (2160, 9, 9, 128) (2160, 128, 32)\n",
      "================================ DNN ============================================\n",
      "input_cnn:  (None, 9, 9, 128)\n",
      "elu1:  (None, 9, 9, 32)\n",
      "elu2:  (None, 9, 9, 64)\n",
      "elu3:  (None, 9, 9, 128)\n",
      "reshape1:  (None, 9, 9, None)\n",
      "elu4:  (None, 9, 9, 13)\n",
      "reshape2:  (None, 1053)\n",
      "input_rnn (None, 128, 32)\n",
      "rnn_in_flat (None, None, 32)\n",
      "rnn_fc_in (None, 128, 1024)\n",
      "lstm_in (None, None, 1024)\n",
      "lstm_cell (None, 32)\n",
      "output (None, 32)\n",
      "rnn_output (32,)\n",
      "lstm_fc_out (None, 1024)\n",
      "lstm_fc_drop (None, 1024)\n",
      "fuse_cnn_rnn  (None, 2077)\n",
      "(None, 2)\n",
      "y  Tensor(\"dense_12/Softmax:0\", shape=(None, 2), dtype=float32)\n",
      "Model :  yes_dominance_s14_0_fold\n",
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_7 (InputLayer)            (None, 9, 9, 128)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 9, 9, 32)     65568       input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 9, 9, 32)     128         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "elu_16 (ELU)                    (None, 9, 9, 32)     0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 9, 9, 64)     32832       elu_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 9, 9, 64)     256         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "elu_17 (ELU)                    (None, 9, 9, 64)     0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 9, 9, 128)    131200      elu_17[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "input_8 (InputLayer)            (None, 128, 32)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 9, 9, 128)    512         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_15 (Reshape)            (None, 128, 32)      0           input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "elu_18 (ELU)                    (None, 9, 9, 128)    0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 128, 1024)    33792       reshape_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_13 (Reshape)            (None, 9, 9, 128)    0           elu_18[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "elu_20 (ELU)                    (None, 128, 1024)    0           dense_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 9, 9, 13)     1677        reshape_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_16 (Reshape)            (None, 128, 1024)    0           elu_20[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 9, 9, 13)     52          conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "rnn_4 (RNN)                     (None, 32)           143616      reshape_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "elu_19 (ELU)                    (None, 9, 9, 13)     0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 1024)         33792       rnn_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "reshape_14 (Reshape)            (None, 1053)         0           elu_19[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 1024)         0           dense_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 2077)         0           reshape_14[0][0]                 \n",
      "                                                                 dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 2)            4156        concatenate_4[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 447,581\n",
      "Trainable params: 447,107\n",
      "Non-trainable params: 474\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Train on 1728 samples, validate on 432 samples\n",
      "Epoch 1/50\n",
      " 256/1728 [===>..........................] - ETA: 9s - loss: 0.8507 - accuracy: 0.6016 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ABHISHEK_VERMA\\Anaconda3\\lib\\site-packages\\keras\\callbacks\\callbacks.py:95: RuntimeWarning: Method (on_train_batch_end) is slow compared to the batch update (10.736345). Check your callbacks.\n",
      "  % (hook_name, delta_t_median), RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1728/1728 [==============================] - 26s 15ms/step - loss: 0.4728 - accuracy: 0.7911 - val_loss: 0.3019 - val_accuracy: 0.8866\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.88657, saving model to lightningedge007a_results/yes/dominance/s14/max_acc_yes_dominance_s14.h5\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.30187, saving model to lightningedge007a_results/yes/dominance/s14/min_loss_yes_dominance_s14.h5\n",
      "Epoch 2/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 0.1346 - accuracy: 0.9468 - val_loss: 0.2226 - val_accuracy: 0.9097\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.88657 to 0.90972, saving model to lightningedge007a_results/yes/dominance/s14/max_acc_yes_dominance_s14.h5\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.30187 to 0.22255, saving model to lightningedge007a_results/yes/dominance/s14/min_loss_yes_dominance_s14.h5\n",
      "Epoch 3/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 0.0555 - accuracy: 0.9855 - val_loss: 0.1836 - val_accuracy: 0.9236\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.90972 to 0.92361, saving model to lightningedge007a_results/yes/dominance/s14/max_acc_yes_dominance_s14.h5\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.22255 to 0.18356, saving model to lightningedge007a_results/yes/dominance/s14/min_loss_yes_dominance_s14.h5\n",
      "Epoch 4/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 0.0260 - accuracy: 0.9954 - val_loss: 0.1552 - val_accuracy: 0.9306\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.92361 to 0.93056, saving model to lightningedge007a_results/yes/dominance/s14/max_acc_yes_dominance_s14.h5\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.18356 to 0.15517, saving model to lightningedge007a_results/yes/dominance/s14/min_loss_yes_dominance_s14.h5\n",
      "Epoch 5/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 0.0140 - accuracy: 0.9994 - val_loss: 0.1544 - val_accuracy: 0.9444\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.93056 to 0.94444, saving model to lightningedge007a_results/yes/dominance/s14/max_acc_yes_dominance_s14.h5\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.15517 to 0.15443, saving model to lightningedge007a_results/yes/dominance/s14/min_loss_yes_dominance_s14.h5\n",
      "Epoch 6/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.1554 - val_accuracy: 0.9329\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.94444\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.15443\n",
      "Epoch 7/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.1281 - val_accuracy: 0.9421\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.94444\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.15443 to 0.12814, saving model to lightningedge007a_results/yes/dominance/s14/min_loss_yes_dominance_s14.h5\n",
      "Epoch 8/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.1279 - val_accuracy: 0.9514\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.94444 to 0.95139, saving model to lightningedge007a_results/yes/dominance/s14/max_acc_yes_dominance_s14.h5\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.12814 to 0.12795, saving model to lightningedge007a_results/yes/dominance/s14/min_loss_yes_dominance_s14.h5\n",
      "Epoch 9/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.1287 - val_accuracy: 0.9421\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.95139\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.12795\n",
      "Epoch 10/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.1244 - val_accuracy: 0.9421\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.95139\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.12795 to 0.12441, saving model to lightningedge007a_results/yes/dominance/s14/min_loss_yes_dominance_s14.h5\n",
      "Epoch 11/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.1218 - val_accuracy: 0.9514\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.95139\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.12441 to 0.12182, saving model to lightningedge007a_results/yes/dominance/s14/min_loss_yes_dominance_s14.h5\n",
      "Epoch 12/50\n",
      "1728/1728 [==============================] - 4s 3ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.1254 - val_accuracy: 0.9491\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.95139\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.12182\n",
      "Epoch 13/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 9.9834e-04 - accuracy: 1.0000 - val_loss: 0.1228 - val_accuracy: 0.9491\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.95139\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.12182\n",
      "Epoch 14/50\n",
      "1728/1728 [==============================] - 4s 2ms/step - loss: 8.7632e-04 - accuracy: 1.0000 - val_loss: 0.1230 - val_accuracy: 0.9491\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.95139\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.12182\n",
      "Epoch 15/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 8.0002e-04 - accuracy: 1.0000 - val_loss: 0.1246 - val_accuracy: 0.9468\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.95139\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.12182\n",
      "Epoch 16/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 7.1152e-04 - accuracy: 1.0000 - val_loss: 0.1235 - val_accuracy: 0.9468\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.95139\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.12182\n",
      "Epoch 17/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 6.4328e-04 - accuracy: 1.0000 - val_loss: 0.1268 - val_accuracy: 0.9491\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.95139\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.12182\n",
      "Epoch 18/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 5.7770e-04 - accuracy: 1.0000 - val_loss: 0.1245 - val_accuracy: 0.9468\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.95139\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.12182\n",
      "Epoch 19/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 5.2780e-04 - accuracy: 1.0000 - val_loss: 0.1255 - val_accuracy: 0.9491\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.95139\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.12182\n",
      "Epoch 20/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 4.8288e-04 - accuracy: 1.0000 - val_loss: 0.1259 - val_accuracy: 0.9468\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.95139\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.12182\n",
      "Epoch 21/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 4.4709e-04 - accuracy: 1.0000 - val_loss: 0.1266 - val_accuracy: 0.9468\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.95139\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.12182\n",
      "Epoch 22/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 4.0688e-04 - accuracy: 1.0000 - val_loss: 0.1283 - val_accuracy: 0.9468\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.95139\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.12182\n",
      "Epoch 23/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 3.7909e-04 - accuracy: 1.0000 - val_loss: 0.1286 - val_accuracy: 0.9468\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.95139\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.12182\n",
      "Epoch 24/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 3.5133e-04 - accuracy: 1.0000 - val_loss: 0.1295 - val_accuracy: 0.9491\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.95139\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.12182\n",
      "Epoch 25/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 3.2958e-04 - accuracy: 1.0000 - val_loss: 0.1292 - val_accuracy: 0.9491\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.95139\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.12182\n",
      "Epoch 26/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 3.0387e-04 - accuracy: 1.0000 - val_loss: 0.1300 - val_accuracy: 0.9491\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.95139\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.12182\n",
      "Epoch 27/50\n",
      "1728/1728 [==============================] - 4s 2ms/step - loss: 2.8789e-04 - accuracy: 1.0000 - val_loss: 0.1314 - val_accuracy: 0.9491\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.95139\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.12182\n",
      "Epoch 28/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1728/1728 [==============================] - 3s 2ms/step - loss: 2.6918e-04 - accuracy: 1.0000 - val_loss: 0.1320 - val_accuracy: 0.9491\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.95139\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.12182\n",
      "Epoch 29/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 2.5180e-04 - accuracy: 1.0000 - val_loss: 0.1333 - val_accuracy: 0.9491\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.95139\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.12182\n",
      "Epoch 30/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 2.3570e-04 - accuracy: 1.0000 - val_loss: 0.1337 - val_accuracy: 0.9491\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.95139\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.12182\n",
      "Epoch 31/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 2.2421e-04 - accuracy: 1.0000 - val_loss: 0.1354 - val_accuracy: 0.9491\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.95139\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.12182\n",
      "Epoch 32/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 2.1436e-04 - accuracy: 1.0000 - val_loss: 0.1337 - val_accuracy: 0.9468\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.95139\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.12182\n",
      "Epoch 33/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 2.0036e-04 - accuracy: 1.0000 - val_loss: 0.1355 - val_accuracy: 0.9491\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.95139\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.12182\n",
      "Epoch 34/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.8840e-04 - accuracy: 1.0000 - val_loss: 0.1351 - val_accuracy: 0.9491\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.95139\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.12182\n",
      "Epoch 35/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.7956e-04 - accuracy: 1.0000 - val_loss: 0.1360 - val_accuracy: 0.9491\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.95139\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.12182\n",
      "Epoch 36/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.7068e-04 - accuracy: 1.0000 - val_loss: 0.1366 - val_accuracy: 0.9491\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.95139\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.12182\n",
      "Epoch 37/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.6211e-04 - accuracy: 1.0000 - val_loss: 0.1381 - val_accuracy: 0.9491\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.95139\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.12182\n",
      "Epoch 38/50\n",
      "1728/1728 [==============================] - 4s 2ms/step - loss: 1.5560e-04 - accuracy: 1.0000 - val_loss: 0.1384 - val_accuracy: 0.9491\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.95139\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.12182\n",
      "Epoch 39/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.4908e-04 - accuracy: 1.0000 - val_loss: 0.1371 - val_accuracy: 0.9468\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.95139\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.12182\n",
      "Epoch 40/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.4187e-04 - accuracy: 1.0000 - val_loss: 0.1379 - val_accuracy: 0.9491\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.95139\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.12182\n",
      "Epoch 41/50\n",
      "1728/1728 [==============================] - 4s 2ms/step - loss: 1.3637e-04 - accuracy: 1.0000 - val_loss: 0.1388 - val_accuracy: 0.9491\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.95139\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.12182\n",
      "Epoch 42/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.2737e-04 - accuracy: 1.0000 - val_loss: 0.1391 - val_accuracy: 0.9491\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.95139\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.12182\n",
      "Epoch 43/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.2274e-04 - accuracy: 1.0000 - val_loss: 0.1392 - val_accuracy: 0.9491\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.95139\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.12182\n",
      "Epoch 44/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.1800e-04 - accuracy: 1.0000 - val_loss: 0.1382 - val_accuracy: 0.9468\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.95139\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.12182\n",
      "Epoch 45/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.1449e-04 - accuracy: 1.0000 - val_loss: 0.1410 - val_accuracy: 0.9491\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.95139\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.12182\n",
      "Epoch 46/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.0908e-04 - accuracy: 1.0000 - val_loss: 0.1410 - val_accuracy: 0.9491\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.95139\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.12182\n",
      "Epoch 47/50\n",
      "1024/1728 [================>.............] - ETA: 1s - loss: 1.0109e-04 - accuracy: 1.0000"
     ]
    }
   ],
   "source": [
    "np.random.seed(32)\n",
    "\n",
    "window_size = 128\n",
    "\n",
    "cnn_suffix ='.mat_win_128_cnn_dataset.pkl'\n",
    "rnn_suffix ='.mat_win_128_rnn_dataset.pkl'\n",
    "label_suffix ='.mat_win_128_labels.pkl'\n",
    "\n",
    "for with_or_without in baseline_preprocessing:\n",
    "    for arousal_or_valence in emotions:\n",
    "        for data_file in data_files:\n",
    "            \n",
    "            gc.collect()\n",
    "            \n",
    "            print('---------------------------------------------------')\n",
    "            print(with_or_without+' '+arousal_or_valence+' '+data_file)\n",
    "            print('---------------------------------------------------\\n')\n",
    "\n",
    "            #data_file    ='s17'\n",
    "            #arousal_or_valence = 'valence'\n",
    "            #with_or_without = 'yes'\n",
    "\n",
    "            dataset_dir = 'deap_shuffled_data/'+with_or_without+'_'+arousal_or_valence+'/'\n",
    "            ###load training set\n",
    "            try:\n",
    "                with open(dataset_dir + data_file + cnn_suffix, \"rb\") as fp:\n",
    "                    cnn_datasets = pickle.load(fp)\n",
    "                with open(dataset_dir + data_file + rnn_suffix, \"rb\") as fp:\n",
    "                    rnn_datasets = pickle.load(fp)\n",
    "                with open(dataset_dir + data_file + label_suffix, \"rb\") as fp:\n",
    "                    labels = pickle.load(fp)\n",
    "                    labels = np.transpose(labels)\n",
    "                    print(\"loaded shape:\",labels.shape)\n",
    "            except:\n",
    "                continue\n",
    "            lables_backup = labels\n",
    "\n",
    "            print(cnn_datasets.shape)\n",
    "            print(rnn_datasets.shape)\n",
    "            print(labels.shape)\n",
    "\n",
    "            #print(\"cnn_dataset shape before reshape:\", np.shape(cnn_datasets))\n",
    "            # cnn_datasets = cnn_datasets.reshape(len(cnn_datasets), window_size, 9,9, 1)\n",
    "            #print(\"cnn_dataset shape after reshape:\", np.shape(cnn_datasets))\n",
    "            one_hot_labels = np.array(list(pd.get_dummies(labels)))\n",
    "\n",
    "            labels = np.asarray(pd.get_dummies(labels), dtype=np.int8)\n",
    "\n",
    "            print(labels.shape)\n",
    "            # shuffle data\n",
    "            index = np.array(range(0, len(labels)))\n",
    "            np.random.shuffle(index)\n",
    "\n",
    "            cnn_datasets   = cnn_datasets[index]\n",
    "            rnn_datasets   = rnn_datasets[index]\n",
    "            labels  = labels[index]\n",
    "\n",
    "            print(cnn_datasets.shape)\n",
    "            print(rnn_datasets.shape)\n",
    "            print(labels.shape)\n",
    "\n",
    "            #print(\"**********(\" + time.asctime(time.localtime(time.time())) + \") Load and Split dataset End **********\\n\")\n",
    "            #print(\"**********(\" + time.asctime(time.localtime(time.time())) + \") Define parameters and functions Begin: **********\\n\")\n",
    "            print('cnn_datasets.shape,rnn_datasets.shape,labels.shape : ',cnn_datasets.shape,rnn_datasets.shape,labels.shape)\n",
    "            #important\n",
    "            cnn_datasets=cnn_datasets.reshape(2400,9,9,-1)# imp\n",
    "            print(cnn_datasets.shape)\n",
    "            print('cnn_datasets.shape : ',cnn_datasets.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            print('========================Train / Test Shapes==============================')\n",
    "\n",
    "\n",
    "\n",
    "            fold=10\n",
    "            curr_fold=0\n",
    "            #for curr_fold in range(fold): # kernel dies\n",
    "                \n",
    "            #   print('curr_fold / fold : ',curr_fold,' / ',fold)\n",
    "\n",
    "\n",
    "            max_acc_acc_list=[]\n",
    "\n",
    "            max_acc_loss_list=[]\n",
    "\n",
    "\n",
    "            min_loss_acc_list=[]\n",
    "\n",
    "            min_loss_loss_list=[]\n",
    "\n",
    "            fold_size = cnn_datasets.shape[0]//fold\n",
    "            indexes_list = [i for i in range(len(cnn_datasets))]\n",
    "            indexes = np.array(indexes_list)\n",
    "            split_list = [i for i in range(curr_fold*fold_size,(curr_fold+1)*fold_size)]\n",
    "            split = np.array(split_list)\n",
    "\n",
    "            cnn_test = cnn_datasets[split] \n",
    "            labels_test = labels[split]\n",
    "            rnn_test = rnn_datasets[split]\n",
    "\n",
    "            split = np.array(list(set(indexes_list)^set(split_list)))\n",
    "\n",
    "            cnn_train = cnn_datasets[split]\n",
    "            rnn_train = rnn_datasets[split]\n",
    "            labels_train = labels[split]\n",
    "\n",
    "            # train_sample = labels_train.shape[0]\n",
    "            # print(\"training examples:\", train_sample)\n",
    "            # test_sample = labels_test.shape[0]\n",
    "            # print(\"test examples    :\",test_sample)\n",
    "            print(cnn_test.shape,rnn_test.shape,cnn_train.shape,rnn_train.shape)\n",
    "\n",
    "            print('================================ DNN ============================================')\n",
    "\n",
    "            input_cnn=Input(shape=(9,9,128))\n",
    "\n",
    "            print('input_cnn: ',input_cnn.shape)\n",
    "\n",
    "            conv1=Conv2D(32,\n",
    "                          kernel_size=(4,4),\n",
    "                          strides=(1,1),\n",
    "                          padding='same',\n",
    "                          input_shape=(9,9,128)\n",
    "                         )(input_cnn)\n",
    "\n",
    "\n",
    "            bn1=BatchNormalization()(conv1)\n",
    "\n",
    "            elu1=ELU()(bn1)\n",
    "\n",
    "            print('elu1: ',elu1.shape)\n",
    "            #?,9,9,32\n",
    "            conv2=Conv2D(64,\n",
    "                          kernel_size=(4,4),\n",
    "                          strides=(1,1),\n",
    "                          padding='same'\n",
    "                         )(elu1)\n",
    "\n",
    "            bn2=BatchNormalization()(conv2)\n",
    "\n",
    "            elu2=ELU()(bn2)\n",
    "\n",
    "            print('elu2: ',elu2.shape)\n",
    "            #?,9,9,64\n",
    "\n",
    "            conv3=Conv2D(128,\n",
    "                          kernel_size=(4,4),\n",
    "                          strides=(1,1),\n",
    "                          padding='same'\n",
    "                         )(elu2)\n",
    "\n",
    "            bn3=BatchNormalization()(conv3)\n",
    "\n",
    "            elu3=ELU()(bn3)\n",
    "\n",
    "\n",
    "            print('elu3: ',elu3.shape)\n",
    "            #?,9,9,128\n",
    "\n",
    "            # mc.add(Flatten())\n",
    "            # mc.add(Lambda(lambda x:x,output_shape=(9,9,32*4*128)))\n",
    "            # mc.add(Lambda(K.reshape((-1,9,9,32*4*128))))\n",
    "            reshape1=Reshape((9,9,-1))(elu3)\n",
    "\n",
    "\n",
    "            print('reshape1: ',reshape1.shape)\n",
    "            #?,9,9,32*4*128\n",
    "\n",
    "            conv4=Conv2D(13,#32*4*128,\n",
    "                          kernel_size=(1,1),\n",
    "                          strides=(1,1),\n",
    "                          padding='same'\n",
    "                         )(reshape1)\n",
    "\n",
    "            bn4=BatchNormalization()(conv4)\n",
    "\n",
    "            elu4=ELU()(bn4)\n",
    "\n",
    "\n",
    "            print('elu4: ',elu4.shape)\n",
    "            #?,9,9,13 #32*4*128\n",
    "\n",
    "            # mc.add(Flatten())\n",
    "\n",
    "            # mc.add(Lambda(lambda x:x,output_shape=([13*9*9])))\n",
    "            # mc.add(Lambda(K.reshape((None,13*9*9))))\n",
    "            reshape2=Reshape(([13*9*9]))(elu4)\n",
    "\n",
    "\n",
    "            print('reshape2: ',reshape2.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            cnn_out_fuse=reshape2\n",
    "\n",
    "\n",
    "            # cube=K.reshape(e3,(-1,9,9,32*4*128))#(e3)\n",
    "\n",
    "\n",
    "            # flat=K.reshape(e4,(-1,13*9*9))#(e4) #1053\n",
    "\n",
    "            # rnn_in=K.placeholder(shape=(None,128,32))\n",
    "            # rnn_in=tf.convert_to_tensor(rnn_datasets,dtype='float32')\n",
    "\n",
    "\n",
    "            # rnn_in.get_shape().as_list()\n",
    "\n",
    "            # rnn_in=K.placeholder(shape=(None,128,32))\n",
    "            # rnn_in_flat=K.reshape(rnn_in,[-1,32])\n",
    "\n",
    "            # print('rnn_in ',rnn_in.shape)\n",
    "\n",
    "            input_rnn=Input(shape=(128,32))\n",
    "            print('input_rnn',input_rnn.shape)\n",
    "\n",
    "            rnn_in_flat=Reshape((-1,32))(input_rnn)\n",
    "            print('rnn_in_flat',rnn_in_flat.shape)\n",
    "            # rnn_in_flat = Lambda(lambda x:x[:,0])(input_rnn)\n",
    "\n",
    "            # rnn_fc_in1 =Dense(32)(rnn_in_flat)\n",
    "            rnn_fc_in1 =Dense(1024)(rnn_in_flat)\n",
    "            rnn_fc_in=ELU()(rnn_fc_in1)\n",
    "            print('rnn_fc_in',rnn_fc_in.shape)\n",
    "\n",
    "            # rnn_fc_in =Dense(1024)(input_rnn)\n",
    "\n",
    "            # lstm_in=Reshape((-1,128,1024))(rnn_fc_in)\n",
    "            lstm_in=Reshape((-1,1024))(rnn_fc_in)\n",
    "            print('lstm_in',lstm_in.shape)\n",
    "\n",
    "            cells=[]\n",
    "\n",
    "            for i in range(2):\n",
    "                cell=LSTMCell(32,unit_forget_bias=True,dropout=0.5)#'forget_bias'=1.0,'state_is_tuple'=True\n",
    "                cells.append(cell)\n",
    "            #     print(cell.shape)\n",
    "\n",
    "            # lstm_cell=StackedRNNCells(cells)\n",
    "            lstm_cell=RNN(cells)(lstm_in)\n",
    "            # print(lstm_cell.shape)\n",
    "            # op,states=RNN(cells)(lstm_in)\n",
    "            print('lstm_cell',lstm_cell.shape)\n",
    "            # output=K.transpose_shape((1,0,2),lstm_cell)\n",
    "            # output=Permute((1,0,2))(lstm_cell)\n",
    "            # output.reshape()\n",
    "            output=lstm_cell\n",
    "            print('output',output.shape)\n",
    "            rnn_output=output[-1]\n",
    "            # rnn_output\n",
    "\n",
    "            print('rnn_output',rnn_output.shape)\n",
    "            # shape_rnn_out=rnn_output.get_shape().as_list()\n",
    "            lstm_fc_out=Dense(1024)(output)#shape_rnn_out[1]\n",
    "\n",
    "            print('lstm_fc_out',lstm_fc_out.shape)\n",
    "\n",
    "\n",
    "            # lstm_fc_out_2=Dense(1053)(lstm_fc_out)#shape_rnn_out[1]\n",
    "\n",
    "\n",
    "\n",
    "            lstm_fc_drop=Dropout(0.5)(lstm_fc_out)\n",
    "            # lstm_fc_drop\n",
    "            print('lstm_fc_drop',lstm_fc_drop.shape)\n",
    "\n",
    "            # fuse_cnn_rnn=add([cnn_out_fuse,lstm_fc_drop])\n",
    "\n",
    "            fuse_cnn_rnn=concatenate([cnn_out_fuse,lstm_fc_drop])\n",
    "            print('fuse_cnn_rnn ',fuse_cnn_rnn.shape)\n",
    "            y=Dense(2,activation='softmax')(fuse_cnn_rnn) ## ,activity_regularizer=regularizers.l2(0.5)\n",
    "            print(y.shape)\n",
    "            y_pred=K.argmax(y,1)\n",
    "            # y_pred=K.argmax(K.softmax(y))\n",
    "            # y_posi=K.softmax(y)\n",
    "            print('y ',y)\n",
    "\n",
    "\n",
    "            directory_le007a='./lightningedge007a_results/'+with_or_without+'/'+arousal_or_valence+'/'+data_file\n",
    "            try:\n",
    "                if not os.path.exists(directory_le007a):\n",
    "                    os.makedirs(directory_le007a)\n",
    "            except OSError:\n",
    "                print ('Error: Creating directory. ' +  directory_le007a)\n",
    "\n",
    "\n",
    "\n",
    "            model=Model(inputs=[input_cnn,input_rnn],outputs=y)\n",
    "            model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "            print('Model : ',with_or_without+'_'+arousal_or_valence+'_'+data_file+'_'+str(curr_fold)+'_fold')\n",
    "            print(model.summary())\n",
    "\n",
    "            m_val_acc=ModelCheckpoint('lightningedge007a_results/'+with_or_without+'/'+arousal_or_valence+'/'+data_file+'/'+'max_acc_'+with_or_without+'_'+arousal_or_valence+'_'+data_file+'.h5',monitor='val_accuracy',mode='max',verbose=1,save_best_only=True)\n",
    "            m_val_loss=ModelCheckpoint('lightningedge007a_results/'+with_or_without+'/'+arousal_or_valence+'/'+data_file+'/'+'min_loss_'+with_or_without+'_'+arousal_or_valence+'_'+data_file+'.h5',monitor='val_loss',mode='min',verbose=1,save_best_only=True)\n",
    "\n",
    "\n",
    "            tb_log_dir='lightningedge007a_results\\\\'+with_or_without+'\\\\'+arousal_or_valence+'\\\\'+data_file+'\\\\'+'logs_'+with_or_without+'_'+arousal_or_valence+'_'+data_file\n",
    "            #tb_log_dir='lightningedge007a_results/'+with_or_without+'/'+arousal_or_valence+'/'+data_file+'/'+'logs_'+with_or_without+'_'+arousal_or_valence+'_'+data_file\n",
    "\n",
    "            createFolder(tb_log_dir)\n",
    "\n",
    "\n",
    "            #log_dir='lightningedge007a_results\\\\'+with_or_without+'\\\\'+arousal_or_valence+'\\\\'+data_file+'\\\\'+'logs_'+with_or_without+'_'+arousal_or_valence+'_'+data_file+'_'+str(curr_fold)+'_fold\\\\' #datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "            tensorboard_callback = callbacks.TensorBoard(log_dir=tb_log_dir)#, histogram_freq=1)\n",
    "\n",
    "            plotpicture=plot_model(model, to_file='lightningedge007a_results/'+with_or_without+'/'+arousal_or_valence+'/'+data_file+'/'+'model_'+with_or_without+'_'+arousal_or_valence+'_'+data_file+'.png', show_shapes=True)\n",
    "\n",
    "            \n",
    "            \n",
    "            gc.collect()\n",
    "            \n",
    "            \n",
    "\n",
    "            history=model.fit([cnn_train,rnn_train],labels_train,batch_size=128,epochs=50,callbacks=[tensorboard_callback,m_val_acc,m_val_loss],validation_split=0.2)\n",
    "\n",
    "\n",
    "            #Plot values\n",
    "            plt.plot(history.history['accuracy'])\n",
    "            plt.plot(history.history['val_accuracy'])\n",
    "            plt.title('max_acc_'+with_or_without+'_'+arousal_or_valence+'_'+data_file)\n",
    "            plt.ylabel('Accuracy')\n",
    "            plt.xlabel('Epoch')\n",
    "            plt.legend(['Train', 'Validation'], loc='upper right',bbox_to_anchor=(1.3,1))\n",
    "            plt.savefig('lightningedge007a_results/'+with_or_without+'/'+arousal_or_valence+'/'+data_file+'/'+'max_acc_'+with_or_without+'_'+arousal_or_valence+'_'+data_file+'.png',bbox_inches='tight')\n",
    "            #plt.show()\n",
    "            plt.close()\n",
    "\n",
    "\n",
    "            # Plot training & validation loss values\n",
    "            plt.plot(history.history['loss'])\n",
    "            plt.plot(history.history['val_loss'])\n",
    "            plt.title('min_loss_'+with_or_without+'_'+arousal_or_valence+'_'+data_file+'_'+str(curr_fold)+'_fold')\n",
    "            plt.ylabel('Loss')\n",
    "            plt.xlabel('Epoch')\n",
    "            plt.legend(['Train', 'Validation'], loc='upper right',bbox_to_anchor=(1.3,1))\n",
    "            plt.savefig('lightningedge007a_results/'+with_or_without+'/'+arousal_or_valence+'/'+data_file+'/'+'min_loss_'+with_or_without+'_'+arousal_or_valence+'_'+data_file+'.png',bbox_inches='tight')\n",
    "            #plt.show()\n",
    "            plt.close()\n",
    "\n",
    "            vam=load_model('lightningedge007a_results/'+with_or_without+'/'+arousal_or_valence+'/'+data_file+'/'+'max_acc_'+with_or_without+'_'+arousal_or_valence+'_'+data_file+'.h5')\n",
    "            vlm=load_model('lightningedge007a_results/'+with_or_without+'/'+arousal_or_valence+'/'+data_file+'/'+'min_loss_'+with_or_without+'_'+arousal_or_valence+'_'+data_file+'.h5')\n",
    "            # pred_labels=vam()\n",
    "            vam_eval=vam.evaluate([cnn_test,rnn_test],labels_test)\n",
    "            print('max acc: ',vam_eval)\n",
    "            vlm_eval=vlm.evaluate([cnn_test,rnn_test],labels_test)\n",
    "            print('min loss: ',vlm_eval)\n",
    "\n",
    "\n",
    "            max_acc_acc_list.append(vam_eval[1])\n",
    "\n",
    "            max_acc_loss_list.append(vam_eval[0])\n",
    "\n",
    "\n",
    "            min_loss_acc_list.append(vlm_eval[1])\n",
    "\n",
    "            min_loss_loss_list.append(vlm_eval[0])\n",
    "\n",
    "            pickle.dump(max_acc_acc_list,open('lightningedge007a_results/'+with_or_without+'/'+arousal_or_valence+'/'+data_file+'/'+'max_acc_acc_list_'+with_or_without+'_'+arousal_or_valence+'_'+data_file+'.pkl','wb'))\n",
    "\n",
    "            pickle.dump(max_acc_loss_list,open('lightningedge007a_results/'+with_or_without+'/'+arousal_or_valence+'/'+data_file+'/'+'max_acc_loss_list_'+with_or_without+'_'+arousal_or_valence+'_'+data_file+'.pkl','wb'))\n",
    "\n",
    "\n",
    "            pickle.dump(min_loss_acc_list,open('lightningedge007a_results/'+with_or_without+'/'+arousal_or_valence+'/'+data_file+'/'+'min_loss_acc_list_'+with_or_without+'_'+arousal_or_valence+'_'+data_file+'.pkl','wb'))\n",
    "\n",
    "            pickle.dump(min_loss_loss_list,open('lightningedge007a_results/'+with_or_without+'/'+arousal_or_valence+'/'+data_file+'/'+'min_loss_loss_list_'+with_or_without+'_'+arousal_or_valence+'_'+data_file+'.pkl','wb'))\n",
    "            \n",
    "            \n",
    "            gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-08T15:30:34.253498Z",
     "start_time": "2019-11-08T15:30:34.249477Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['s14', 's15']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_files=data_files[13:15]\n",
    "data_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-08T15:39:50.213997Z",
     "start_time": "2019-11-08T15:30:43.451786Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------\n",
      "yes dominance s14\n",
      "---------------------------------------------------\n",
      "\n",
      "loaded shape: (2400,)\n",
      "(2400, 128, 9, 9)\n",
      "(2400, 128, 32)\n",
      "(2400,)\n",
      "(2400, 2)\n",
      "(2400, 128, 9, 9)\n",
      "(2400, 128, 32)\n",
      "(2400, 2)\n",
      "cnn_datasets.shape,rnn_datasets.shape,labels.shape :  (2400, 128, 9, 9) (2400, 128, 32) (2400, 2)\n",
      "(2400, 9, 9, 128)\n",
      "cnn_datasets.shape :  (2400, 9, 9, 128)\n",
      "========================Train / Test Shapes==============================\n",
      "(240, 9, 9, 128) (240, 128, 32) (2160, 9, 9, 128) (2160, 128, 32)\n",
      "================================ DNN ============================================\n",
      "input_cnn:  (None, 9, 9, 128)\n",
      "elu1:  (None, 9, 9, 32)\n",
      "elu2:  (None, 9, 9, 64)\n",
      "elu3:  (None, 9, 9, 128)\n",
      "reshape1:  (None, 9, 9, None)\n",
      "elu4:  (None, 9, 9, 13)\n",
      "reshape2:  (None, 1053)\n",
      "input_rnn (None, 128, 32)\n",
      "rnn_in_flat (None, None, 32)\n",
      "rnn_fc_in (None, 128, 1024)\n",
      "lstm_in (None, None, 1024)\n",
      "lstm_cell (None, 32)\n",
      "output (None, 32)\n",
      "rnn_output (32,)\n",
      "lstm_fc_out (None, 1024)\n",
      "lstm_fc_drop (None, 1024)\n",
      "fuse_cnn_rnn  (None, 2077)\n",
      "(None, 2)\n",
      "y  Tensor(\"dense_3/Softmax:0\", shape=(None, 2), dtype=float32)\n",
      "Model :  yes_dominance_s14_0_fold\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 9, 9, 128)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 9, 9, 32)     65568       input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 9, 9, 32)     128         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "elu_1 (ELU)                     (None, 9, 9, 32)     0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 9, 9, 64)     32832       elu_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 9, 9, 64)     256         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "elu_2 (ELU)                     (None, 9, 9, 64)     0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 9, 9, 128)    131200      elu_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 128, 32)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 9, 9, 128)    512         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_3 (Reshape)             (None, 128, 32)      0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "elu_3 (ELU)                     (None, 9, 9, 128)    0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 128, 1024)    33792       reshape_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 9, 9, 128)    0           elu_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "elu_5 (ELU)                     (None, 128, 1024)    0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 9, 9, 13)     1677        reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_4 (Reshape)             (None, 128, 1024)    0           elu_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 9, 9, 13)     52          conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "rnn_1 (RNN)                     (None, 32)           143616      reshape_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "elu_4 (ELU)                     (None, 9, 9, 13)     0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1024)         33792       rnn_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "reshape_2 (Reshape)             (None, 1053)         0           elu_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 1024)         0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 2077)         0           reshape_2[0][0]                  \n",
      "                                                                 dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 2)            4156        concatenate_1[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 447,581\n",
      "Trainable params: 447,107\n",
      "Non-trainable params: 474\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Train on 1728 samples, validate on 432 samples\n",
      "Epoch 1/50\n",
      " 256/1728 [===>..........................] - ETA: 19s - loss: 0.8421 - accuracy: 0.5547"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ABHISHEK_VERMA\\Anaconda3\\lib\\site-packages\\keras\\callbacks\\callbacks.py:95: RuntimeWarning: Method (on_train_batch_end) is slow compared to the batch update (10.863425). Check your callbacks.\n",
      "  % (hook_name, delta_t_median), RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1728/1728 [==============================] - 28s 16ms/step - loss: 0.4619 - accuracy: 0.7859 - val_loss: 0.3790 - val_accuracy: 0.8310\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.83102, saving model to lightningedge007a_results/yes/dominance/s14/max_acc_yes_dominance_s14.h5\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.37900, saving model to lightningedge007a_results/yes/dominance/s14/min_loss_yes_dominance_s14.h5\n",
      "Epoch 2/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 0.1387 - accuracy: 0.9491 - val_loss: 0.3035 - val_accuracy: 0.8704\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.83102 to 0.87037, saving model to lightningedge007a_results/yes/dominance/s14/max_acc_yes_dominance_s14.h5\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.37900 to 0.30349, saving model to lightningedge007a_results/yes/dominance/s14/min_loss_yes_dominance_s14.h5\n",
      "Epoch 3/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 0.0571 - accuracy: 0.9844 - val_loss: 0.2379 - val_accuracy: 0.9005\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.87037 to 0.90046, saving model to lightningedge007a_results/yes/dominance/s14/max_acc_yes_dominance_s14.h5\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.30349 to 0.23791, saving model to lightningedge007a_results/yes/dominance/s14/min_loss_yes_dominance_s14.h5\n",
      "Epoch 4/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 0.0245 - accuracy: 0.9977 - val_loss: 0.2176 - val_accuracy: 0.9120\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.90046 to 0.91204, saving model to lightningedge007a_results/yes/dominance/s14/max_acc_yes_dominance_s14.h5\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.23791 to 0.21757, saving model to lightningedge007a_results/yes/dominance/s14/min_loss_yes_dominance_s14.h5\n",
      "Epoch 5/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 0.0125 - accuracy: 0.9994 - val_loss: 0.1887 - val_accuracy: 0.9306\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.91204 to 0.93056, saving model to lightningedge007a_results/yes/dominance/s14/max_acc_yes_dominance_s14.h5\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.21757 to 0.18873, saving model to lightningedge007a_results/yes/dominance/s14/min_loss_yes_dominance_s14.h5\n",
      "Epoch 6/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.1878 - val_accuracy: 0.9282\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.93056\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.18873 to 0.18777, saving model to lightningedge007a_results/yes/dominance/s14/min_loss_yes_dominance_s14.h5\n",
      "Epoch 7/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.1786 - val_accuracy: 0.9282\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.93056\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.18777 to 0.17862, saving model to lightningedge007a_results/yes/dominance/s14/min_loss_yes_dominance_s14.h5\n",
      "Epoch 8/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.1692 - val_accuracy: 0.9398\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.93056 to 0.93981, saving model to lightningedge007a_results/yes/dominance/s14/max_acc_yes_dominance_s14.h5\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.17862 to 0.16920, saving model to lightningedge007a_results/yes/dominance/s14/min_loss_yes_dominance_s14.h5\n",
      "Epoch 9/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.1729 - val_accuracy: 0.9375\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.93981\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.16920\n",
      "Epoch 10/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.1676 - val_accuracy: 0.9352\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.93981\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.16920 to 0.16759, saving model to lightningedge007a_results/yes/dominance/s14/min_loss_yes_dominance_s14.h5\n",
      "Epoch 11/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.1715 - val_accuracy: 0.9375\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.93981\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.16759\n",
      "Epoch 12/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.1691 - val_accuracy: 0.9352\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.93981\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.16759\n",
      "Epoch 13/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.1733 - val_accuracy: 0.9329\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.93981\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.16759\n",
      "Epoch 14/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 9.5158e-04 - accuracy: 1.0000 - val_loss: 0.1709 - val_accuracy: 0.9398\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.93981\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.16759\n",
      "Epoch 15/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 8.6518e-04 - accuracy: 1.0000 - val_loss: 0.1716 - val_accuracy: 0.9375\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.93981\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.16759\n",
      "Epoch 16/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 7.6063e-04 - accuracy: 1.0000 - val_loss: 0.1746 - val_accuracy: 0.9375\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.93981\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.16759\n",
      "Epoch 17/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 6.8850e-04 - accuracy: 1.0000 - val_loss: 0.1732 - val_accuracy: 0.9375\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.93981\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.16759\n",
      "Epoch 18/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 6.3648e-04 - accuracy: 1.0000 - val_loss: 0.1752 - val_accuracy: 0.9375\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.93981\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.16759\n",
      "Epoch 19/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 5.6572e-04 - accuracy: 1.0000 - val_loss: 0.1747 - val_accuracy: 0.9375\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.93981\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.16759\n",
      "Epoch 20/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 5.1115e-04 - accuracy: 1.0000 - val_loss: 0.1779 - val_accuracy: 0.9398\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.93981\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.16759\n",
      "Epoch 21/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 4.6775e-04 - accuracy: 1.0000 - val_loss: 0.1783 - val_accuracy: 0.9375\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.93981\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.16759\n",
      "Epoch 22/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 4.3312e-04 - accuracy: 1.0000 - val_loss: 0.1786 - val_accuracy: 0.9375\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.93981\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.16759\n",
      "Epoch 23/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 3.9575e-04 - accuracy: 1.0000 - val_loss: 0.1792 - val_accuracy: 0.9375\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.93981\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.16759\n",
      "Epoch 24/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 3.6890e-04 - accuracy: 1.0000 - val_loss: 0.1806 - val_accuracy: 0.9375\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.93981\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.16759\n",
      "Epoch 25/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 3.4509e-04 - accuracy: 1.0000 - val_loss: 0.1810 - val_accuracy: 0.9375\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.93981\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.16759\n",
      "Epoch 26/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 3.1654e-04 - accuracy: 1.0000 - val_loss: 0.1811 - val_accuracy: 0.9375\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.93981\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.16759\n",
      "Epoch 27/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 3.0162e-04 - accuracy: 1.0000 - val_loss: 0.1818 - val_accuracy: 0.9375\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.93981\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.16759\n",
      "Epoch 28/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1728/1728 [==============================] - 3s 2ms/step - loss: 2.8143e-04 - accuracy: 1.0000 - val_loss: 0.1824 - val_accuracy: 0.9329\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.93981\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.16759\n",
      "Epoch 29/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 2.6036e-04 - accuracy: 1.0000 - val_loss: 0.1833 - val_accuracy: 0.9352\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.93981\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.16759\n",
      "Epoch 30/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 2.4735e-04 - accuracy: 1.0000 - val_loss: 0.1844 - val_accuracy: 0.9352\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.93981\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.16759\n",
      "Epoch 31/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 2.3316e-04 - accuracy: 1.0000 - val_loss: 0.1846 - val_accuracy: 0.9375\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.93981\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.16759\n",
      "Epoch 32/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 2.2128e-04 - accuracy: 1.0000 - val_loss: 0.1856 - val_accuracy: 0.9375\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.93981\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.16759\n",
      "Epoch 33/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 2.0811e-04 - accuracy: 1.0000 - val_loss: 0.1863 - val_accuracy: 0.9375\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.93981\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.16759\n",
      "Epoch 34/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.9779e-04 - accuracy: 1.0000 - val_loss: 0.1866 - val_accuracy: 0.9352\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.93981\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.16759\n",
      "Epoch 35/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.8380e-04 - accuracy: 1.0000 - val_loss: 0.1872 - val_accuracy: 0.9352\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.93981\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.16759\n",
      "Epoch 36/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.7524e-04 - accuracy: 1.0000 - val_loss: 0.1880 - val_accuracy: 0.9352\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.93981\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.16759\n",
      "Epoch 37/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.6910e-04 - accuracy: 1.0000 - val_loss: 0.1887 - val_accuracy: 0.9352\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.93981\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.16759\n",
      "Epoch 38/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.5881e-04 - accuracy: 1.0000 - val_loss: 0.1894 - val_accuracy: 0.9352\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.93981\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.16759\n",
      "Epoch 39/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.5374e-04 - accuracy: 1.0000 - val_loss: 0.1890 - val_accuracy: 0.9352\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.93981\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.16759\n",
      "Epoch 40/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.4673e-04 - accuracy: 1.0000 - val_loss: 0.1896 - val_accuracy: 0.9352\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.93981\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.16759\n",
      "Epoch 41/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.3732e-04 - accuracy: 1.0000 - val_loss: 0.1904 - val_accuracy: 0.9375\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.93981\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.16759\n",
      "Epoch 42/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.3389e-04 - accuracy: 1.0000 - val_loss: 0.1901 - val_accuracy: 0.9352\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.93981\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.16759\n",
      "Epoch 43/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.2771e-04 - accuracy: 1.0000 - val_loss: 0.1899 - val_accuracy: 0.9352\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.93981\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.16759\n",
      "Epoch 44/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.2426e-04 - accuracy: 1.0000 - val_loss: 0.1908 - val_accuracy: 0.9352\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.93981\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.16759\n",
      "Epoch 45/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.1464e-04 - accuracy: 1.0000 - val_loss: 0.1918 - val_accuracy: 0.9398\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.93981\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.16759\n",
      "Epoch 46/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.1281e-04 - accuracy: 1.0000 - val_loss: 0.1918 - val_accuracy: 0.9375\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.93981\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.16759\n",
      "Epoch 47/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.0724e-04 - accuracy: 1.0000 - val_loss: 0.1912 - val_accuracy: 0.9375\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.93981\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.16759\n",
      "Epoch 48/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.0560e-04 - accuracy: 1.0000 - val_loss: 0.1917 - val_accuracy: 0.9398\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.93981\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.16759\n",
      "Epoch 49/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.0055e-04 - accuracy: 1.0000 - val_loss: 0.1916 - val_accuracy: 0.9352\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.93981\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.16759\n",
      "Epoch 50/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 9.6525e-05 - accuracy: 1.0000 - val_loss: 0.1923 - val_accuracy: 0.9398\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.93981\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.16759\n",
      "240/240 [==============================] - 1s 4ms/step\n",
      "max acc:  [0.12558981229861577, 0.949999988079071]\n",
      "240/240 [==============================] - 1s 3ms/step\n",
      "min loss:  [0.12033954759438832, 0.949999988079071]\n",
      "---------------------------------------------------\n",
      "yes dominance s15\n",
      "---------------------------------------------------\n",
      "\n",
      "loaded shape: (2400,)\n",
      "(2400, 128, 9, 9)\n",
      "(2400, 128, 32)\n",
      "(2400,)\n",
      "(2400, 2)\n",
      "(2400, 128, 9, 9)\n",
      "(2400, 128, 32)\n",
      "(2400, 2)\n",
      "cnn_datasets.shape,rnn_datasets.shape,labels.shape :  (2400, 128, 9, 9) (2400, 128, 32) (2400, 2)\n",
      "(2400, 9, 9, 128)\n",
      "cnn_datasets.shape :  (2400, 9, 9, 128)\n",
      "========================Train / Test Shapes==============================\n",
      "(240, 9, 9, 128) (240, 128, 32) (2160, 9, 9, 128) (2160, 128, 32)\n",
      "================================ DNN ============================================\n",
      "input_cnn:  (None, 9, 9, 128)\n",
      "elu1:  (None, 9, 9, 32)\n",
      "elu2:  (None, 9, 9, 64)\n",
      "elu3:  (None, 9, 9, 128)\n",
      "reshape1:  (None, 9, 9, None)\n",
      "elu4:  (None, 9, 9, 13)\n",
      "reshape2:  (None, 1053)\n",
      "input_rnn (None, 128, 32)\n",
      "rnn_in_flat (None, None, 32)\n",
      "rnn_fc_in (None, 128, 1024)\n",
      "lstm_in (None, None, 1024)\n",
      "lstm_cell (None, 32)\n",
      "output (None, 32)\n",
      "rnn_output (32,)\n",
      "lstm_fc_out (None, 1024)\n",
      "lstm_fc_drop (None, 1024)\n",
      "fuse_cnn_rnn  (None, 2077)\n",
      "(None, 2)\n",
      "y  Tensor(\"dense_6/Softmax:0\", shape=(None, 2), dtype=float32)\n",
      "Model :  yes_dominance_s15_0_fold\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 9, 9, 128)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 9, 9, 32)     65568       input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 9, 9, 32)     128         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "elu_6 (ELU)                     (None, 9, 9, 32)     0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 9, 9, 64)     32832       elu_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 9, 9, 64)     256         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "elu_7 (ELU)                     (None, 9, 9, 64)     0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 9, 9, 128)    131200      elu_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            (None, 128, 32)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 9, 9, 128)    512         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_7 (Reshape)             (None, 128, 32)      0           input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "elu_8 (ELU)                     (None, 9, 9, 128)    0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 128, 1024)    33792       reshape_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_5 (Reshape)             (None, 9, 9, 128)    0           elu_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "elu_10 (ELU)                    (None, 128, 1024)    0           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 9, 9, 13)     1677        reshape_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_8 (Reshape)             (None, 128, 1024)    0           elu_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 9, 9, 13)     52          conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "rnn_2 (RNN)                     (None, 32)           143616      reshape_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "elu_9 (ELU)                     (None, 9, 9, 13)     0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 1024)         33792       rnn_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "reshape_6 (Reshape)             (None, 1053)         0           elu_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 1024)         0           dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 2077)         0           reshape_6[0][0]                  \n",
      "                                                                 dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 2)            4156        concatenate_2[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 447,581\n",
      "Trainable params: 447,107\n",
      "Non-trainable params: 474\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1728 samples, validate on 432 samples\n",
      "Epoch 1/50\n",
      " 256/1728 [===>..........................] - ETA: 10s - loss: 0.9954 - accuracy: 0.5469"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ABHISHEK_VERMA\\Anaconda3\\lib\\site-packages\\keras\\callbacks\\callbacks.py:95: RuntimeWarning: Method (on_train_batch_end) is slow compared to the batch update (10.454029). Check your callbacks.\n",
      "  % (hook_name, delta_t_median), RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1728/1728 [==============================] - 25s 15ms/step - loss: 0.4106 - accuracy: 0.8275 - val_loss: 0.2016 - val_accuracy: 0.9329\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.93287, saving model to lightningedge007a_results/yes/dominance/s15/max_acc_yes_dominance_s15.h5\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.20161, saving model to lightningedge007a_results/yes/dominance/s15/min_loss_yes_dominance_s15.h5\n",
      "Epoch 2/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 0.0621 - accuracy: 0.9774 - val_loss: 0.1212 - val_accuracy: 0.9630\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.93287 to 0.96296, saving model to lightningedge007a_results/yes/dominance/s15/max_acc_yes_dominance_s15.h5\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.20161 to 0.12115, saving model to lightningedge007a_results/yes/dominance/s15/min_loss_yes_dominance_s15.h5\n",
      "Epoch 3/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 0.0224 - accuracy: 0.9948 - val_loss: 0.1108 - val_accuracy: 0.9630\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.96296\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.12115 to 0.11079, saving model to lightningedge007a_results/yes/dominance/s15/min_loss_yes_dominance_s15.h5\n",
      "Epoch 4/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 0.0063 - accuracy: 0.9994 - val_loss: 0.0865 - val_accuracy: 0.9676\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.96296 to 0.96759, saving model to lightningedge007a_results/yes/dominance/s15/max_acc_yes_dominance_s15.h5\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.11079 to 0.08647, saving model to lightningedge007a_results/yes/dominance/s15/min_loss_yes_dominance_s15.h5\n",
      "Epoch 5/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0717 - val_accuracy: 0.9722\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.96759 to 0.97222, saving model to lightningedge007a_results/yes/dominance/s15/max_acc_yes_dominance_s15.h5\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.08647 to 0.07171, saving model to lightningedge007a_results/yes/dominance/s15/min_loss_yes_dominance_s15.h5\n",
      "Epoch 6/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0699 - val_accuracy: 0.9745\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.97222 to 0.97454, saving model to lightningedge007a_results/yes/dominance/s15/max_acc_yes_dominance_s15.h5\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.07171 to 0.06989, saving model to lightningedge007a_results/yes/dominance/s15/min_loss_yes_dominance_s15.h5\n",
      "Epoch 7/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0636 - val_accuracy: 0.9815\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.97454 to 0.98148, saving model to lightningedge007a_results/yes/dominance/s15/max_acc_yes_dominance_s15.h5\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.06989 to 0.06357, saving model to lightningedge007a_results/yes/dominance/s15/min_loss_yes_dominance_s15.h5\n",
      "Epoch 8/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0614 - val_accuracy: 0.9792\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.98148\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.06357 to 0.06136, saving model to lightningedge007a_results/yes/dominance/s15/min_loss_yes_dominance_s15.h5\n",
      "Epoch 9/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 9.9713e-04 - accuracy: 1.0000 - val_loss: 0.0588 - val_accuracy: 0.9792\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.98148\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.06136 to 0.05881, saving model to lightningedge007a_results/yes/dominance/s15/min_loss_yes_dominance_s15.h5\n",
      "Epoch 10/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 8.4527e-04 - accuracy: 1.0000 - val_loss: 0.0577 - val_accuracy: 0.9792\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.98148\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.05881 to 0.05772, saving model to lightningedge007a_results/yes/dominance/s15/min_loss_yes_dominance_s15.h5\n",
      "Epoch 11/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 7.3567e-04 - accuracy: 1.0000 - val_loss: 0.0569 - val_accuracy: 0.9792\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.98148\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.05772 to 0.05687, saving model to lightningedge007a_results/yes/dominance/s15/min_loss_yes_dominance_s15.h5\n",
      "Epoch 12/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 6.4958e-04 - accuracy: 1.0000 - val_loss: 0.0552 - val_accuracy: 0.9792\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.98148\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.05687 to 0.05516, saving model to lightningedge007a_results/yes/dominance/s15/min_loss_yes_dominance_s15.h5\n",
      "Epoch 13/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 5.7460e-04 - accuracy: 1.0000 - val_loss: 0.0538 - val_accuracy: 0.9815\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.98148\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.05516 to 0.05378, saving model to lightningedge007a_results/yes/dominance/s15/min_loss_yes_dominance_s15.h5\n",
      "Epoch 14/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 5.2188e-04 - accuracy: 1.0000 - val_loss: 0.0539 - val_accuracy: 0.9792\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.98148\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.05378\n",
      "Epoch 15/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 4.6680e-04 - accuracy: 1.0000 - val_loss: 0.0531 - val_accuracy: 0.9792\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.98148\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.05378 to 0.05315, saving model to lightningedge007a_results/yes/dominance/s15/min_loss_yes_dominance_s15.h5\n",
      "Epoch 16/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 4.2681e-04 - accuracy: 1.0000 - val_loss: 0.0527 - val_accuracy: 0.9792\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.98148\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.05315 to 0.05271, saving model to lightningedge007a_results/yes/dominance/s15/min_loss_yes_dominance_s15.h5\n",
      "Epoch 17/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 3.8729e-04 - accuracy: 1.0000 - val_loss: 0.0523 - val_accuracy: 0.9815\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.98148\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.05271 to 0.05228, saving model to lightningedge007a_results/yes/dominance/s15/min_loss_yes_dominance_s15.h5\n",
      "Epoch 18/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 3.5790e-04 - accuracy: 1.0000 - val_loss: 0.0520 - val_accuracy: 0.9815\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.98148\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.05228 to 0.05204, saving model to lightningedge007a_results/yes/dominance/s15/min_loss_yes_dominance_s15.h5\n",
      "Epoch 19/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 3.2540e-04 - accuracy: 1.0000 - val_loss: 0.0518 - val_accuracy: 0.9792\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.98148\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.05204 to 0.05181, saving model to lightningedge007a_results/yes/dominance/s15/min_loss_yes_dominance_s15.h5\n",
      "Epoch 20/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 3.0333e-04 - accuracy: 1.0000 - val_loss: 0.0515 - val_accuracy: 0.9815\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.98148\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.05181 to 0.05147, saving model to lightningedge007a_results/yes/dominance/s15/min_loss_yes_dominance_s15.h5\n",
      "Epoch 21/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 2.7184e-04 - accuracy: 1.0000 - val_loss: 0.0513 - val_accuracy: 0.9815\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.98148\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.05147 to 0.05134, saving model to lightningedge007a_results/yes/dominance/s15/min_loss_yes_dominance_s15.h5\n",
      "Epoch 22/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 2.5718e-04 - accuracy: 1.0000 - val_loss: 0.0514 - val_accuracy: 0.9792\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.98148\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.05134\n",
      "Epoch 23/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 2.4304e-04 - accuracy: 1.0000 - val_loss: 0.0506 - val_accuracy: 0.9838\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00023: val_accuracy improved from 0.98148 to 0.98380, saving model to lightningedge007a_results/yes/dominance/s15/max_acc_yes_dominance_s15.h5\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.05134 to 0.05063, saving model to lightningedge007a_results/yes/dominance/s15/min_loss_yes_dominance_s15.h5\n",
      "Epoch 24/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 2.2379e-04 - accuracy: 1.0000 - val_loss: 0.0505 - val_accuracy: 0.9838\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.98380\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.05063 to 0.05045, saving model to lightningedge007a_results/yes/dominance/s15/min_loss_yes_dominance_s15.h5\n",
      "Epoch 25/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 2.0974e-04 - accuracy: 1.0000 - val_loss: 0.0503 - val_accuracy: 0.9838\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.98380\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.05045 to 0.05033, saving model to lightningedge007a_results/yes/dominance/s15/min_loss_yes_dominance_s15.h5\n",
      "Epoch 26/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.9857e-04 - accuracy: 1.0000 - val_loss: 0.0503 - val_accuracy: 0.9838\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.98380\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.05033 to 0.05028, saving model to lightningedge007a_results/yes/dominance/s15/min_loss_yes_dominance_s15.h5\n",
      "Epoch 27/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.8651e-04 - accuracy: 1.0000 - val_loss: 0.0502 - val_accuracy: 0.9838\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.98380\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.05028 to 0.05024, saving model to lightningedge007a_results/yes/dominance/s15/min_loss_yes_dominance_s15.h5\n",
      "Epoch 28/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.7391e-04 - accuracy: 1.0000 - val_loss: 0.0505 - val_accuracy: 0.9838\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.98380\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.05024\n",
      "Epoch 29/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.6509e-04 - accuracy: 1.0000 - val_loss: 0.0504 - val_accuracy: 0.9838\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.98380\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.05024\n",
      "Epoch 30/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.5690e-04 - accuracy: 1.0000 - val_loss: 0.0505 - val_accuracy: 0.9838\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.98380\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.05024\n",
      "Epoch 31/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.4872e-04 - accuracy: 1.0000 - val_loss: 0.0500 - val_accuracy: 0.9838\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.98380\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.05024 to 0.04999, saving model to lightningedge007a_results/yes/dominance/s15/min_loss_yes_dominance_s15.h5\n",
      "Epoch 32/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.4120e-04 - accuracy: 1.0000 - val_loss: 0.0501 - val_accuracy: 0.9838\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.98380\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.04999\n",
      "Epoch 33/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.3344e-04 - accuracy: 1.0000 - val_loss: 0.0502 - val_accuracy: 0.9838\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.98380\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.04999\n",
      "Epoch 34/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.2741e-04 - accuracy: 1.0000 - val_loss: 0.0500 - val_accuracy: 0.9838\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.98380\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.04999 to 0.04999, saving model to lightningedge007a_results/yes/dominance/s15/min_loss_yes_dominance_s15.h5\n",
      "Epoch 35/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.1832e-04 - accuracy: 1.0000 - val_loss: 0.0500 - val_accuracy: 0.9838\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.98380\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.04999 to 0.04999, saving model to lightningedge007a_results/yes/dominance/s15/min_loss_yes_dominance_s15.h5\n",
      "Epoch 36/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.1593e-04 - accuracy: 1.0000 - val_loss: 0.0498 - val_accuracy: 0.9838\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.98380\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.04999 to 0.04977, saving model to lightningedge007a_results/yes/dominance/s15/min_loss_yes_dominance_s15.h5\n",
      "Epoch 37/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.0865e-04 - accuracy: 1.0000 - val_loss: 0.0497 - val_accuracy: 0.9838\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.98380\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.04977 to 0.04970, saving model to lightningedge007a_results/yes/dominance/s15/min_loss_yes_dominance_s15.h5\n",
      "Epoch 38/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.0626e-04 - accuracy: 1.0000 - val_loss: 0.0501 - val_accuracy: 0.9838\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.98380\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.04970\n",
      "Epoch 39/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 1.0027e-04 - accuracy: 1.0000 - val_loss: 0.0497 - val_accuracy: 0.9838\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.98380\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.04970 to 0.04969, saving model to lightningedge007a_results/yes/dominance/s15/min_loss_yes_dominance_s15.h5\n",
      "Epoch 40/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 9.6343e-05 - accuracy: 1.0000 - val_loss: 0.0498 - val_accuracy: 0.9838\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.98380\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.04969\n",
      "Epoch 41/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 9.2674e-05 - accuracy: 1.0000 - val_loss: 0.0498 - val_accuracy: 0.9838\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.98380\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.04969\n",
      "Epoch 42/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 8.7007e-05 - accuracy: 1.0000 - val_loss: 0.0498 - val_accuracy: 0.9838\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.98380\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.04969\n",
      "Epoch 43/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 8.4727e-05 - accuracy: 1.0000 - val_loss: 0.0496 - val_accuracy: 0.9838\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.98380\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.04969 to 0.04964, saving model to lightningedge007a_results/yes/dominance/s15/min_loss_yes_dominance_s15.h5\n",
      "Epoch 44/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 8.1437e-05 - accuracy: 1.0000 - val_loss: 0.0497 - val_accuracy: 0.9838\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.98380\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.04964\n",
      "Epoch 45/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 7.9063e-05 - accuracy: 1.0000 - val_loss: 0.0499 - val_accuracy: 0.9838\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.98380\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.04964\n",
      "Epoch 46/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 7.4764e-05 - accuracy: 1.0000 - val_loss: 0.0495 - val_accuracy: 0.9838\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.98380\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.04964 to 0.04951, saving model to lightningedge007a_results/yes/dominance/s15/min_loss_yes_dominance_s15.h5\n",
      "Epoch 47/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 7.3034e-05 - accuracy: 1.0000 - val_loss: 0.0494 - val_accuracy: 0.9838\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.98380\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.04951 to 0.04939, saving model to lightningedge007a_results/yes/dominance/s15/min_loss_yes_dominance_s15.h5\n",
      "Epoch 48/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 6.9530e-05 - accuracy: 1.0000 - val_loss: 0.0495 - val_accuracy: 0.9838\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.98380\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.04939\n",
      "Epoch 49/50\n",
      "1728/1728 [==============================] - 3s 2ms/step - loss: 6.7245e-05 - accuracy: 1.0000 - val_loss: 0.0496 - val_accuracy: 0.9838\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.98380\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.04939\n",
      "Epoch 50/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1728/1728 [==============================] - 3s 2ms/step - loss: 6.4995e-05 - accuracy: 1.0000 - val_loss: 0.0497 - val_accuracy: 0.9838\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.98380\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.04939\n",
      "240/240 [==============================] - 1s 5ms/step\n",
      "max acc:  [0.029465879569761454, 0.9916666746139526]\n",
      "240/240 [==============================] - 1s 4ms/step\n",
      "min loss:  [0.028377537611716738, 0.9916666746139526]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(32)\n",
    "\n",
    "window_size = 128\n",
    "\n",
    "cnn_suffix ='.mat_win_128_cnn_dataset.pkl'\n",
    "rnn_suffix ='.mat_win_128_rnn_dataset.pkl'\n",
    "label_suffix ='.mat_win_128_labels.pkl'\n",
    "\n",
    "for with_or_without in baseline_preprocessing:\n",
    "    for arousal_or_valence in emotions:\n",
    "        for data_file in data_files:\n",
    "            \n",
    "            gc.collect()\n",
    "            \n",
    "            print('---------------------------------------------------')\n",
    "            print(with_or_without+' '+arousal_or_valence+' '+data_file)\n",
    "            print('---------------------------------------------------\\n')\n",
    "\n",
    "            #data_file    ='s17'\n",
    "            #arousal_or_valence = 'valence'\n",
    "            #with_or_without = 'yes'\n",
    "\n",
    "            dataset_dir = 'deap_shuffled_data/'+with_or_without+'_'+arousal_or_valence+'/'\n",
    "            ###load training set\n",
    "            try:\n",
    "                with open(dataset_dir + data_file + cnn_suffix, \"rb\") as fp:\n",
    "                    cnn_datasets = pickle.load(fp)\n",
    "                with open(dataset_dir + data_file + rnn_suffix, \"rb\") as fp:\n",
    "                    rnn_datasets = pickle.load(fp)\n",
    "                with open(dataset_dir + data_file + label_suffix, \"rb\") as fp:\n",
    "                    labels = pickle.load(fp)\n",
    "                    labels = np.transpose(labels)\n",
    "                    print(\"loaded shape:\",labels.shape)\n",
    "            except:\n",
    "                continue\n",
    "            lables_backup = labels\n",
    "\n",
    "            print(cnn_datasets.shape)\n",
    "            print(rnn_datasets.shape)\n",
    "            print(labels.shape)\n",
    "\n",
    "            #print(\"cnn_dataset shape before reshape:\", np.shape(cnn_datasets))\n",
    "            # cnn_datasets = cnn_datasets.reshape(len(cnn_datasets), window_size, 9,9, 1)\n",
    "            #print(\"cnn_dataset shape after reshape:\", np.shape(cnn_datasets))\n",
    "            one_hot_labels = np.array(list(pd.get_dummies(labels)))\n",
    "\n",
    "            labels = np.asarray(pd.get_dummies(labels), dtype=np.int8)\n",
    "\n",
    "            print(labels.shape)\n",
    "            # shuffle data\n",
    "            index = np.array(range(0, len(labels)))\n",
    "            np.random.shuffle(index)\n",
    "\n",
    "            cnn_datasets   = cnn_datasets[index]\n",
    "            rnn_datasets   = rnn_datasets[index]\n",
    "            labels  = labels[index]\n",
    "\n",
    "            print(cnn_datasets.shape)\n",
    "            print(rnn_datasets.shape)\n",
    "            print(labels.shape)\n",
    "\n",
    "            #print(\"**********(\" + time.asctime(time.localtime(time.time())) + \") Load and Split dataset End **********\\n\")\n",
    "            #print(\"**********(\" + time.asctime(time.localtime(time.time())) + \") Define parameters and functions Begin: **********\\n\")\n",
    "            print('cnn_datasets.shape,rnn_datasets.shape,labels.shape : ',cnn_datasets.shape,rnn_datasets.shape,labels.shape)\n",
    "            #important\n",
    "            cnn_datasets=cnn_datasets.reshape(2400,9,9,-1)# imp\n",
    "            print(cnn_datasets.shape)\n",
    "            print('cnn_datasets.shape : ',cnn_datasets.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            print('========================Train / Test Shapes==============================')\n",
    "\n",
    "\n",
    "\n",
    "            fold=10\n",
    "            curr_fold=0\n",
    "            #for curr_fold in range(fold): # kernel dies\n",
    "                \n",
    "            #   print('curr_fold / fold : ',curr_fold,' / ',fold)\n",
    "\n",
    "\n",
    "            max_acc_acc_list=[]\n",
    "\n",
    "            max_acc_loss_list=[]\n",
    "\n",
    "\n",
    "            min_loss_acc_list=[]\n",
    "\n",
    "            min_loss_loss_list=[]\n",
    "\n",
    "            fold_size = cnn_datasets.shape[0]//fold\n",
    "            indexes_list = [i for i in range(len(cnn_datasets))]\n",
    "            indexes = np.array(indexes_list)\n",
    "            split_list = [i for i in range(curr_fold*fold_size,(curr_fold+1)*fold_size)]\n",
    "            split = np.array(split_list)\n",
    "\n",
    "            cnn_test = cnn_datasets[split] \n",
    "            labels_test = labels[split]\n",
    "            rnn_test = rnn_datasets[split]\n",
    "\n",
    "            split = np.array(list(set(indexes_list)^set(split_list)))\n",
    "\n",
    "            cnn_train = cnn_datasets[split]\n",
    "            rnn_train = rnn_datasets[split]\n",
    "            labels_train = labels[split]\n",
    "\n",
    "            # train_sample = labels_train.shape[0]\n",
    "            # print(\"training examples:\", train_sample)\n",
    "            # test_sample = labels_test.shape[0]\n",
    "            # print(\"test examples    :\",test_sample)\n",
    "            print(cnn_test.shape,rnn_test.shape,cnn_train.shape,rnn_train.shape)\n",
    "\n",
    "            print('================================ DNN ============================================')\n",
    "\n",
    "            input_cnn=Input(shape=(9,9,128))\n",
    "\n",
    "            print('input_cnn: ',input_cnn.shape)\n",
    "\n",
    "            conv1=Conv2D(32,\n",
    "                          kernel_size=(4,4),\n",
    "                          strides=(1,1),\n",
    "                          padding='same',\n",
    "                          input_shape=(9,9,128)\n",
    "                         )(input_cnn)\n",
    "\n",
    "\n",
    "            bn1=BatchNormalization()(conv1)\n",
    "\n",
    "            elu1=ELU()(bn1)\n",
    "\n",
    "            print('elu1: ',elu1.shape)\n",
    "            #?,9,9,32\n",
    "            conv2=Conv2D(64,\n",
    "                          kernel_size=(4,4),\n",
    "                          strides=(1,1),\n",
    "                          padding='same'\n",
    "                         )(elu1)\n",
    "\n",
    "            bn2=BatchNormalization()(conv2)\n",
    "\n",
    "            elu2=ELU()(bn2)\n",
    "\n",
    "            print('elu2: ',elu2.shape)\n",
    "            #?,9,9,64\n",
    "\n",
    "            conv3=Conv2D(128,\n",
    "                          kernel_size=(4,4),\n",
    "                          strides=(1,1),\n",
    "                          padding='same'\n",
    "                         )(elu2)\n",
    "\n",
    "            bn3=BatchNormalization()(conv3)\n",
    "\n",
    "            elu3=ELU()(bn3)\n",
    "\n",
    "\n",
    "            print('elu3: ',elu3.shape)\n",
    "            #?,9,9,128\n",
    "\n",
    "            # mc.add(Flatten())\n",
    "            # mc.add(Lambda(lambda x:x,output_shape=(9,9,32*4*128)))\n",
    "            # mc.add(Lambda(K.reshape((-1,9,9,32*4*128))))\n",
    "            reshape1=Reshape((9,9,-1))(elu3)\n",
    "\n",
    "\n",
    "            print('reshape1: ',reshape1.shape)\n",
    "            #?,9,9,32*4*128\n",
    "\n",
    "            conv4=Conv2D(13,#32*4*128,\n",
    "                          kernel_size=(1,1),\n",
    "                          strides=(1,1),\n",
    "                          padding='same'\n",
    "                         )(reshape1)\n",
    "\n",
    "            bn4=BatchNormalization()(conv4)\n",
    "\n",
    "            elu4=ELU()(bn4)\n",
    "\n",
    "\n",
    "            print('elu4: ',elu4.shape)\n",
    "            #?,9,9,13 #32*4*128\n",
    "\n",
    "            # mc.add(Flatten())\n",
    "\n",
    "            # mc.add(Lambda(lambda x:x,output_shape=([13*9*9])))\n",
    "            # mc.add(Lambda(K.reshape((None,13*9*9))))\n",
    "            reshape2=Reshape(([13*9*9]))(elu4)\n",
    "\n",
    "\n",
    "            print('reshape2: ',reshape2.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            cnn_out_fuse=reshape2\n",
    "\n",
    "\n",
    "            # cube=K.reshape(e3,(-1,9,9,32*4*128))#(e3)\n",
    "\n",
    "\n",
    "            # flat=K.reshape(e4,(-1,13*9*9))#(e4) #1053\n",
    "\n",
    "            # rnn_in=K.placeholder(shape=(None,128,32))\n",
    "            # rnn_in=tf.convert_to_tensor(rnn_datasets,dtype='float32')\n",
    "\n",
    "\n",
    "            # rnn_in.get_shape().as_list()\n",
    "\n",
    "            # rnn_in=K.placeholder(shape=(None,128,32))\n",
    "            # rnn_in_flat=K.reshape(rnn_in,[-1,32])\n",
    "\n",
    "            # print('rnn_in ',rnn_in.shape)\n",
    "\n",
    "            input_rnn=Input(shape=(128,32))\n",
    "            print('input_rnn',input_rnn.shape)\n",
    "\n",
    "            rnn_in_flat=Reshape((-1,32))(input_rnn)\n",
    "            print('rnn_in_flat',rnn_in_flat.shape)\n",
    "            # rnn_in_flat = Lambda(lambda x:x[:,0])(input_rnn)\n",
    "\n",
    "            # rnn_fc_in1 =Dense(32)(rnn_in_flat)\n",
    "            rnn_fc_in1 =Dense(1024)(rnn_in_flat)\n",
    "            rnn_fc_in=ELU()(rnn_fc_in1)\n",
    "            print('rnn_fc_in',rnn_fc_in.shape)\n",
    "\n",
    "            # rnn_fc_in =Dense(1024)(input_rnn)\n",
    "\n",
    "            # lstm_in=Reshape((-1,128,1024))(rnn_fc_in)\n",
    "            lstm_in=Reshape((-1,1024))(rnn_fc_in)\n",
    "            print('lstm_in',lstm_in.shape)\n",
    "\n",
    "            cells=[]\n",
    "\n",
    "            for i in range(2):\n",
    "                cell=LSTMCell(32,unit_forget_bias=True,dropout=0.5)#'forget_bias'=1.0,'state_is_tuple'=True\n",
    "                cells.append(cell)\n",
    "            #     print(cell.shape)\n",
    "\n",
    "            # lstm_cell=StackedRNNCells(cells)\n",
    "            lstm_cell=RNN(cells)(lstm_in)\n",
    "            # print(lstm_cell.shape)\n",
    "            # op,states=RNN(cells)(lstm_in)\n",
    "            print('lstm_cell',lstm_cell.shape)\n",
    "            # output=K.transpose_shape((1,0,2),lstm_cell)\n",
    "            # output=Permute((1,0,2))(lstm_cell)\n",
    "            # output.reshape()\n",
    "            output=lstm_cell\n",
    "            print('output',output.shape)\n",
    "            rnn_output=output[-1]\n",
    "            # rnn_output\n",
    "\n",
    "            print('rnn_output',rnn_output.shape)\n",
    "            # shape_rnn_out=rnn_output.get_shape().as_list()\n",
    "            lstm_fc_out=Dense(1024)(output)#shape_rnn_out[1]\n",
    "\n",
    "            print('lstm_fc_out',lstm_fc_out.shape)\n",
    "\n",
    "\n",
    "            # lstm_fc_out_2=Dense(1053)(lstm_fc_out)#shape_rnn_out[1]\n",
    "\n",
    "\n",
    "\n",
    "            lstm_fc_drop=Dropout(0.5)(lstm_fc_out)\n",
    "            # lstm_fc_drop\n",
    "            print('lstm_fc_drop',lstm_fc_drop.shape)\n",
    "\n",
    "            # fuse_cnn_rnn=add([cnn_out_fuse,lstm_fc_drop])\n",
    "\n",
    "            fuse_cnn_rnn=concatenate([cnn_out_fuse,lstm_fc_drop])\n",
    "            print('fuse_cnn_rnn ',fuse_cnn_rnn.shape)\n",
    "            y=Dense(2,activation='softmax')(fuse_cnn_rnn) ## ,activity_regularizer=regularizers.l2(0.5)\n",
    "            print(y.shape)\n",
    "            y_pred=K.argmax(y,1)\n",
    "            # y_pred=K.argmax(K.softmax(y))\n",
    "            # y_posi=K.softmax(y)\n",
    "            print('y ',y)\n",
    "\n",
    "\n",
    "            directory_le007a='./lightningedge007a_results/'+with_or_without+'/'+arousal_or_valence+'/'+data_file\n",
    "            try:\n",
    "                if not os.path.exists(directory_le007a):\n",
    "                    os.makedirs(directory_le007a)\n",
    "            except OSError:\n",
    "                print ('Error: Creating directory. ' +  directory_le007a)\n",
    "\n",
    "\n",
    "\n",
    "            model=Model(inputs=[input_cnn,input_rnn],outputs=y)\n",
    "            model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "            print('Model : ',with_or_without+'_'+arousal_or_valence+'_'+data_file+'_'+str(curr_fold)+'_fold')\n",
    "            print(model.summary())\n",
    "\n",
    "            m_val_acc=ModelCheckpoint('lightningedge007a_results/'+with_or_without+'/'+arousal_or_valence+'/'+data_file+'/'+'max_acc_'+with_or_without+'_'+arousal_or_valence+'_'+data_file+'.h5',monitor='val_accuracy',mode='max',verbose=1,save_best_only=True)\n",
    "            m_val_loss=ModelCheckpoint('lightningedge007a_results/'+with_or_without+'/'+arousal_or_valence+'/'+data_file+'/'+'min_loss_'+with_or_without+'_'+arousal_or_valence+'_'+data_file+'.h5',monitor='val_loss',mode='min',verbose=1,save_best_only=True)\n",
    "\n",
    "\n",
    "            tb_log_dir='lightningedge007a_results\\\\'+with_or_without+'\\\\'+arousal_or_valence+'\\\\'+data_file+'\\\\'+'logs_'+with_or_without+'_'+arousal_or_valence+'_'+data_file\n",
    "            #tb_log_dir='lightningedge007a_results/'+with_or_without+'/'+arousal_or_valence+'/'+data_file+'/'+'logs_'+with_or_without+'_'+arousal_or_valence+'_'+data_file\n",
    "\n",
    "            createFolder(tb_log_dir)\n",
    "\n",
    "\n",
    "            #log_dir='lightningedge007a_results\\\\'+with_or_without+'\\\\'+arousal_or_valence+'\\\\'+data_file+'\\\\'+'logs_'+with_or_without+'_'+arousal_or_valence+'_'+data_file+'_'+str(curr_fold)+'_fold\\\\' #datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "            tensorboard_callback = callbacks.TensorBoard(log_dir=tb_log_dir)#, histogram_freq=1)\n",
    "\n",
    "            plotpicture=plot_model(model, to_file='lightningedge007a_results/'+with_or_without+'/'+arousal_or_valence+'/'+data_file+'/'+'model_'+with_or_without+'_'+arousal_or_valence+'_'+data_file+'.png', show_shapes=True)\n",
    "\n",
    "            \n",
    "            \n",
    "            gc.collect()\n",
    "            \n",
    "            \n",
    "\n",
    "            history=model.fit([cnn_train,rnn_train],labels_train,batch_size=128,epochs=50,callbacks=[tensorboard_callback,m_val_acc,m_val_loss],validation_split=0.2)\n",
    "\n",
    "\n",
    "            #Plot values\n",
    "            plt.plot(history.history['accuracy'])\n",
    "            plt.plot(history.history['val_accuracy'])\n",
    "            plt.title('max_acc_'+with_or_without+'_'+arousal_or_valence+'_'+data_file)\n",
    "            plt.ylabel('Accuracy')\n",
    "            plt.xlabel('Epoch')\n",
    "            plt.legend(['Train', 'Validation'], loc='upper right',bbox_to_anchor=(1.3,1))\n",
    "            plt.savefig('lightningedge007a_results/'+with_or_without+'/'+arousal_or_valence+'/'+data_file+'/'+'max_acc_'+with_or_without+'_'+arousal_or_valence+'_'+data_file+'.png',bbox_inches='tight')\n",
    "            #plt.show()\n",
    "            plt.close()\n",
    "\n",
    "\n",
    "            # Plot training & validation loss values\n",
    "            plt.plot(history.history['loss'])\n",
    "            plt.plot(history.history['val_loss'])\n",
    "            plt.title('min_loss_'+with_or_without+'_'+arousal_or_valence+'_'+data_file+'_'+str(curr_fold)+'_fold')\n",
    "            plt.ylabel('Loss')\n",
    "            plt.xlabel('Epoch')\n",
    "            plt.legend(['Train', 'Validation'], loc='upper right',bbox_to_anchor=(1.3,1))\n",
    "            plt.savefig('lightningedge007a_results/'+with_or_without+'/'+arousal_or_valence+'/'+data_file+'/'+'min_loss_'+with_or_without+'_'+arousal_or_valence+'_'+data_file+'.png',bbox_inches='tight')\n",
    "            #plt.show()\n",
    "            plt.close()\n",
    "\n",
    "            vam=load_model('lightningedge007a_results/'+with_or_without+'/'+arousal_or_valence+'/'+data_file+'/'+'max_acc_'+with_or_without+'_'+arousal_or_valence+'_'+data_file+'.h5')\n",
    "            vlm=load_model('lightningedge007a_results/'+with_or_without+'/'+arousal_or_valence+'/'+data_file+'/'+'min_loss_'+with_or_without+'_'+arousal_or_valence+'_'+data_file+'.h5')\n",
    "            # pred_labels=vam()\n",
    "            vam_eval=vam.evaluate([cnn_test,rnn_test],labels_test)\n",
    "            print('max acc: ',vam_eval)\n",
    "            vlm_eval=vlm.evaluate([cnn_test,rnn_test],labels_test)\n",
    "            print('min loss: ',vlm_eval)\n",
    "\n",
    "\n",
    "            max_acc_acc_list.append(vam_eval[1])\n",
    "\n",
    "            max_acc_loss_list.append(vam_eval[0])\n",
    "\n",
    "\n",
    "            min_loss_acc_list.append(vlm_eval[1])\n",
    "\n",
    "            min_loss_loss_list.append(vlm_eval[0])\n",
    "\n",
    "            pickle.dump(max_acc_acc_list,open('lightningedge007a_results/'+with_or_without+'/'+arousal_or_valence+'/'+data_file+'/'+'max_acc_acc_list_'+with_or_without+'_'+arousal_or_valence+'_'+data_file+'.pkl','wb'))\n",
    "\n",
    "            pickle.dump(max_acc_loss_list,open('lightningedge007a_results/'+with_or_without+'/'+arousal_or_valence+'/'+data_file+'/'+'max_acc_loss_list_'+with_or_without+'_'+arousal_or_valence+'_'+data_file+'.pkl','wb'))\n",
    "\n",
    "\n",
    "            pickle.dump(min_loss_acc_list,open('lightningedge007a_results/'+with_or_without+'/'+arousal_or_valence+'/'+data_file+'/'+'min_loss_acc_list_'+with_or_without+'_'+arousal_or_valence+'_'+data_file+'.pkl','wb'))\n",
    "\n",
    "            pickle.dump(min_loss_loss_list,open('lightningedge007a_results/'+with_or_without+'/'+arousal_or_valence+'/'+data_file+'/'+'min_loss_loss_list_'+with_or_without+'_'+arousal_or_valence+'_'+data_file+'.pkl','wb'))\n",
    "            \n",
    "            \n",
    "            gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 560.8,
   "position": {
    "height": "40px",
    "left": "4px",
    "right": "20px",
    "top": "117px",
    "width": "657.4px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "none",
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
