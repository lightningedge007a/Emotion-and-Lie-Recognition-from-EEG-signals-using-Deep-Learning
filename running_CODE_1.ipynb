{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-19T19:23:27.002585Z",
     "start_time": "2019-11-19T19:23:26.999593Z"
    }
   },
   "outputs": [],
   "source": [
    "emotion='valence'\n",
    "data_file='s16'\n",
    "with_or_without='yes'#don't change #preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-19T19:23:34.391992Z",
     "start_time": "2019-11-19T19:23:29.433830Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "\n",
    "from keras.layers import Conv2D, Dense, Flatten, ELU, BatchNormalization, LSTMCell, StackedRNNCells,\\\n",
    "    RNN, Permute, Dropout, Concatenate, Input, concatenate, Lambda, Reshape, Lambda\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.utils import plot_model\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers.merge import add\n",
    "\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "from keras.models import load_model\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-19T19:24:43.517084Z",
     "start_time": "2019-11-19T19:23:53.042711Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------\n",
      "yes valence s16\n",
      "---------------------------------------------------\n",
      "\n",
      "loaded shape: (2400,)\n",
      "cnn_datasets.shape,rnn_datasets.shape,labels.shape :  (2400, 128, 9, 9) (2400, 128, 32) (2400, 2)\n",
      "(2400, 9, 9, 128)\n",
      "cnn_datasets.shape :  (2400, 9, 9, 128)\n",
      "================================ DNN ============================================\n",
      "input_cnn:  (None, 9, 9, 128)\n",
      "elu1:  (None, 9, 9, 32)\n",
      "elu2:  (None, 9, 9, 64)\n",
      "elu3:  (None, 9, 9, 128)\n",
      "reshape1:  (None, 9, 9, None)\n",
      "elu4:  (None, 9, 9, 13)\n",
      "reshape2:  (None, 1053)\n",
      "input_rnn (None, 128, 32)\n",
      "rnn_in_flat (None, None, 32)\n",
      "rnn_fc_in (None, 128, 1024)\n",
      "lstm_in (None, None, 1024)\n",
      "lstm_cell (None, 32)\n",
      "output (None, 32)\n",
      "rnn_output (32,)\n",
      "lstm_fc_out (None, 1024)\n",
      "lstm_fc_drop (None, 1024)\n",
      "fuse_cnn_rnn  (None, 2077)\n",
      "(None, 2)\n",
      "y  Tensor(\"dense_3/Softmax:0\", shape=(None, 2), dtype=float32)\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 9, 9, 128)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 9, 9, 32)     65568       input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 9, 9, 32)     128         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "elu_1 (ELU)                     (None, 9, 9, 32)     0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 9, 9, 64)     32832       elu_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 9, 9, 64)     256         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "elu_2 (ELU)                     (None, 9, 9, 64)     0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 9, 9, 128)    131200      elu_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 128, 32)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 9, 9, 128)    512         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_3 (Reshape)             (None, 128, 32)      0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "elu_3 (ELU)                     (None, 9, 9, 128)    0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 128, 1024)    33792       reshape_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 9, 9, 128)    0           elu_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "elu_5 (ELU)                     (None, 128, 1024)    0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 9, 9, 13)     1677        reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_4 (Reshape)             (None, 128, 1024)    0           elu_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 9, 9, 13)     52          conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "rnn_1 (RNN)                     (None, 32)           143616      reshape_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "elu_4 (ELU)                     (None, 9, 9, 13)     0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1024)         33792       rnn_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "reshape_2 (Reshape)             (None, 1053)         0           elu_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 1024)         0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 2077)         0           reshape_2[0][0]                  \n",
      "                                                                 dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 2)            4156        concatenate_1[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 447,581\n",
      "Trainable params: 447,107\n",
      "Non-trainable params: 474\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "2400/2400 [==============================] - 11s 5ms/step\n",
      "max acc:  [0.011826703823559607, 0.996666669845581]\n",
      "Loss :  0.011826703823559607\n",
      "Accuracy :  0.996666669845581\n",
      "2400/2400 [==============================] - 7s 3ms/step\n",
      "min loss:  [0.011755167483497643, 0.996666669845581]\n",
      "Loss :  0.011755167483497643\n",
      "Accuracy :  0.996666669845581\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(32)\n",
    "\n",
    "window_size = 128\n",
    "\n",
    "cnn_suffix ='.mat_win_128_cnn_dataset.pkl'\n",
    "rnn_suffix ='.mat_win_128_rnn_dataset.pkl'\n",
    "label_suffix ='.mat_win_128_labels.pkl'\n",
    "\n",
    "print('---------------------------------------------------')\n",
    "print(with_or_without+' '+emotion+' '+data_file)\n",
    "print('---------------------------------------------------\\n')\n",
    "\n",
    "\n",
    "dataset_dir = 'deap_shuffled_data/'+with_or_without+'_'+emotion+'/'\n",
    "###load training set\n",
    "try:\n",
    "    with open(dataset_dir + data_file + cnn_suffix, \"rb\") as fp:\n",
    "        cnn_datasets = pickle.load(fp)\n",
    "    with open(dataset_dir + data_file + rnn_suffix, \"rb\") as fp:\n",
    "        rnn_datasets = pickle.load(fp)\n",
    "    with open(dataset_dir + data_file + label_suffix, \"rb\") as fp:\n",
    "        labels = pickle.load(fp)\n",
    "        labels = np.transpose(labels)\n",
    "        print(\"loaded shape:\",labels.shape)\n",
    "except:\n",
    "    print('data file of this subject isnt available')\n",
    "    exit()\n",
    "    \n",
    "lables_backup = labels\n",
    "\n",
    "one_hot_labels = np.array(list(pd.get_dummies(labels)))\n",
    "\n",
    "labels = np.asarray(pd.get_dummies(labels), dtype=np.int8)\n",
    "\n",
    "# shuffle data\n",
    "index = np.array(range(0, len(labels)))\n",
    "np.random.shuffle(index)\n",
    "\n",
    "cnn_datasets   = cnn_datasets[index]\n",
    "rnn_datasets   = rnn_datasets[index]\n",
    "labels  = labels[index]\n",
    "\n",
    "print('cnn_datasets.shape,rnn_datasets.shape,labels.shape : ',cnn_datasets.shape,rnn_datasets.shape,labels.shape)\n",
    "#important\n",
    "cnn_datasets=cnn_datasets.reshape(2400,9,9,-1)# imp\n",
    "print(cnn_datasets.shape)\n",
    "print('cnn_datasets.shape : ',cnn_datasets.shape)\n",
    "\n",
    "\n",
    "print('================================ DNN ============================================')\n",
    "\n",
    "input_cnn=Input(shape=(9,9,128))\n",
    "\n",
    "print('input_cnn: ',input_cnn.shape)\n",
    "\n",
    "conv1=Conv2D(32,\n",
    "              kernel_size=(4,4),\n",
    "              strides=(1,1),\n",
    "              padding='same',\n",
    "              input_shape=(9,9,128)\n",
    "             )(input_cnn)\n",
    "\n",
    "\n",
    "bn1=BatchNormalization()(conv1)\n",
    "\n",
    "elu1=ELU()(bn1)\n",
    "\n",
    "print('elu1: ',elu1.shape)\n",
    "#?,9,9,32\n",
    "conv2=Conv2D(64,\n",
    "              kernel_size=(4,4),\n",
    "              strides=(1,1),\n",
    "              padding='same'\n",
    "             )(elu1)\n",
    "\n",
    "bn2=BatchNormalization()(conv2)\n",
    "\n",
    "elu2=ELU()(bn2)\n",
    "\n",
    "print('elu2: ',elu2.shape)\n",
    "#?,9,9,64\n",
    "\n",
    "conv3=Conv2D(128,\n",
    "              kernel_size=(4,4),\n",
    "              strides=(1,1),\n",
    "              padding='same'\n",
    "             )(elu2)\n",
    "\n",
    "bn3=BatchNormalization()(conv3)\n",
    "\n",
    "elu3=ELU()(bn3)\n",
    "\n",
    "\n",
    "print('elu3: ',elu3.shape)\n",
    "#?,9,9,128\n",
    "\n",
    "# mc.add(Flatten())\n",
    "# mc.add(Lambda(lambda x:x,output_shape=(9,9,32*4*128)))\n",
    "# mc.add(Lambda(K.reshape((-1,9,9,32*4*128))))\n",
    "reshape1=Reshape((9,9,-1))(elu3)\n",
    "\n",
    "\n",
    "print('reshape1: ',reshape1.shape)\n",
    "#?,9,9,32*4*128\n",
    "\n",
    "conv4=Conv2D(13,#32*4*128,\n",
    "              kernel_size=(1,1),\n",
    "              strides=(1,1),\n",
    "              padding='same'\n",
    "             )(reshape1)\n",
    "\n",
    "bn4=BatchNormalization()(conv4)\n",
    "\n",
    "elu4=ELU()(bn4)\n",
    "\n",
    "\n",
    "print('elu4: ',elu4.shape)\n",
    "#?,9,9,13 #32*4*128\n",
    "\n",
    "# mc.add(Flatten())\n",
    "\n",
    "# mc.add(Lambda(lambda x:x,output_shape=([13*9*9])))\n",
    "# mc.add(Lambda(K.reshape((None,13*9*9))))\n",
    "reshape2=Reshape(([13*9*9]))(elu4)\n",
    "\n",
    "\n",
    "print('reshape2: ',reshape2.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "cnn_out_fuse=reshape2\n",
    "\n",
    "\n",
    "# cube=K.reshape(e3,(-1,9,9,32*4*128))#(e3)\n",
    "\n",
    "\n",
    "# flat=K.reshape(e4,(-1,13*9*9))#(e4) #1053\n",
    "\n",
    "# rnn_in=K.placeholder(shape=(None,128,32))\n",
    "# rnn_in=tf.convert_to_tensor(rnn_datasets,dtype='float32')\n",
    "\n",
    "\n",
    "# rnn_in.get_shape().as_list()\n",
    "\n",
    "# rnn_in=K.placeholder(shape=(None,128,32))\n",
    "# rnn_in_flat=K.reshape(rnn_in,[-1,32])\n",
    "\n",
    "# print('rnn_in ',rnn_in.shape)\n",
    "\n",
    "input_rnn=Input(shape=(128,32))\n",
    "print('input_rnn',input_rnn.shape)\n",
    "\n",
    "rnn_in_flat=Reshape((-1,32))(input_rnn)\n",
    "print('rnn_in_flat',rnn_in_flat.shape)\n",
    "# rnn_in_flat = Lambda(lambda x:x[:,0])(input_rnn)\n",
    "\n",
    "# rnn_fc_in1 =Dense(32)(rnn_in_flat)\n",
    "rnn_fc_in1 =Dense(1024)(rnn_in_flat)\n",
    "rnn_fc_in=ELU()(rnn_fc_in1)\n",
    "print('rnn_fc_in',rnn_fc_in.shape)\n",
    "\n",
    "# rnn_fc_in =Dense(1024)(input_rnn)\n",
    "\n",
    "# lstm_in=Reshape((-1,128,1024))(rnn_fc_in)\n",
    "lstm_in=Reshape((-1,1024))(rnn_fc_in)\n",
    "print('lstm_in',lstm_in.shape)\n",
    "\n",
    "cells=[]\n",
    "\n",
    "for i in range(2):\n",
    "    cell=LSTMCell(32,unit_forget_bias=True,dropout=0.5)#'forget_bias'=1.0,'state_is_tuple'=True\n",
    "    cells.append(cell)\n",
    "#     print(cell.shape)\n",
    "\n",
    "# lstm_cell=StackedRNNCells(cells)\n",
    "lstm_cell=RNN(cells)(lstm_in)\n",
    "# print(lstm_cell.shape)\n",
    "# op,states=RNN(cells)(lstm_in)\n",
    "print('lstm_cell',lstm_cell.shape)\n",
    "# output=K.transpose_shape((1,0,2),lstm_cell)\n",
    "# output=Permute((1,0,2))(lstm_cell)\n",
    "# output.reshape()\n",
    "output=lstm_cell\n",
    "print('output',output.shape)\n",
    "rnn_output=output[-1]\n",
    "# rnn_output\n",
    "\n",
    "print('rnn_output',rnn_output.shape)\n",
    "# shape_rnn_out=rnn_output.get_shape().as_list()\n",
    "lstm_fc_out=Dense(1024)(output)#shape_rnn_out[1]\n",
    "\n",
    "print('lstm_fc_out',lstm_fc_out.shape)\n",
    "\n",
    "\n",
    "# lstm_fc_out_2=Dense(1053)(lstm_fc_out)#shape_rnn_out[1]\n",
    "\n",
    "\n",
    "\n",
    "lstm_fc_drop=Dropout(0.5)(lstm_fc_out)\n",
    "# lstm_fc_drop\n",
    "print('lstm_fc_drop',lstm_fc_drop.shape)\n",
    "\n",
    "# fuse_cnn_rnn=add([cnn_out_fuse,lstm_fc_drop])\n",
    "\n",
    "fuse_cnn_rnn=concatenate([cnn_out_fuse,lstm_fc_drop])\n",
    "print('fuse_cnn_rnn ',fuse_cnn_rnn.shape)\n",
    "y=Dense(2,activation='softmax')(fuse_cnn_rnn) ## ,activity_regularizer=regularizers.l2(0.5)\n",
    "print(y.shape)\n",
    "y_pred=K.argmax(y,1)\n",
    "# y_pred=K.argmax(K.softmax(y))\n",
    "# y_posi=K.softmax(y)\n",
    "print('y ',y)\n",
    "\n",
    "\n",
    "# directory_le007a='./lightningedge007a_results/'+with_or_without+'/'+arousal_or_valence+'/'+data_file\n",
    "# try:\n",
    "#     if not os.path.exists(directory_le007a):\n",
    "#         os.makedirs(directory_le007a)\n",
    "# except OSError:\n",
    "#     print ('Error: Creating directory. ' +  directory_le007a)\n",
    "\n",
    "\n",
    "\n",
    "model=Model(inputs=[input_cnn,input_rnn],outputs=y)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "\n",
    "\n",
    "# tb_log_dir='lightningedge007a_results\\\\'+with_or_without+'\\\\'+arousal_or_valence+'\\\\'+data_file+'\\\\'+'logs_'+with_or_without+'_'+arousal_or_valence+'_'+data_file\n",
    "# createFolder(tb_log_dir)\n",
    "\n",
    "\n",
    "#log_dir='lightningedge007a_results\\\\'+with_or_without+'\\\\'+arousal_or_valence+'\\\\'+data_file+'\\\\'+'logs_'+with_or_without+'_'+arousal_or_valence+'_'+data_file+'_'+str(curr_fold)+'_fold\\\\' #datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "# tensorboard_callback = callbacks.TensorBoard(log_dir=tb_log_dir)#, histogram_freq=1)\n",
    "\n",
    "# plotpicture=plot_model(model, to_file='lightningedge007a_results/'+with_or_without+'/'+arousal_or_valence+'/'+data_file+'/'+'model_'+with_or_without+'_'+arousal_or_valence+'_'+data_file+'.png', show_shapes=True)\n",
    "#\n",
    "# plot_model(model,show_shapes=True)\n",
    "#history=model.fit([cnn_train,rnn_train],labels_train,batch_size=128,epochs=50,callbacks=[tensorboard_callback,m_val_acc,m_val_loss],validation_split=0.2)\n",
    "\n",
    "\n",
    "#Plot values\n",
    "# plt.plot(history.history['accuracy'])\n",
    "# plt.plot(history.history['val_accuracy'])\n",
    "# plt.title('max_acc_'+with_or_without+'_'+arousal_or_valence+'_'+data_file)\n",
    "# plt.ylabel('Accuracy')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.legend(['Train', 'Validation'], loc='upper right',bbox_to_anchor=(1.3,1))\n",
    "# plt.savefig('lightningedge007a_results/'+with_or_without+'/'+arousal_or_valence+'/'+data_file+'/'+'max_acc_'+with_or_without+'_'+arousal_or_valence+'_'+data_file+'.png',bbox_inches='tight')\n",
    "# #plt.show()\n",
    "# plt.close()\n",
    "# print(plotpicture)\n",
    "\n",
    "# Plot training & validation loss values\n",
    "# plt.plot(history.history['loss'])\n",
    "# plt.plot(history.history['val_loss'])\n",
    "# plt.title('min_loss_'+with_or_without+'_'+arousal_or_valence+'_'+data_file+'_'+str(curr_fold)+'_fold')\n",
    "# plt.ylabel('Loss')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.legend(['Train', 'Validation'], loc='upper right',bbox_to_anchor=(1.3,1))\n",
    "# plt.savefig('lightningedge007a_results/'+with_or_without+'/'+arousal_or_valence+'/'+data_file+'/'+'min_loss_'+with_or_without+'_'+arousal_or_valence+'_'+data_file+'.png',bbox_inches='tight')\n",
    "# #plt.show()\n",
    "# plt.close()\n",
    "\n",
    "vam=load_model('lightningedge007a_results/'+with_or_without+'/'+emotion+'/'+data_file+'/'+'max_acc_'+with_or_without+'_'+emotion+'_'+data_file+'.h5')\n",
    "vlm=load_model('lightningedge007a_results/'+with_or_without+'/'+emotion+'/'+data_file+'/'+'min_loss_'+with_or_without+'_'+emotion+'_'+data_file+'.h5')\n",
    "# pred_labels=vam()\n",
    "vam_eval=vam.evaluate([cnn_datasets,rnn_datasets],labels)\n",
    "print('max acc: ',vam_eval)\n",
    "\n",
    "print('Loss : ',vam_eval[0])\n",
    "print('Accuracy : ',vam_eval[1])\n",
    "\n",
    "vlm_eval=vlm.evaluate([cnn_datasets,rnn_datasets],labels)\n",
    "print('min loss: ',vlm_eval)\n",
    "\n",
    "print('Loss : ',vlm_eval[0])\n",
    "print('Accuracy : ',vlm_eval[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
